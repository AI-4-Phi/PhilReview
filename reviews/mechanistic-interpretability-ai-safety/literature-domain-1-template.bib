@comment{
====================================================================
DOMAIN: Mechanistic Interpretability - Foundations and Methods
SEARCH_DATE: 2025-12-22
PAPERS_FOUND: 18 (High: 12, Medium: 6)
SEARCH_SOURCES: Semantic Scholar, OpenAlex, arXiv
====================================================================

DOMAIN_OVERVIEW:
Mechanistic interpretability (MI) represents a research paradigm focused on reverse-engineering the learned algorithms and computational structures within neural networks. This domain encompasses work on circuit discovery, feature extraction, and understanding how transformers implement specific behaviors through their internal mechanisms. Key methodological approaches include activation patching, automated circuit discovery (ACDC), and analysis of attention patterns and MLP activations. Recent work has expanded from small toy models to larger language models, with emphasis on identifying interpretable features, understanding grokking phenomena, and developing systematic methods for circuit analysis.

The field is anchored by foundational work from researchers like Chris Olah, Neel Nanda, and the Anthropic interpretability team, establishing both theoretical frameworks (e.g., causal abstraction, modularity assumptions) and practical tools (e.g., TransformerLens, circuit discovery algorithms). Recent developments focus on scaling interpretability methods, automating discovery processes, and connecting MI to downstream applications in AI safety and model understanding.

RELEVANCE_TO_PROJECT:
This domain directly addresses the first research objective: clarifying what "mechanistic interpretability" means in current literature. The papers surveyed reveal both narrow definitions (focusing on neuron-level activations and circuits) and broader conceptualizations (including functional and algorithmic explanations). This diversity in definitions is central to understanding the apparent conflicts between papers like Hendrycks & Hiscott (2025) and Kästner & Crook (2024).

NOTABLE_GAPS:
Limited explicit discussion of what makes an explanation "mechanistic" versus other forms of interpretability. Most papers assume a shared understanding rather than providing definitional clarity. Philosophical grounding for why circuit-level explanations should be privileged over behavioral or functional explanations remains underdeveloped.

SYNTHESIS_GUIDANCE:
Use this domain to establish the technical landscape of MI approaches. Contrast narrow (circuit/neuron-level) versus broad (including functional) definitions. Highlight methodological diversity while noting the field's assumptions about what counts as "interpretation."

KEY_POSITIONS:
- Circuit-focused MI (narrow definition): 8 papers - Focus on identifying minimal computational subgraphs
- Algorithmic understanding: 6 papers - Emphasis on reverse-engineering learned algorithms
- Causal/theoretical foundations: 4 papers - Developing formal frameworks for mechanistic explanation
====================================================================
}

@inproceedings{nanda2023progress,
  author = {Nanda, Neel and Chan, Lawrence and Lieberum, Tom and Smith, Jess and Steinhardt, J.},
  title = {{Progress measures for grokking via mechanistic interpretability}},
  booktitle = {International Conference on Learning Representations},
  year = {2023},
  doi = {10.48550/arXiv.2301.05217},
  eprint = {2301.05217},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Progress measures for grokking via mechanistic int... Abstract: Neural networks often exhibit emergent behavior, where qualitatively new capabilities arise from scaling up the amount of parameters, training data, o...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{conmy2023automated,
  author = {Conmy, Arthur and Mavor-Parker, Augustine N. and Lynch, Aengus and Heimersheim, Stefan and Garriga-Alonso, Adrià},
  title = {{Towards Automated Circuit Discovery for Mechanistic Interpretability}},
  journal = {Neural Information Processing Systems},
  year = {2023},
  doi = {10.48550/arXiv.2304.14997},
  eprint = {2304.14997},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Towards Automated Circuit Discovery for Mechanisti... Abstract: Through considerable effort and intuition, several recent works have reverse-engineered nontrivial behaviors of transformer models. This paper systema...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{bereska2024mechanistic,
  author = {Bereska, Leonard and Gavves, E.},
  title = {{Mechanistic Interpretability for AI Safety - A Review}},
  journal = {Trans. Mach. Learn. Res.},
  year = {2024},
  doi = {10.48550/arXiv.2404.14082},
  eprint = {2404.14082},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Mechanistic Interpretability for AI Safety - A Rev... Abstract: Understanding AI systems' inner workings is critical for ensuring value alignment and safety. This review explores mechanistic interpretability: rever...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{geiger2023causal,
  author = {Geiger, Atticus and Ibeling, D. and Zur, Amir and Chaudhary, Maheep and Chauhan, Sonakshi and Huang, Jing and Arora, Aryaman and Wu, Zhengxuan and Goodman, Noah D. and Potts, Christopher and Icard, Thomas F.},
  title = {{Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability}},
  year = {2023},
  eprint = {2301.04709},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Causal Abstraction: A Theoretical Foundation for M... Abstract: Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{rai2024practical,
  author = {Rai, Daking and Zhou, Yilun and Feng, Shi and Saparov, Abulhair and Yao, Ziyu},
  title = {{A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models}},
  journal = {arXiv.org},
  year = {2024},
  doi = {10.48550/arXiv.2407.02646},
  eprint = {2407.02646},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze A Practical Review of Mechanistic Interpretability... Abstract: Mechanistic interpretability (MI) is an emerging sub-field of interpretability that seeks to understand a neural network model by reverse-engineering ...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{sharkey2025problems,
  author = {Sharkey, Lee and Chughtai, Bilal and Batson, Joshua and Lindsey, Jack and Wu, Jeff and Bushnaq, Lucius and Goldowsky-Dill, Nicholas and Heimersheim, Stefan and Ortega, Alejandro and Bloom, Joseph and Biderman, Stella and Garriga-Alonso, Adrià and Conmy, Arthur and Nanda, Neel and Rumbelow, Jessica and Wattenberg, Martin and Schoots, Nandi and Miller, Joseph and Michaud, Eric J. and Casper, Stephen and Tegmark, Max and Saunders, William and Bau, David and Todd, Eric and Geiger, Atticus and Geva, Mor and Hoogland, Jesse and Murfet, Daniel and McGrath, Thomas},
  title = {{Open Problems in Mechanistic Interpretability}},
  journal = {arXiv.org},
  year = {2025},
  doi = {10.48550/arXiv.2501.16496},
  eprint = {2501.16496},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Open Problems in Mechanistic Interpretability... Abstract: Mechanistic interpretability aims to understand the computational mechanisms underlying neural networks' capabilities in order to accomplish concrete ...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@inproceedings{sun2024redeep:,
  author = {Sun, ZhongXiang and Zang, Xiaoxue and Zheng, Kai and Song, Yang and Xu, Jun and Zhang, Xiao and Yu, Weijie and Li, Han},
  title = {{ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability}},
  booktitle = {International Conference on Learning Representations},
  year = {2024},
  doi = {10.48550/arXiv.2410.11414},
  eprint = {2410.11414},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze ReDeEP: Detecting Hallucination in Retrieval-Augme... Abstract: Retrieval-Augmented Generation (RAG) models are designed to incorporate external knowledge, reducing hallucinations caused by insufficient parametric ...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{liu2023seeing,
  author = {Liu, Ziming and Gan, Eric and Tegmark, Max},
  title = {{Seeing is Believing: Brain-Inspired Modular Training for Mechanistic Interpretability}},
  journal = {arXiv.org},
  year = {2023},
  doi = {10.48550/arXiv.2305.08746},
  eprint = {2305.08746},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Seeing is Believing: Brain-Inspired Modular Traini... Abstract: We introduce Brain-Inspired Modular Training (BIMT), a method for making neural networks more modular and interpretable. Inspired by brains, BIMT embe...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@inproceedings{palit2023vision-language,
  author = {Palit, Vedant and Pandey, Rohan and Arora, Aryaman and Liang, Paul Pu},
  title = {{Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP}},
  booktitle = {2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)},
  year = {2023},
  doi = {10.1109/ICCVW60793.2023.00307},
  eprint = {2308.14179},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Towards Vision-Language Mechanistic Interpretabili... Abstract: Mechanistic interpretability seeks to understand the neural mechanisms that enable specific behaviors in Large Language Models (LLMs) by leveraging ca...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{he2024dictionary,
  author = {He, Zhengfu and Ge, Xuyang and Tang, Qiong and Sun, Tianxiang and Cheng, Qinyuan and Qiu, Xipeng},
  title = {{Dictionary Learning Improves Patch-Free Circuit Discovery in Mechanistic Interpretability: A Case Study on Othello-GPT}},
  journal = {arXiv.org},
  year = {2024},
  doi = {10.48550/arXiv.2402.12201},
  eprint = {2402.12201},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Dictionary Learning Improves Patch-Free Circuit Di... Abstract: Sparse dictionary learning has been a rapidly growing technique in mechanistic interpretability to attack superposition and extract more human-underst...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{kästner2024explaining,
  author = {Kästner, Lena and Crook, Barnaby},
  title = {{Explaining AI through mechanistic interpretability}},
  journal = {European Journal for Philosophy of Science},
  year = {2024},
  doi = {10.1007/s13194-024-00614-4},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Explaining AI through mechanistic interpretability... Abstract: Recent work in explainable artificial intelligence (XAI) attempts to render opaque AI systems understandable through a divide-and-conquer strategy. Ho...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{zimmermann2023scale,
  author = {Zimmermann, Roland S. and Klein, Thomas and Brendel, Wieland},
  title = {{Scale Alone Does not Improve Mechanistic Interpretability in Vision Models}},
  journal = {Neural Information Processing Systems},
  year = {2023},
  doi = {10.48550/arXiv.2307.05471},
  eprint = {2307.05471},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Scale Alone Does not Improve Mechanistic Interpret... Abstract: In light of the recent widespread adoption of AI systems, understanding the internal information processing of neural networks has become increasingly...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, High}
}

@article{michaud2024opening,
  author = {Michaud, Eric J. and Liao, Isaac and Lad, Vedang and Liu, Ziming and Mudide, Anish and Loughridge, Chloe and Guo, Zifan Carl and Kheirkhah, Tara Rezaei and Vukeli'c, Mateja and Tegmark, Max},
  title = {{Opening the AI black box: program synthesis via mechanistic interpretability}},
  journal = {arXiv.org},
  year = {2024},
  doi = {10.48550/arXiv.2402.05110},
  eprint = {2402.05110},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Opening the AI black box: program synthesis via me... Abstract: We present MIPS, a novel method for program synthesis based on automated mechanistic interpretability of neural networks trained to perform the desire...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

@inproceedings{pearce2024bilinear,
  author = {Pearce, Michael T. and Dooms, Thomas and Rigg, Alice and Oramas, José and Sharkey, Lee},
  title = {{Bilinear MLPs enable weight-based mechanistic interpretability}},
  booktitle = {International Conference on Learning Representations},
  year = {2024},
  doi = {10.48550/arXiv.2410.08417},
  eprint = {2410.08417},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Bilinear MLPs enable weight-based mechanistic inte... Abstract: A mechanistic understanding of how MLPs do computation in deep neural networks remains elusive. Current interpretability work can extract features fro...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

@inproceedings{men2024unlocking,
  author = {Men, Tianyi and Cao, Pengfei and Jin, Zhuoran and Chen, Yubo and Liu, Kang and Zhao, Jun},
  title = {{Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models}},
  booktitle = {Conference on Empirical Methods in Natural Language Processing},
  year = {2024},
  doi = {10.48550/arXiv.2406.16033},
  eprint = {2406.16033},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Unlocking the Future: Exploring Look-Ahead Plannin... Abstract: Planning, as the core module of agents, is crucial in various fields such as embodied agents, web navigation, and tool using. With the development of ...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

@inproceedings{garc'ia-carrasco2024gpt-2,
  author = {Garc'ia-Carrasco, Jorge and Mat'e, Alejandro and Trujillo, Juan},
  title = {{How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability}},
  booktitle = {International Conference on Artificial Intelligence and Statistics},
  year = {2024},
  doi = {10.48550/arXiv.2405.04156},
  eprint = {2405.04156},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze How does GPT-2 Predict Acronyms? Extracting and Un... Abstract: Transformer-based language models are treated as black-boxes because of their large number of parameters and complex internal interactions, which is a...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

@article{golovanevsky2024notice?,
  author = {Golovanevsky, Michal and Rudman, William and Palit, Vedant and Singh, Ritambhara and Eickhoff, Carsten},
  title = {{What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for Noise-free Text-Image Corruption and Evaluation}},
  journal = {North American Chapter of the Association for Computational Linguistics},
  year = {2024},
  doi = {10.48550/arXiv.2406.16320},
  eprint = {2406.16320},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze What Do VLMs NOTICE? A Mechanistic Interpretabilit... Abstract: Vision-Language Models (VLMs) have gained community-spanning prominence due to their ability to integrate visual and textual inputs to perform complex...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

@article{bushnaq2024degeneracy,
  author = {Bushnaq, Lucius and Mendel, Jake and Heimersheim, Stefan and Braun, Dan and Goldowsky-Dill, Nicholas and Hänni, Kaarel and Wu, Cindy and Hobbhahn, Marius},
  title = {{Using Degeneracy in the Loss Landscape for Mechanistic Interpretability}},
  journal = {arXiv.org},
  year = {2024},
  doi = {10.48550/arXiv.2405.10927},
  eprint = {2405.10927},
  archivePrefix = {arXiv},
  note = {
CORE ARGUMENT: [TEMPLATE: Analyze Using Degeneracy in the Loss Landscape for Mechani... Abstract: Mechanistic Interpretability aims to reverse engineer the algorithms implemented by neural networks by studying their weights and activations. An obst...]

RELEVANCE: [TEMPLATE: Connect to MI definition and safety relevance]

POSITION: [TEMPLATE: Identify position in MI landscape]
},
  keywords = {mechanistic-interpretability, Medium}
}

% End of Domain 1 bibliography
