[search_philpapers.py] Searching PhilPapers: 'AI safety', limit=20
[search_philpapers.py] Retrieved 11 entries...
[search_philpapers.py] Search complete: 11 entries found
{
  "status": "success",
  "source": "philpapers_via_brave",
  "query": "AI safety",
  "results": [
    {
      "title": "Eleni Angelou, Artificial Intelligence Safety as an Emerging Paradigm",
      "url": "https://philpapers.org/rec/ANGAIS-2",
      "philpapers_id": "ANGAIS",
      "snippet": "Artificial Intelligence (AI) safety is an interdisciplinary field undergoing transformation to become its own paradigm. By adopting a Kuhnian approach to this transformation, I seek to describe the features that make ...",
      "page_age": null
    },
    {
      "title": "Jacqueline Harding & Cameron Domenico Kirk-Giannini, What is AI safety? What do we want it to be?",
      "url": "https://philpapers.org/rec/HARWIA-15",
      "philpapers_id": "HARWIA",
      "snippet": "The field of AI safety seeks to prevent or reduce the harms caused by AI systems. A simple and appealing account of what is distinctive of AI safety as a field ...",
      "page_age": null
    },
    {
      "title": "William D'Alessandro & Cameron Domenico Kirk-Giannini, Artificial Intelligence: Approaches to Safety",
      "url": "https://philpapers.org/rec/DALAIA-2",
      "philpapers_id": "DALAIA",
      "snippet": "AI safety is an interdisciplinary field focused on mitigating the harms caused by AI systems. We review a range of research directions in AI safety, focusing on those to which philosophers have made or are in a position to make the most significant ...",
      "page_age": null
    },
    {
      "title": "Thomas Metcalf, AI safety and regulatory capture",
      "url": "https://philpapers.org/rec/METASA-5",
      "philpapers_id": "METASA",
      "snippet": "Researchers, politicians, and the general public support safety regulations on the production and use of AI technology. Yet regulations on new technology are susceptible to the harmful phenomenon of regulatory capture, ...",
      "page_age": null
    },
    {
      "title": "Erich Riesen, A sociotechnological-system approach to AI ethics",
      "url": "https://philpapers.org/rec/RIEASA-3",
      "philpapers_id": "RIEASA",
      "snippet": "In contrast, the sociotechnological approach coheres with actual progress being made on AI safety (e.g., networking, shared user-artifact control, and value alignment) and makes vivid solutions to the safety problem that do not require the creation of humnanlike moral decision-makers.",
      "page_age": null
    },
    {
      "title": "Robert Long, Jeff Sebo & Toni Sims, Is there a tension between AI safety and AI welfare?",
      "url": "https://philpapers.org/rec/LONITA-6",
      "philpapers_id": "LONITA",
      "snippet": "The field of AI safety considers whether and how AI development can be safe and beneficial for humans and other animals, and the field of AI welfare considers whether and how AI development can be safe and beneficial for AI systems.",
      "page_age": null
    },
    {
      "title": "Herman Cappelen, Josh Dever & John Hawthorne, AI safety: a climb to Armageddon?",
      "url": "https://philpapers.org/rec/CAPASA-5",
      "philpapers_id": "CAPASA",
      "snippet": "The paper examines three response strategies: Optimism, Mitigation, and Holism. Each faces challenges stemming from intrinsic features of the AI safety landscape that we term Bottlenecking, the Perfection Barrier, and Equilibrium Fluctuation.",
      "page_age": null
    },
    {
      "title": "Leonard Dung & Florian Mai, AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?",
      "url": "https://philpapers.org/rec/DUNAAS",
      "philpapers_id": "DUNAAS",
      "snippet": "AI alignment research aims to develop techniques to ensure that AI systems do not cause harm. However, every alignment technique has failure modes, which are conditions in which there is a non-negligible chance that the technique fails to provide safety.",
      "page_age": null
    },
    {
      "title": "Erich Riesen & Mark Boespflug, Aligning with Ideal Values: A Proposal for Anchoring AI in Moral Expertise",
      "url": "https://philpapers.org/rec/RIEAWI",
      "philpapers_id": "RIEAWI",
      "snippet": "Autonomous AI agents are increasingly required to operate in contexts where human welfare is at stake, raising the imperative for them to act in ways that are morally optimal\u2014or at least morally permissible.",
      "page_age": null
    },
    {
      "title": "Leonard Dung, Saving Artificial Minds: Understanding and Preventing AI Suffering",
      "url": "https://philpapers.org/rec/DUNSAM-3",
      "philpapers_id": "DUNSAM",
      "snippet": "This is the first book to investigate the nature and extent of artificial intelligence (AI) suffering risks. It argues that AI suffering risk is a serious near-term concern and analyzes approaches for addressing it.",
      "page_age": null
    },
    {
      "title": "Herman Cappelen & Josh Dever, Making AI Intelligible: Philosophical Foundations",
      "url": "https://philpapers.org/rec/CAPMAI",
      "philpapers_id": "CAPMAI",
      "snippet": "AI Rights for Human Safety.Peter Salib &amp; Simon Goldstein - manuscript",
      "page_age": null
    }
  ],
  "count": 11,
  "errors": []
}
