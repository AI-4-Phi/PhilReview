[search_arxiv.py] Searching arXiv: 'all:AI safety alignment AND cat:cs.AI' (category=cs.AI), limit=30
[search_arxiv.py] Search complete: 30 papers found
[search_arxiv.py] Cached results (cache key: arxiv_e28fdc82feea422e)
{
  "status": "success",
  "source": "arxiv",
  "query": "all:AI safety alignment AND cat:cs.AI",
  "results": [
    {
      "arxiv_id": "2512.17902",
      "title": "Adversarial Robustness of Vision in Open Foundation Models",
      "authors": [
        "Jonathon Fox",
        "William J Buchanan",
        "Pavlos Papadopoulos"
      ],
      "abstract": "With the increase in deep learning, it becomes increasingly difficult to understand the model in which AI systems can identify objects. Thus, an adversary could aim to modify an image by adding unseen elements, which will confuse the AI in its recognition of an entity. This paper thus investigates the adversarial robustness of LLaVA-1.5-13B and Meta's Llama 3.2 Vision-8B-2. These are tested for untargeted PGD (Projected Gradient Descent) against the visual input modality, and empirically evaluated on the Visual Question Answering (VQA) v2 dataset subset. The results of these adversarial attacks are then quantified using the standard VQA accuracy metric. This evaluation is then compared with the accuracy degradation (accuracy drop) of LLaVA and Llama 3.2 Vision. A key finding is that Llama 3.2 Vision, despite a lower baseline accuracy in this setup, exhibited a smaller drop in performance under attack compared to LLaVA, particularly at higher perturbation levels. Overall, the findings confirm that the vision modality represents a viable attack vector for degrading the performance of contemporary open-weight VLMs, including Meta's Llama 3.2 Vision. Furthermore, they highlight that adversarial robustness does not necessarily correlate directly with standard benchmark performance and may be influenced by underlying architectural and training factors.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "doi": "10.1109/ACCESS.2025.3645997",
      "journal_ref": "IEEE Access, 2025",
      "pdf_url": "https://arxiv.org/pdf/2512.17902v1",
      "url": "https://arxiv.org/abs/2512.17902"
    },
    {
      "arxiv_id": "2512.17898",
      "title": "Humanlike AI Design Increases Anthropomorphism but Yields Divergent Outcomes on Engagement and Trust Globally",
      "authors": [
        "Robin Schimmelpfennig",
        "Mark D\u00edaz",
        "Vinodkumar Prabhakaran",
        "Aida Davani"
      ],
      "abstract": "Over a billion users across the globe interact with AI systems engineered with increasing sophistication to mimic human traits. This shift has triggered urgent debate regarding Anthropomorphism, the attribution of human characteristics to synthetic agents, and its potential to induce misplaced trust or emotional dependency. However, the causal link between more humanlike AI design and subsequent effects on engagement and trust has not been tested in realistic human-AI interactions with a global user pool. Prevailing safety frameworks continue to rely on theoretical assumptions derived from Western populations, overlooking the global diversity of AI users. Here, we address these gaps through two large-scale cross-national experiments (N=3,500) across 10 diverse nations, involving real-time and open-ended interactions with an AI system. We find that when evaluating an AI's human-likeness, users focus less on the kind of theoretical aspects often cited in policy (e.g., sentience or consciousness), but rather applied, interactional cues like conversation flow or understanding the user's perspective. We also experimentally demonstrate that humanlike design levers can causally increase anthropomorphism among users; however, we do not find that humanlike design universally increases behavioral measures for user engagement and trust, as previous theoretical work suggests. Instead, part of the connection between human-likeness and behavioral outcomes is fractured by culture: specific design choices that foster self-reported trust in AI-systems in some populations (e.g., Brazil) may trigger the opposite result in others (e.g., Japan). Our findings challenge prevailing narratives of inherent risk in humanlike AI design. Instead, we identify a nuanced, culturally mediated landscape of human-AI interaction, which demands that we move beyond a one-size-fits-all approach in AI governance.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17898v1",
      "url": "https://arxiv.org/abs/2512.17898"
    },
    {
      "arxiv_id": "2512.17897",
      "title": "RadarGen: Automotive Radar Point Cloud Generation from Cameras",
      "authors": [
        "Tomer Borreda",
        "Fangqiang Ding",
        "Sanja Fidler",
        "Shengyu Huang",
        "Or Litany"
      ],
      "abstract": "We present RadarGen, a diffusion model for synthesizing realistic automotive radar point clouds from multi-view camera imagery. RadarGen adapts efficient image-latent diffusion to the radar domain by representing radar measurements in bird's-eye-view form that encodes spatial structure together with radar cross section (RCS) and Doppler attributes. A lightweight recovery step reconstructs point clouds from the generated maps. To better align generation with the visual scene, RadarGen incorporates BEV-aligned depth, semantic, and motion cues extracted from pretrained foundation models, which guide the stochastic generation process toward physically plausible radar patterns. Conditioning on images makes the approach broadly compatible, in principle, with existing visual datasets and simulation frameworks, offering a scalable direction for multimodal generative simulation. Evaluations on large-scale driving data show that RadarGen captures characteristic radar measurement distributions and reduces the gap to perception models trained on real data, marking a step toward unified generative simulation across sensing modalities.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17897v1",
      "url": "https://arxiv.org/abs/2512.17897"
    },
    {
      "arxiv_id": "2512.17896",
      "title": "XAgen: An Explainability Tool for Identifying and Correcting Failures in Multi-Agent Workflows",
      "authors": [
        "Xinru Wang",
        "Ming Yin",
        "Eunyee Koh",
        "Mustafa Doga Dogan"
      ],
      "abstract": "As multi-agent systems powered by Large Language Models (LLMs) are increasingly adopted in real-world workflows, users with diverse technical backgrounds are now building and refining their own agentic processes. However, these systems can fail in opaque ways, making it difficult for users to observe, understand, and correct errors. We conducted formative interviews with 12 practitioners to identify mismatches between existing observability tools and users' needs. Based on these insights, we designed XAgen, an explainability tool that supports users with varying AI expertise through three core capabilities: log visualization for glanceable workflow understanding, human-in-the-loop feedback to capture expert judgment, and automatic error detection via an LLM-as-a-judge. In a user study with 8 participants, XAgen helped users more easily locate failures, attribute to specific agents or steps, and iteratively improve configurations. Our findings surface human-centered design guidelines for explainable agentic AI development and highlights opportunities for more context-aware interactive debugging.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17896v1",
      "url": "https://arxiv.org/abs/2512.17896"
    },
    {
      "arxiv_id": "2512.17883",
      "title": "Map2Video: Street View Imagery Driven AI Video Generation",
      "authors": [
        "Hye-Young Jo",
        "Mose Sakashita",
        "Aditi Mishra",
        "Ryo Suzuki",
        "Koichiro Niinuma",
        "Aakar Gupta"
      ],
      "abstract": "AI video generation has lowered barriers to video creation, but current tools still struggle with inconsistency. Filmmakers often find that clips fail to match characters and backgrounds, making it difficult to build coherent sequences. A formative study with filmmakers highlighted challenges in shot composition, character motion, and camera control. We present Map2Video, a street view imagery-driven AI video generation tool grounded in real-world geographies. The system integrates Unity and ComfyUI with the VACE video generation model, as well as OpenStreetMap and Mapillary for street view imagery. Drawing on familiar filmmaking practices such as location scouting and rehearsal, Map2Video enables users to choose map locations, position actors and cameras in street view imagery, sketch movement paths, refine camera motion, and generate spatially consistent videos. We evaluated Map2Video with 12 filmmakers. Compared to an image-to-video baseline, it achieved higher spatial accuracy, required less cognitive effort, and offered stronger controllability for both scene replication and open-ended creative exploration.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.HC",
      "categories": [
        "cs.HC"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17883v1",
      "url": "https://arxiv.org/abs/2512.17883"
    },
    {
      "arxiv_id": "2512.17864",
      "title": "Interpretable Plant Leaf Disease Detection Using Attention-Enhanced CNN",
      "authors": [
        "Balram Singh",
        "Ram Prakash Sharma",
        "Somnath Dey"
      ],
      "abstract": "Plant diseases pose a significant threat to global food security, necessitating accurate and interpretable disease detection methods. This study introduces an interpretable attention-guided Convolutional Neural Network (CNN), CBAM-VGG16, for plant leaf disease detection. By integrating Convolution Block Attention Module (CBAM) at each convolutional stage, the model enhances feature extraction and disease localization. Trained on five diverse plant disease datasets, our approach outperforms recent techniques, achieving high accuracy (up to 98.87%) and demonstrating robust generalization. Here, we show the effectiveness of our method through comprehensive evaluation and interpretability analysis using CBAM attention maps, Grad-CAM, Grad-CAM++, and Layer-wise Relevance Propagation (LRP). This study advances the application of explainable AI in agricultural diagnostics, offering a transparent and reliable system for smart farming. The code of our proposed work is available at https://github.com/BS0111/PlantAttentionCBAM.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17864v1",
      "url": "https://arxiv.org/abs/2512.17864"
    },
    {
      "arxiv_id": "2512.17851",
      "title": "InfSplign: Inference-Time Spatial Alignment of Text-to-Image Diffusion Models",
      "authors": [
        "Sarah Rastegar",
        "Violeta Chatalbasheva",
        "Sieger Falkena",
        "Anuj Singh",
        "Yanbo Wang",
        "Tejas Gokhale",
        "Hamid Palangi",
        "Hadi Jamali-Rad"
      ],
      "abstract": "Text-to-image (T2I) diffusion models generate high-quality images but often fail to capture the spatial relations specified in text prompts. This limitation can be traced to two factors: lack of fine-grained spatial supervision in training data and inability of text embeddings to encode spatial semantics. We introduce InfSplign, a training-free inference-time method that improves spatial alignment by adjusting the noise through a compound loss in every denoising step. Proposed loss leverages different levels of cross-attention maps extracted from the backbone decoder to enforce accurate object placement and a balanced object presence during sampling. The method is lightweight, plug-and-play, and compatible with any diffusion backbone. Our comprehensive evaluations on VISOR and T2I-CompBench show that InfSplign establishes a new state-of-the-art (to the best of our knowledge), achieving substantial performance gains over the strongest existing inference-time baselines and even outperforming the fine-tuning-based methods. Codebase is available at GitHub.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17851v1",
      "url": "https://arxiv.org/abs/2512.17851"
    },
    {
      "arxiv_id": "2512.17850",
      "title": "Integrating Computational Methods and AI into Qualitative Studies of Aging and Later Life",
      "authors": [
        "Corey M. Abramson"
      ],
      "abstract": "This chapter demonstrates how computational social science (CSS) tools are extending and expanding research on aging. The depth and context from traditionally qualitative methods such as participant observation, in-depth interviews, and historical documents are increasingly employed alongside scalable data management, computational text analysis, and open-science practices. Machine learning (ML) and natural language processing (NLP), provide resources to aggregate and systematically index large volumes of qualitative data, identify patterns, and maintain clear links to in-depth accounts. Drawing on case studies of projects that examine later life--including examples with original data from the DISCERN study (a team-based ethnography of life with dementia) and secondary analyses of the American Voices Project (nationally representative interview)--the chapter highlights both uses and challenges of bringing CSS tools into more meaningful dialogue with qualitative aging research. The chapter argues such work has potential for (1) streamlining and augmenting existing workflows, (2) scaling up samples and projects, and (3) generating multi-method approaches to address important questions in new ways, before turning to practices useful for individuals and teams seeking to understand current possibilities or refine their workflow processes. The chapter concludes that current developments are not without peril, but offer potential for new insights into aging and the life course by broadening--rather than replacing--the methodological foundations of qualitative research.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17850v1",
      "url": "https://arxiv.org/abs/2512.17850"
    },
    {
      "arxiv_id": "2512.17841",
      "title": "NeuRehab: A Reinforcement Learning and Spiking Neural Network-Based Rehab Automation Framework",
      "authors": [
        "Phani Pavan Kambhampati",
        "Chainesh Gautam",
        "Jagan Palaniswamy",
        "Madhav Rao"
      ],
      "abstract": "Recent advancements in robotic rehabilitation therapy have provided modular exercise systems for post-stroke muscle recovery with basic control schemes. But these systems struggle to adapt to patients' complex and ever-changing behaviour, and to operate within mobile settings, such as heat and power. To aid this, we present NeuRehab: an end-to-end framework consisting of a training and inference pipeline with AI-based automation, co-designed with neuromorphic computing-based control systems that balance action performance, power consumption, and observed latency. The framework consists of 2 partitions. One is designated for the rehabilitation device based on ultra-low power spiking networks deployed on dedicated neuromorphic hardware. The other resides on stationary hardware that can accommodate computationally intensive hardware for fine-tuning on a per-patient basis. By maintaining a communication channel between both the modules and splitting the algorithm components, the power and latency requirements of the movable system have been optimised, while retaining the learning performance advantages of compute- and power-hungry hardware on the stationary machine. As part of the framework, we propose (a) the split machine learning processes for efficiency in architectural utilisation, and (b) task-specific temporal optimisations to lower edge-inference control latency. This paper evaluates the proposed methods on a reference stepper motor-based shoulder exercise. Overall, these methods offer comparable performance uplifts over the State-of-the-art for neuromorphic deployment, while achieving over 60% savings in both power and latency during inference compared to standard implementations.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CE",
      "categories": [
        "cs.CE",
        "eess.SY"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17841v1",
      "url": "https://arxiv.org/abs/2512.17841"
    },
    {
      "arxiv_id": "2512.17838",
      "title": "ReX-MLE: The Autonomous Agent Benchmark for Medical Imaging Challenges",
      "authors": [
        "Roshan Kenia",
        "Xiaoman Zhang",
        "Pranav Rajpurkar"
      ],
      "abstract": "Autonomous coding agents built on large language models (LLMs) can now solve many general software and machine learning tasks, but they remain ineffective on complex, domain-specific scientific problems. Medical imaging is a particularly demanding domain, requiring long training cycles, high-dimensional data handling, and specialized preprocessing and validation pipelines, capabilities not fully measured in existing agent benchmarks. To address this gap, we introduce ReX-MLE, a benchmark of 20 challenges derived from high-impact medical imaging competitions spanning diverse modalities and task types. Unlike prior ML-agent benchmarks, ReX-MLE evaluates full end-to-end workflows, requiring agents to independently manage data preprocessing, model training, and submission under realistic compute and time constraints. Evaluating state-of-the-art agents (AIDE, ML-Master, R&D-Agent) with different LLM backends (GPT-5, Gemini, Claude), we observe a severe performance gap: most submissions rank in the 0th percentile compared to human experts. Failures stem from domain-knowledge and engineering limitations. ReX-MLE exposes these bottlenecks and provides a foundation for developing domain-aware autonomous AI systems.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17838v1",
      "url": "https://arxiv.org/abs/2512.17838"
    },
    {
      "arxiv_id": "2512.17795",
      "title": "Intelligent Knowledge Mining Framework: Bridging AI Analysis and Trustworthy Preservation",
      "authors": [
        "Binh Vu"
      ],
      "abstract": "The unprecedented proliferation of digital data presents significant challenges in access, integration, and value creation across all data-intensive sectors. Valuable information is frequently encapsulated within disparate systems, unstructured documents, and heterogeneous formats, creating silos that impede efficient utilization and collaborative decision-making. This paper introduces the Intelligent Knowledge Mining Framework (IKMF), a comprehensive conceptual model designed to bridge the critical gap between dynamic AI-driven analysis and trustworthy long-term preservation. The framework proposes a dual-stream architecture: a horizontal Mining Process that systematically transforms raw data into semantically rich, machine-actionable knowledge, and a parallel Trustworthy Archiving Stream that ensures the integrity, provenance, and computational reproducibility of these assets. By defining a blueprint for this symbiotic relationship, the paper provides a foundational model for transforming static repositories into living ecosystems that facilitate the flow of actionable intelligence from producers to consumers. This paper outlines the motivation, problem statement, and key research questions guiding the research and development of the framework, presents the underlying scientific methodology, and details its conceptual design and modeling.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.DL",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.IR"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17795v1",
      "url": "https://arxiv.org/abs/2512.17795"
    },
    {
      "arxiv_id": "2512.17793",
      "title": "Systemic Risks of Interacting AI",
      "authors": [
        "Paul Darius",
        "Thomas Hoppe",
        "Andrei Aleksandrov"
      ],
      "abstract": "In this study, we investigate system-level emergent risks of interacting AI agents. The core contribution of this work is an exploratory scenario-based identification of these risks as well as their categorization. We consider a multitude of systemic risk examples from existing literature and develop two scenarios demonstrating emergent risk patterns in domains of smart grid and social welfare. We provide a taxonomy of identified risks that categorizes them in different groups. In addition, we make two other important contributions: first, we identify what emergent behavior types produce systemic risks, and second, we develop a graphical language \"Agentology\" for visualization of interacting AI systems. Our study opens a new research direction for system-level risks of interacting AI, and is the first to closely investigate them.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17793v1",
      "url": "https://arxiv.org/abs/2512.17793"
    },
    {
      "arxiv_id": "2512.17762",
      "title": "Can You Hear Me Now? A Benchmark for Long-Range Graph Propagation",
      "authors": [
        "Luca Miglior",
        "Matteo Tolloso",
        "Alessio Gravina",
        "Davide Bacciu"
      ],
      "abstract": "Effectively capturing long-range interactions remains a fundamental yet unresolved challenge in graph neural network (GNN) research, critical for applications across diverse fields of science. To systematically address this, we introduce ECHO (Evaluating Communication over long HOps), a novel benchmark specifically designed to rigorously assess the capabilities of GNNs in handling very long-range graph propagation. ECHO includes three synthetic graph tasks, namely single-source shortest paths, node eccentricity, and graph diameter, each constructed over diverse and structurally challenging topologies intentionally designed to introduce significant information bottlenecks. ECHO also includes two real-world datasets, ECHO-Charge and ECHO-Energy, which define chemically grounded benchmarks for predicting atomic partial charges and molecular total energies, respectively, with reference computations obtained at the density functional theory (DFT) level. Both tasks inherently depend on capturing complex long-range molecular interactions. Our extensive benchmarking of popular GNN architectures reveals clear performance gaps, emphasizing the difficulty of true long-range propagation and highlighting design choices capable of overcoming inherent limitations. ECHO thereby sets a new standard for evaluating long-range information propagation, also providing a compelling example for its need in AI for science.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17762v1",
      "url": "https://arxiv.org/abs/2512.17762"
    },
    {
      "arxiv_id": "2512.17752",
      "title": "Affect, Body, Cognition, Demographics, and Emotion: The ABCDE of Text Features for Computational Affective Science",
      "authors": [
        "Jan Philip Wahle",
        "Krishnapriya Vishnubhotla",
        "Bela Gipp",
        "Saif M. Mohammad"
      ],
      "abstract": "Work in Computational Affective Science and Computational Social Science explores a wide variety of research questions about people, emotions, behavior, and health. Such work often relies on language data that is first labeled with relevant information, such as the use of emotion words or the age of the speaker. Although many resources and algorithms exist to enable this type of labeling, discovering, accessing, and using them remains a substantial impediment, particularly for practitioners outside of computer science. Here, we present the ABCDE dataset (Affect, Body, Cognition, Demographics, and Emotion), a large-scale collection of over 400 million text utterances drawn from social media, blogs, books, and AI-generated sources. The dataset is annotated with a wide range of features relevant to computational affective and social science. ABCDE facilitates interdisciplinary research across numerous fields, including affective science, cognitive science, the digital humanities, sociology, political science, and computational linguistics.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17752v1",
      "url": "https://arxiv.org/abs/2512.17752"
    },
    {
      "arxiv_id": "2512.17724",
      "title": "SAVeD: A First-Person Social Media Video Dataset for ADAS-equipped vehicle Near-Miss and Crash Event Analyses",
      "authors": [
        "Shaoyan Zhai",
        "Mohamed Abdel-Aty",
        "Chenzhu Wang",
        "Rodrigo Vena Garcia"
      ],
      "abstract": "The advancement of safety-critical research in driving behavior in ADAS-equipped vehicles require real-world datasets that not only include diverse traffic scenarios but also capture high-risk edge cases such as near-miss events and system failures. However, existing datasets are largely limited to either simulated environments or human-driven vehicle data, lacking authentic ADAS (Advanced Driver Assistance System) vehicle behavior under risk conditions. To address this gap, this paper introduces SAVeD, a large-scale video dataset curated from publicly available social media content, explicitly focused on ADAS vehicle-related crashes, near-miss incidents, and disengagements. SAVeD features 2,119 first-person videos, capturing ADAS vehicle operations in diverse locations, lighting conditions, and weather scenarios. The dataset includes video frame-level annotations for collisions, evasive maneuvers, and disengagements, enabling analysis of both perception and decision-making failures. We demonstrate SAVeD's utility through multiple analyses and contributions: (1) We propose a novel framework integrating semantic segmentation and monocular depth estimation to compute real-time Time-to-Collision (TTC) for dynamic objects. (2) We utilize the Generalized Extreme Value (GEV) distribution to model and quantify the extreme risk in crash and near-miss events across different roadway types. (3) We establish benchmarks for state-of-the-art VLLMs (VideoLLaMA2 and InternVL2.5 HiCo R16), showing that SAVeD's detailed annotations significantly enhance model performance through domain adaptation in complex near-miss scenarios.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17724v1",
      "url": "https://arxiv.org/abs/2512.17724"
    },
    {
      "arxiv_id": "2512.17677",
      "title": "Toward Ethical AI Through Bayesian Uncertainty in Neural Question Answering",
      "authors": [
        "Riccardo Di Sipio"
      ],
      "abstract": "We explore Bayesian reasoning as a means to quantify uncertainty in neural networks for question answering. Starting with a multilayer perceptron on the Iris dataset, we show how posterior inference conveys confidence in predictions. We then extend this to language models, applying Bayesian inference first to a frozen head and finally to LoRA-adapted transformers, evaluated on the CommonsenseQA benchmark. Rather than aiming for state-of-the-art accuracy, we compare Laplace approximations against maximum a posteriori (MAP) estimates to highlight uncertainty calibration and selective prediction. This allows models to abstain when confidence is low. An ``I don't know'' response not only improves interpretability but also illustrates how Bayesian methods can contribute to more responsible and ethical deployment of neural question-answering systems.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "doi": "10.1007/s43681-025-00838-x",
      "journal_ref": "AI Ethics 6, 38 (2026)",
      "pdf_url": "https://arxiv.org/pdf/2512.17677v1",
      "url": "https://arxiv.org/abs/2512.17677"
    },
    {
      "arxiv_id": "2512.17667",
      "title": "STAR: Semantic-Traffic Alignment and Retrieval for Zero-Shot HTTPS Website Fingerprinting",
      "authors": [
        "Yifei Cheng",
        "Yujia Zhu",
        "Baiyang Li",
        "Xinhao Deng",
        "Yitong Cai",
        "Yaochen Ren",
        "Qingyun Liu"
      ],
      "abstract": "Modern HTTPS mechanisms such as Encrypted Client Hello (ECH) and encrypted DNS improve privacy but remain vulnerable to website fingerprinting (WF) attacks, where adversaries infer visited sites from encrypted traffic patterns. Existing WF methods rely on supervised learning with site-specific labeled traces, which limits scalability and fails to handle previously unseen websites. We address these limitations by reformulating WF as a zero-shot cross-modal retrieval problem and introducing STAR. STAR learns a joint embedding space for encrypted traffic traces and crawl-time logic profiles using a dual-encoder architecture. Trained on 150K automatically collected traffic-logic pairs with contrastive and consistency objectives and structure-aware augmentation, STAR retrieves the most semantically aligned profile for a trace without requiring target-side traffic during training. Experiments on 1,600 unseen websites show that STAR achieves 87.9 percent top-1 accuracy and 0.963 AUC in open-world detection, outperforming supervised and few-shot baselines. Adding an adapter with only four labeled traces per site further boosts top-5 accuracy to 98.8 percent. Our analysis reveals intrinsic semantic-traffic alignment in modern web protocols, identifying semantic leakage as the dominant privacy risk in encrypted HTTPS traffic. We release STAR's datasets and code to support reproducibility and future research.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CR",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17667v1",
      "url": "https://arxiv.org/abs/2512.17667"
    },
    {
      "arxiv_id": "2512.17655",
      "title": "Bitbox: Behavioral Imaging Toolbox for Computational Analysis of Behavior from Videos",
      "authors": [
        "Evangelos Sariyanidi",
        "Gokul Nair",
        "Lisa Yankowitz",
        "Casey J. Zampella",
        "Mohan Kashyap Pargi",
        "Aashvi Manakiwala",
        "Maya McNealis",
        "John D. Herrington",
        "Jeffrey Cohn",
        "Robert T. Schultz",
        "Birkan Tunc"
      ],
      "abstract": "Computational measurement of human behavior from video has recently become feasible due to major advances in AI. These advances now enable granular and precise quantification of facial expression, head movement, body action, and other behavioral modalities and are increasingly used in psychology, psychiatry, neuroscience, and mental health research. However, mainstream adoption remains slow. Most existing methods and software are developed for engineering audiences, require specialized software stacks, and fail to provide behavioral measurements at a level directly useful for hypothesis-driven research. As a result, there is a large barrier to entry for researchers who wish to use modern, AI-based tools in their work. We introduce Bitbox, an open-source toolkit designed to remove this barrier and make advanced computational analysis directly usable by behavioral scientists and clinical researchers. Bitbox is guided by principles of reproducibility, modularity, and interpretability. It provides a standardized interface for extracting high-level behavioral measurements from video, leveraging multiple face, head, and body processors. The core modules have been tested and validated on clinical samples and are designed so that new measures can be added with minimal effort. Bitbox is intended to serve both sides of the translational gap. It gives behavioral researchers access to robust, high-level behavioral metrics without requiring engineering expertise, and it provides computer scientists a practical mechanism for disseminating methods to domains where their impact is most needed. We expect that Bitbox will accelerate integration of computational behavioral measurement into behavioral, clinical, and mental health research. Bitbox has been designed from the beginning as a community-driven effort that will evolve through contributions from both method developers and domain scientists.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "q-bio.NC"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17655v1",
      "url": "https://arxiv.org/abs/2512.17655"
    },
    {
      "arxiv_id": "2512.17630",
      "title": "Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection",
      "authors": [
        "Menna Elgabry",
        "Ali Hamdi"
      ],
      "abstract": "This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17630v1",
      "url": "https://arxiv.org/abs/2512.17630"
    },
    {
      "arxiv_id": "2512.17629",
      "title": "SCOPE: Sequential Causal Optimization of Process Interventions",
      "authors": [
        "Jakob De Moor",
        "Hans Weytjens",
        "Johannes De Smedt",
        "Jochen De Weerdt"
      ],
      "abstract": "Prescriptive Process Monitoring (PresPM) recommends interventions during business processes to optimize key performance indicators (KPIs). In realistic settings, interventions are rarely isolated: organizations need to align sequences of interventions to jointly steer the outcome of a case. Existing PresPM approaches fall short in this respect. Many focus on a single intervention decision, while others treat multiple interventions independently, ignoring how they interact over time. Methods that do address these dependencies depend either on simulation or data augmentation to approximate the process to train a Reinforcement Learning (RL) agent, which can create a reality gap and introduce bias. We introduce SCOPE, a PresPM approach that learns aligned sequential intervention recommendations. SCOPE employs backward induction to estimate the effect of each candidate intervention action, propagating its impact from the final decision point back to the first. By leveraging causal learners, our method can utilize observational data directly, unlike methods that require constructing process approximations for reinforcement learning. Experiments on both an existing synthetic dataset and a new semi-synthetic dataset show that SCOPE consistently outperforms state-of-the-art PresPM techniques in optimizing the KPI. The novel semi-synthetic setup, based on a real-life event log, is provided as a reusable benchmark for future work on sequential PresPM.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17629v1",
      "url": "https://arxiv.org/abs/2512.17629"
    },
    {
      "arxiv_id": "2512.17600",
      "title": "STAMP/STPA informed characterization of Factors Leading to Loss of Control in AI Systems",
      "authors": [
        "Steve Barrett",
        "Anna Bruvere",
        "Sean P. Fillingham",
        "Catherine Rhodes",
        "Stefano Vergani"
      ],
      "abstract": "A major concern amongst AI safety practitioners is the possibility of loss of control, whereby humans lose the ability to exert control over increasingly advanced AI systems. The range of concerns is wide, spanning current day risks to future existential risks, and a range of loss of control pathways from rapid AI self-exfiltration scenarios to more gradual disempowerment scenarios. In this work we set out to firstly, provide a more structured framework for discussing and characterizing loss of control and secondly, to use this framework to assist those responsible for the safe operation of AI-containing socio-technical systems to identify causal factors leading to loss of control. We explore how these two needs can be better met by making use of a methodology developed within the safety-critical systems community known as STAMP and its associated hazard analysis technique of STPA. We select the STAMP methodology primarily because it is based around a world-view that socio-technical systems can be functionally modeled as control structures, and that safety issues arise when there is a loss of control in these structures.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17600v1",
      "url": "https://arxiv.org/abs/2512.17600"
    },
    {
      "arxiv_id": "2512.17589",
      "title": "Torrent: A Distributed DMA for Efficient and Flexible Point-to-Multipoint Data Movement",
      "authors": [
        "Yunhao Deng",
        "Fanchen Kong",
        "Xiaoling Yi",
        "Ryan Antonio",
        "Marian Verhelst"
      ],
      "abstract": "The growing disparity between computational power and on-chip communication bandwidth is a critical bottleneck in modern Systems-on-Chip (SoCs), especially for data-parallel workloads like AI. Efficient point-to-multipoint (P2MP) data movement, such as multicast, is essential for high performance. However, native multicast support is lacking in standard interconnect protocols. Existing P2MP solutions, such as multicast-capable Network-on-Chip (NoC), impose additional overhead to the network hardware and require modifications to the interconnect protocol, compromising scalability and compatibility.   This paper introduces Torrent, a novel distributed DMA architecture that enables efficient P2MP data transfers without modifying NoC hardware and interconnect protocol. Torrent conducts P2MP data transfers by forming logical chains over the NoC, where the data traverses through targeted destinations resembling a linked list. This Chainwrite mechanism preserves the P2P nature of every data transfer while enabling flexible data transfers to an unlimited number of destinations. To optimize the performance and energy consumption of Chainwrite, two scheduling algorithms are developed to determine the optimal chain order based on NoC topology.   Our RTL and FPGA prototype evaluations using both synthetic and real workloads demonstrate significant advantages in performance, flexibility, and scalability over network-layer multicast. Compared to the unicast baseline, Torrent achieves up to a 7.88x speedup. ASIC synthesis on 16nm technology confirms the architecture's minimal footprint in area (1.2%) and power (2.3%). Thanks to the Chainwrite, Torrent delivers scalable P2MP data transfers with a small cycle overhead of 82CC and area overhead of 207um2 per destination.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.AR",
      "categories": [
        "cs.AR",
        "cs.DC"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17589v1",
      "url": "https://arxiv.org/abs/2512.17589"
    },
    {
      "arxiv_id": "2512.17586",
      "title": "Learning Safe Autonomous Driving Policies Using Predictive Safety Representations",
      "authors": [
        "Mahesh Keswani",
        "Raunak Bhattacharyya"
      ],
      "abstract": "Safe reinforcement learning (SafeRL) is a prominent paradigm for autonomous driving, where agents are required to optimize performance under strict safety requirements. This dual objective creates a fundamental tension, as overly conservative policies limit driving efficiency while aggressive exploration risks safety violations. The Safety Representations for Safer Policy Learning (SRPL) framework addresses this challenge by equipping agents with a predictive model of future constraint violations and has shown promise in controlled environments. This paper investigates whether SRPL extends to real-world autonomous driving scenarios. Systematic experiments on the Waymo Open Motion Dataset (WOMD) and NuPlan demonstrate that SRPL can improve the reward-safety tradeoff, achieving statistically significant improvements in success rate (effect sizes r = 0.65-0.86) and cost reduction (effect sizes r = 0.70-0.83), with p < 0.05 for observed improvements. However, its effectiveness depends on the underlying policy optimizer and the dataset distribution. The results further show that predictive safety representations play a critical role in improving robustness to observation noise. Additionally, in zero-shot cross-dataset evaluation, SRPL-augmented agents demonstrate improved generalization compared to non-SRPL methods. These findings collectively demonstrate the potential of predictive safety representations to strengthen SafeRL for autonomous driving.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17586v1",
      "url": "https://arxiv.org/abs/2512.17586"
    },
    {
      "arxiv_id": "2512.17584",
      "title": "Optimized Scheduling and Positioning of Mobile Manipulators in Collaborative Applications",
      "authors": [
        "Christian Cella",
        "Sole Ester Sonnino",
        "Marco Faroni",
        "Andrea Zanchettin",
        "Paolo Rocco"
      ],
      "abstract": "The growing integration of mobile robots in shared workspaces requires efficient path planning and coordination between the agents, accounting for safety and productivity. In this work, we propose a digital model-based optimization framework for mobile manipulators in human-robot collaborative environments, in order to determine the sequence of robot base poses and the task scheduling for the robot. The complete problem is treated as black-box, and Particle Swarm Optimization (PSO) is employed to balance conflicting Key-Performance Indicators (KPIs). We demonstrate improvements in cycle time, task sequencing, and adaptation to human presence in a collaborative box-packing scenario.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17584v1",
      "url": "https://arxiv.org/abs/2512.17584"
    },
    {
      "arxiv_id": "2512.17581",
      "title": "Medical Imaging AI Competitions Lack Fairness",
      "authors": [
        "Annika Reinke",
        "Evangelia Christodoulou",
        "Sthuthi Sadananda",
        "A. Emre Kavur",
        "Khrystyna Faryna",
        "Daan Schouten",
        "Bennett A. Landman",
        "Carole Sudre",
        "Olivier Colliot",
        "Nick Heller",
        "Sophie Loizillon",
        "Martin Ma\u0161ka",
        "Ma\u00eblys Solal",
        "Arya Yazdan-Panah",
        "Vilma Bozgo",
        "\u00d6mer S\u00fcmer",
        "Siem de Jong",
        "Sophie Fischer",
        "Michal Kozubek",
        "Tim R\u00e4dsch",
        "Nadim Hammoud",
        "Fruzsina Moln\u00e1r-G\u00e1bor",
        "Steven Hicks",
        "Michael A. Riegler",
        "Anindo Saha",
        "Vajira Thambawita",
        "Pal Halvorsen",
        "Amelia Jim\u00e9nez-S\u00e1nchez",
        "Qingyang Yang",
        "Veronika Cheplygina",
        "Sabrina Bottazzi",
        "Alexander Seitel",
        "Spyridon Bakas",
        "Alexandros Karargyris",
        "Kiran Vaidhya Venkadesh",
        "Bram van Ginneken",
        "Lena Maier-Hein"
      ],
      "abstract": "Benchmarking competitions are central to the development of artificial intelligence (AI) in medical imaging, defining performance standards and shaping methodological progress. However, it remains unclear whether these benchmarks provide data that are sufficiently representative, accessible, and reusable to support clinically meaningful AI. In this work, we assess fairness along two complementary dimensions: (1) whether challenge datasets are representative of real-world clinical diversity, and (2) whether they are accessible and legally reusable in line with the FAIR principles. To address this question, we conducted a large-scale systematic study of 241 biomedical image analysis challenges comprising 458 tasks across 19 imaging modalities. Our findings show substantial biases in dataset composition, including geographic location, modality-, and problem type-related biases, indicating that current benchmarks do not adequately reflect real-world clinical diversity. Despite their widespread influence, challenge datasets were frequently constrained by restrictive or ambiguous access conditions, inconsistent or non-compliant licensing practices, and incomplete documentation, limiting reproducibility and long-term reuse. Together, these shortcomings expose foundational fairness limitations in our benchmarking ecosystem and highlight a disconnect between leaderboard success and clinical relevance.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17581v1",
      "url": "https://arxiv.org/abs/2512.17581"
    },
    {
      "arxiv_id": "2512.17579",
      "title": "On Using Neural Networks to Learn Safety Speed Reduction in Human-Robot Collaboration: A Comparative Analysis",
      "authors": [
        "Marco Faroni",
        "Alessio Span\u00f2",
        "Andrea M. Zanchettin",
        "Paolo Rocco"
      ],
      "abstract": "In Human-Robot Collaboration, safety mechanisms such as Speed and Separation Monitoring and Power and Force Limitation dynamically adjust the robot's speed based on human proximity. While essential for risk reduction, these mechanisms introduce slowdowns that makes cycle time estimation a hard task and impact job scheduling efficiency. Existing methods for estimating cycle times or designing schedulers often rely on predefined safety models, which may not accurately reflect real-world safety implementations, as these depend on case-specific risk assessments. In this paper, we propose a deep learning approach to predict the robot's safety scaling factor directly from process execution data. We analyze multiple neural network architectures and demonstrate that a simple feed-forward network effectively estimates the robot's slowdown. This capability is crucial for improving cycle time predictions and designing more effective scheduling algorithms in collaborative robotic environments.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17579v1",
      "url": "https://arxiv.org/abs/2512.17579"
    },
    {
      "arxiv_id": "2512.17571",
      "title": "Journey Through the World of Dynamical Systems on Networks",
      "authors": [
        "A. Puchalska",
        "M. N. Cartier van Dissel",
        "P. Gora",
        "M. Iskrzy\u0144ski",
        "M. Kramar Fijav\u017e",
        "D. Manea",
        "A. Mauroy",
        "I. Naki\u0107",
        "S. Nicaise",
        "M. B. Paradowski",
        "G. Rotundo",
        "E. Sikolya"
      ],
      "abstract": "We present a subjective selection of methods for complex systems analysis ranging from statistical tools through numerical methods based on AI to both linear and non-linear ODEs and PDEs. All the notions apply the network structure and are presented in the context of applied problems to visualise the strengths and drawbacks of the approach. The major aim of capturing such a broad overview is to understand the interrelations between network theories that seem to be distant from the mathematical perspective.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "math.DS",
      "categories": [
        "math.DS"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17571v1",
      "url": "https://arxiv.org/abs/2512.17571"
    },
    {
      "arxiv_id": "2512.17560",
      "title": "Learning-Based Safety-Aware Task Scheduling for Efficient Human-Robot Collaboration",
      "authors": [
        "M. Faroni",
        "A. Spano",
        "A. M. Zanchettin",
        "P. Rocco"
      ],
      "abstract": "Ensuring human safety in collaborative robotics can compromise efficiency because traditional safety measures increase robot cycle time when human interaction is frequent. This paper proposes a safety-aware approach to mitigate efficiency losses without assuming prior knowledge of safety logic. Using a deep-learning model, the robot learns the relationship between system state and safety-induced speed reductions based on execution data. Our framework does not explicitly predict human motions but directly models the interaction effects on robot speed, simplifying implementation and enhancing generalizability to different safety logics. At runtime, the learned model optimizes task selection to minimize cycle time while adhering to safety requirements. Experiments on a pick-and-packaging scenario demonstrated significant reductions in cycle times.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17560v1",
      "url": "https://arxiv.org/abs/2512.17560"
    },
    {
      "arxiv_id": "2512.17559",
      "title": "Towards Explainable Conversational AI for Early Diagnosis with Large Language Models",
      "authors": [
        "Maliha Tabassum",
        "M Shamim Kaiser"
      ],
      "abstract": "Healthcare systems around the world are grappling with issues like inefficient diagnostics, rising costs, and limited access to specialists. These problems often lead to delays in treatment and poor health outcomes. Most current AI and deep learning diagnostic systems are not very interactive or transparent, making them less effective in real-world, patient-centered environments. This research introduces a diagnostic chatbot powered by a Large Language Model (LLM), using GPT-4o, Retrieval-Augmented Generation, and explainable AI techniques. The chatbot engages patients in a dynamic conversation, helping to extract and normalize symptoms while prioritizing potential diagnoses through similarity matching and adaptive questioning. With Chain-of-Thought prompting, the system also offers more transparent reasoning behind its diagnoses. When tested against traditional machine learning models like Naive Bayes, Logistic Regression, SVM, Random Forest, and KNN, the LLM-based system delivered impressive results, achieving an accuracy of 90% and Top-3 accuracy of 100%. These findings offer a promising outlook for more transparent, interactive, and clinically relevant AI in healthcare.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17559v1",
      "url": "https://arxiv.org/abs/2512.17559"
    },
    {
      "arxiv_id": "2512.17553",
      "title": "Deep Learning-based Robust Autonomous Navigation of Aerial Robots in Dense Forests",
      "authors": [
        "Guglielmo Del Col",
        "V\u00e4in\u00f6 Karjalainen",
        "Teemu Hakala",
        "Yibo Zhang",
        "Eija Honkavaara"
      ],
      "abstract": "Autonomous aerial navigation in dense natural environments remains challenging due to limited visibility, thin and irregular obstacles, GNSS-denied operation, and frequent perceptual degradation. This work presents an improved deep learning-based navigation framework that integrates semantically enhanced depth encoding with neural motion-primitive evaluation for robust flight in cluttered forests. Several modules are incorporated on top of the original sevae-ORACLE algorithm to address limitations observed during real-world deployment, including lateral control for sharper maneuvering, a temporal consistency mechanism to suppress oscillatory planning decisions, a stereo-based visual-inertial odometry solution for drift-resilient state estimation, and a supervisory safety layer that filters unsafe actions in real time. A depth refinement stage is included to improve the representation of thin branches and reduce stereo noise, while GPU optimization increases onboard inference throughput from 4 Hz to 10 Hz.   The proposed approach is evaluated against several existing learning-based navigation methods under identical environmental conditions and hardware constraints. It demonstrates higher success rates, more stable trajectories, and improved collision avoidance, particularly in highly cluttered forest settings. The system is deployed on a custom quadrotor in three boreal forest environments, achieving fully autonomous completion in all flights in moderate and dense clutter, and 12 out of 15 flights in highly dense underbrush. These results demonstrate improved reliability and safety over existing navigation methods in complex natural environments.",
      "published": "2025-12-19",
      "updated": "2025-12-19",
      "primary_category": "cs.RO",
      "categories": [
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2512.17553v1",
      "url": "https://arxiv.org/abs/2512.17553"
    }
  ],
  "count": 30,
  "errors": []
}
