{
  "status": "success",
  "source": "openalex",
  "query": "fairness gerrymandering",
  "results": [
    {
      "openalex_id": "W2768894107",
      "doi": "10.48550/arxiv.1711.05144",
      "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness",
      "authors": [
        {
          "name": "Michael Kearns",
          "openalex_id": "A5029730907",
          "orcid": "https://orcid.org/0000-0001-7569-0147",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Seth Neel",
          "openalex_id": "A5035371128",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Aaron Roth",
          "openalex_id": "A5057693522",
          "orcid": "https://orcid.org/0000-0002-0586-0515",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Zhiwei Steven Wu",
          "openalex_id": "A5001070941",
          "orcid": "https://orcid.org/0000-0002-8125-8227"
        }
      ],
      "publication_year": 2017,
      "publication_date": "2017-11-14",
      "abstract": "The most prevalent notions of fairness in machine learning are statistical definitions: they fix a small collection of pre-defined groups, and then ask for parity of some statistic of the classifier across these groups. Constraints of this form are susceptible to intentional or inadvertent \"fairness gerrymandering\", in which a classifier appears to be fair on each individual group, but badly violates the fairness constraint on one or more structured subgroups defined over the protected attributes. We propose instead to demand statistical notions of fairness across exponentially (or infinitely) many subgroups, defined by a structured class of functions over the protected attributes. This interpolates between statistical definitions of fairness and recently proposed individual notions of fairness, but raises several computational challenges. It is no longer clear how to audit a fixed classifier to see if it satisfies such a strong definition of fairness. We prove that the computational problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is equivalent to the problem of weak agnostic learning, which means it is computationally hard in the worst case, even for simple structured subclasses. We then derive two algorithms that provably converge to the best fair classifier, given access to oracles which can solve the agnostic learning problem. The algorithms are based on a formulation of subgroup fairness as a two-player zero-sum game between a Learner and an Auditor. Our first algorithm provably converges in a polynomial number of steps. Our second algorithm enjoys only provably asymptotic convergence, but has the merit of simplicity and faster per-step computation. We implement the simpler algorithm using linear regression as a heuristic oracle, and show that we can effectively both audit and learn fair classifiers on real datasets.",
      "cited_by_count": 303,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/1711.05144"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Digital Economy and Work Transformation"
      ],
      "referenced_works_count": 11,
      "url": "https://openalex.org/W2768894107"
    },
    {
      "openalex_id": "W2962751370",
      "doi": null,
      "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness",
      "authors": [
        {
          "name": "Michael Kearns",
          "openalex_id": "A5029730907",
          "orcid": "https://orcid.org/0000-0001-7569-0147",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Seth Neel",
          "openalex_id": "A5035371128",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Aaron Roth",
          "openalex_id": "A5057693522",
          "orcid": "https://orcid.org/0000-0002-0586-0515",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Zhiwei Steven Wu",
          "openalex_id": "A5001070941",
          "orcid": "https://orcid.org/0000-0002-8125-8227"
        }
      ],
      "publication_year": 2017,
      "publication_date": "2017-11-14",
      "abstract": "The most prevalent notions of in machine learning are statistical definitions: they fix a small collection of pre-defined groups, and then ask for parity of some statistic of the classifier across these groups. Constraints of this form are susceptible to intentional or inadvertent fairness gerrymandering, in which a classifier appears to be fair on each individual group, but badly violates the constraint on one or more structured subgroups defined over the protected attributes. We propose instead to demand statistical notions of across exponentially (or infinitely) many subgroups, defined by a structured class of functions over the protected attributes. This interpolates between statistical definitions of and recently proposed individual notions of fairness, but raises several computational challenges. It is no longer clear how to audit a fixed classifier to see if it satisfies such a strong definition of fairness. We prove that the computational problem of auditing subgroup for both equality of false positive rates and statistical parity is equivalent to the problem of weak agnostic learning, which means it is computationally hard in the worst case, even for simple structured subclasses. \r\nWe then derive two algorithms that provably converge to the best fair classifier, given access to oracles which can solve the agnostic learning problem. The algorithms are based on a formulation of subgroup as a two-player zero-sum game between a Learner and an Auditor. Our first algorithm provably converges in a polynomial number of steps. Our second algorithm enjoys only provably asymptotic convergence, but has the merit of simplicity and faster per-step computation. We implement the simpler algorithm using linear regression as a heuristic oracle, and show that we can effectively both audit and learn fair classifiers on real datasets.",
      "cited_by_count": 122,
      "type": "article",
      "source": {
        "name": "International Conference on Machine Learning",
        "type": "conference",
        "issn": null
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI"
      ],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W2962751370"
    },
    {
      "openalex_id": "W3003396981",
      "doi": "10.1111/ssqu.12741",
      "title": "Making Partisan Gerrymandering Fair: One Old and Two New Methods",
      "authors": [
        {
          "name": "Steven J. Brams",
          "openalex_id": "A5010863735",
          "orcid": "https://orcid.org/0000-0003-3650-0392",
          "institutions": [
            "New York University"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-01",
      "abstract": "Objective To introduce a novel way to make partisan gerrymandering fair. Methods In the context of two parties, divide a state into two geographical areas, each of which contain a number of districts that are roughly proportional to the share of the statewide vote received by each party in the last congressional elections. Allow each party to unilaterally design the districts in a designated area of the state, restricted only by traditional districting principles. Adaptations may be made to account for more than two parties. Results Each party gerrymanders but is limited to doing so in its designated area of the state, with results that are roughly proportional to the statewide vote. Conclusion \u201cFair gerrymandering\u201d is a way to counter unfair partisan gerrymandering and it is likely to reduce the number of uncontested elections and increase voter turnout.",
      "cited_by_count": 6,
      "type": "article",
      "source": {
        "name": "Social Science Quarterly",
        "type": "journal",
        "issn": [
          "0038-4941",
          "1540-6237"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Political Systems and Governance",
        "Electoral Systems and Political Participation"
      ],
      "referenced_works_count": 1,
      "url": "https://openalex.org/W3003396981"
    },
    {
      "openalex_id": "W4387888733",
      "doi": "10.1016/j.artint.2023.104035",
      "title": "Gerrymandering individual fairness",
      "authors": [
        {
          "name": "Tim R\u00e4z",
          "openalex_id": "A5070345670",
          "orcid": "https://orcid.org/0000-0002-8464-4190"
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-24",
      "abstract": "Individual fairness requires that similar individuals are treated similarly. It is supposed to prevent the unfair treatment of individuals on the subgroup level and to overcome the problem that group fairness measures are susceptible to manipulation or gerrymandering. The goal of the present paper is to explore the extent to which individual fairness itself can be gerrymandered. It will be proved that individual fairness can be gerrymandered in the context of predicting scores. Then, it will be argued that individual fairness is a very weak notion of fairness for some choices of feature space and metric. Finally, it will be discussed which properties of (individual) fairness are desirable.",
      "cited_by_count": 4,
      "type": "article",
      "source": {
        "name": "Artificial Intelligence",
        "type": "journal",
        "issn": [
          "0004-3702",
          "1872-7921"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://doi.org/10.1016/j.artint.2023.104035"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Experimental Behavioral Economics Studies",
        "Qualitative Comparative Analysis Research"
      ],
      "referenced_works_count": 33,
      "url": "https://openalex.org/W4387888733"
    },
    {
      "openalex_id": "W4220738081",
      "doi": "10.1016/j.mathsocsci.2022.03.002",
      "title": "Fairness in plurality systems with implications for detecting partisan gerrymandering",
      "authors": [
        {
          "name": "Jeffrey Barton",
          "openalex_id": "A5030298084",
          "orcid": "https://orcid.org/0000-0002-4167-7953",
          "institutions": [
            "Birmingham\u2013Southern College"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-03-29",
      "abstract": "For both two-party and multiparty elections we construct a baseline standard for fair seat proportions based on three intuitive assumptions about plurality voting systems. We show that such systems are inherently biased against minority parties irrespective of political geography and are thus incompatible with the ideal of proportional representation. The construction produces sensible theoretical and empirical results when applied to U.S. and Canadian elections, and it is consistent with baseline standards produced by certain simulation methods. We apply the standard to detect partisan gerrymanders in a simple way that handles edge cases appropriately and flags expected real maps as problematic.",
      "cited_by_count": 4,
      "type": "article",
      "source": {
        "name": "Mathematical Social Sciences",
        "type": "journal",
        "issn": [
          "0165-4896",
          "1879-3118"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://doi.org/10.1016/j.mathsocsci.2022.03.002"
      },
      "topics": [
        "Electoral Systems and Political Participation",
        "Game Theory and Voting Systems",
        "Judicial and Constitutional Studies"
      ],
      "referenced_works_count": 23,
      "url": "https://openalex.org/W4220738081"
    },
    {
      "openalex_id": "W4283170908",
      "doi": "10.1145/3531146.3533114",
      "title": "Are \u201cIntersectionally Fair\u201d AI Algorithms Really Fair to Women of Color? A Philosophical Analysis",
      "authors": [
        {
          "name": "Youjin Kong",
          "openalex_id": "A5033685060",
          "orcid": "https://orcid.org/0000-0001-5049-8503",
          "institutions": [
            "Oregon State University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-06-20",
      "abstract": "A growing number of studies on fairness in artificial intelligence (AI) use the notion of intersectionality to measure AI fairness. Most of these studies take intersectional fairness to be a matter of statistical parity among intersectional subgroups: an AI algorithm is \"intersectionally fair\" if the probability of the outcome is roughly the same across all subgroups defined by different combinations of the protected attributes. This paper identifies and examines three fundamental problems with this dominant interpretation of intersectional fairness in AI. First, the dominant approach is so preoccupied with the intersection of attributes/categories (e.g., race, gender) that it fails to address the intersection of oppression (e.g., racism, sexism), which is more central to intersectionality as a critical framework. Second, the dominant approach faces a dilemma between infinite regress and fairness gerrymandering: it either keeps splitting groups into smaller subgroups or arbitrarily selects protected groups. Lastly, the dominant view fails to capture what it really means for AI algorithms to be fair, in terms of both distributive and non-distributive fairness. I distinguish a strong sense of AI fairness from a weak sense that is prevalent in the literature, and conclude by envisioning paths towards strong intersectional fairness in AI.",
      "cited_by_count": 48,
      "type": "article",
      "source": {
        "name": "2022 ACM Conference on Fairness, Accountability, and Transparency",
        "type": "conference",
        "issn": null
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Psychology of Moral and Emotional Judgment",
        "Feminist Epistemology and Gender Studies"
      ],
      "referenced_works_count": 32,
      "url": "https://openalex.org/W4283170908"
    },
    {
      "openalex_id": "W4224951969",
      "doi": "10.48550/arxiv.2204.11615",
      "title": "Gerrymandering Individual Fairness",
      "authors": [
        {
          "name": "Tim R\u00e4z",
          "openalex_id": "A5070345670",
          "orcid": "https://orcid.org/0000-0002-8464-4190",
          "institutions": [
            "University of Bern"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-04-25",
      "abstract": "Individual fairness, proposed by Dwork et al., is a fairness measure that is supposed to prevent the unfair treatment of individuals on the subgroup level, and to overcome the problem that group fairness measures are susceptible to manipulation, or gerrymandering. The goal of the present paper is to explore the extent to which it is possible to gerrymander individual fairness itself. It will be proved that gerrymandering individual fairness in the context of predicting scores is possible. It will also be argued that individual fairness provides a very weak notion of fairness for some choices of feature space and metric. Finally, it will be discussed how the general idea of individual fairness may be preserved by formulating a notion of fairness that allows us to overcome some of the problems with individual fairness identified here and elsewhere.",
      "cited_by_count": 1,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2204.11615"
      },
      "topics": [
        "Social and Intergroup Psychology",
        "Experimental Behavioral Economics Studies"
      ],
      "referenced_works_count": 19,
      "url": "https://openalex.org/W4224951969"
    },
    {
      "openalex_id": "W3093426043",
      "doi": null,
      "title": "Abating gerrymandering by mandating fairness",
      "authors": [
        {
          "name": "Johannes Benade",
          "openalex_id": "A5016943043"
        },
        {
          "name": "Ariel D. Procaccia",
          "openalex_id": "A5041089506",
          "orcid": "https://orcid.org/0000-0002-8774-5827"
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-01",
      "abstract": "Political redistricting has been at the center of a rancorous public and legal debate overvoting rights and partisanship in the U.S. Even in cases where there is a desire to craft districtings that are acceptable to both sides of the aisle, it is unclear how to do so. Our proposed approach to this problem combines fair division and optimization; at its heart is a rigorous notion of fairness for districtings, which we call the fair coin \ufb02ip guarantee. We apply our approach to district four U.S. states, and \ufb01nd that enforcing fairness does not come at a signi\ufb01cant cost to traditional measures of quality.",
      "cited_by_count": 1,
      "type": "article",
      "source": {
        "name": "OpenBU/Boston University Institutional Repository (Boston University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Healthcare Quality and Management"
      ],
      "referenced_works_count": 1,
      "url": "https://openalex.org/W3093426043"
    },
    {
      "openalex_id": "W4415018704",
      "doi": "10.1007/s11109-025-10086-8",
      "title": "Attitudes Surrounding Fairness and Competition in Sports Predict Choices to Partisan Gerrymander",
      "authors": [
        {
          "name": "Hilary Jan Izatt",
          "openalex_id": "A5089183279",
          "institutions": [
            "Binghamton University"
          ]
        },
        {
          "name": "Sam Fuller",
          "openalex_id": "A5084074781",
          "orcid": "https://orcid.org/0000-0002-9670-1092",
          "institutions": [
            "American University"
          ]
        }
      ],
      "publication_year": 2025,
      "publication_date": "2025-10-10",
      "abstract": "Abstract Partisan polarization in the United States has intensified, fueling hostility toward partisan out-groups and eroding political and social trust. This divide has often been compared to the fervent loyalty of sports fans, where competition and \u201cteam spirit\u201d dominate behaviors. Despite this comparison, research has not systematically explored how views on fairness and competitiveness in partisan competition predict support for anti-democratic policies. This paper addresses this gap by developing a novel survey battery that uses sports as a conceptual proxy to measure these attitudes. We test this survey battery, and further refine it, on two U.S. samples. Using dimensional analysis we recover two latent dimensions: fairness and competitiveness. Using a novel measure, a gerrymandering map-choice, we find that these dimensions are highly predictive of anti-democratic behavior. This study illustrates how individuals\u2019 partisanship and underlying psychology lead to undemocratic outcomes in the context of partisan competition.",
      "cited_by_count": 1,
      "type": "article",
      "source": {
        "name": "Political Behavior",
        "type": "journal",
        "issn": [
          "0190-9320",
          "1573-6687"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s11109-025-10086-8.pdf"
      },
      "topics": [
        "Sports, Gender, and Society",
        "Sport and Mega-Event Impacts",
        "Doping in Sports"
      ],
      "referenced_works_count": 73,
      "url": "https://openalex.org/W4415018704"
    },
    {
      "openalex_id": "W3006526458",
      "doi": "10.48550/arxiv.2002.06849",
      "title": "Gerrymandering and fair districting in parallel voting systems",
      "authors": [
        {
          "name": "Igor Mandric",
          "openalex_id": "A5008135101",
          "orcid": "https://orcid.org/0000-0003-4362-5169"
        },
        {
          "name": "Igor Ro\u015fca",
          "openalex_id": "A5103808118"
        },
        {
          "name": "Radu Buzatu",
          "openalex_id": "A5034865294",
          "orcid": "https://orcid.org/0000-0002-2322-8740"
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-17",
      "abstract": "Switching from one electoral system to another one is frequently criticized by the opposition and is viewed as a means for the ruling party to stay in power. In particular, when the new electoral system is a parallel voting (or a single-member district) system, the ruling party is usually suspected of a biased way of partitioning the state into electoral districts such that based on a priori knowledge it has more chances to win in a maximum possible number of districts. In this paper, we propose a new methodology for deciding whether a particular party benefits from a given districting map under a parallel voting system. As a part of our methodology, we formulate and solve several gerrymandering problems. We showcased the application of our approach to the Moldovan parliamentary elections of 2019. Our results suggest that contrary to the arguments of previous studies, there is no clear evidence to consider that the districting map used in those elections was unfair.",
      "cited_by_count": 1,
      "type": "preprint",
      "source": {
        "name": "arXiv (Cornell University)",
        "type": "repository",
        "issn": null
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/2002.06849"
      },
      "topics": [
        "Game Theory and Voting Systems",
        "Electoral Systems and Political Participation",
        "Internet Traffic Analysis and Secure E-voting"
      ],
      "referenced_works_count": 25,
      "url": "https://openalex.org/W3006526458"
    },
    {
      "openalex_id": "W2982061150",
      "doi": "10.1017/s000305541900056x",
      "title": "Theoretical Foundations and Empirical Evaluations of Partisan Fairness in District-Based Democracies",
      "authors": [
        {
          "name": "Jonathan N. Katz",
          "openalex_id": "A5051019098",
          "orcid": "https://orcid.org/0000-0002-5287-3503",
          "institutions": [
            "California Institute of Technology"
          ]
        },
        {
          "name": "Gary King",
          "openalex_id": "A5087421071",
          "orcid": "https://orcid.org/0000-0002-5327-7631",
          "institutions": [
            "Harvard University Press"
          ]
        },
        {
          "name": "Elizabeth Rosenblatt",
          "openalex_id": "A5078638216",
          "orcid": "https://orcid.org/0000-0002-8890-3014",
          "institutions": [
            "Harvard University Press"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-10-23",
      "abstract": "We clarify the theoretical foundations of partisan fairness standards for district-based democratic electoral systems, including essential assumptions and definitions not previously recognized, formalized, or in some cases even discussed. We also offer extensive empirical evidence for assumptions with observable implications. We cover partisan symmetry, the most commonly accepted fairness standard, and other perspectives. Throughout, we follow a fundamental principle of statistical inference too often ignored in this literature\u2014defining the quantity of interest separately so its measures can be proven wrong, evaluated, and improved. This enables us to prove which of the many newly proposed fairness measures are statistically appropriate and which are biased, limited, or not measures of the theoretical quantity they seek to estimate at all. Because real-world redistricting and gerrymandering involve complicated politics with numerous participants and conflicting goals, measures biased for partisan fairness sometimes still provide useful descriptions of other aspects of electoral systems.",
      "cited_by_count": 86,
      "type": "article",
      "source": {
        "name": "American Political Science Review",
        "type": "journal",
        "issn": [
          "0003-0554",
          "1537-5943"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Electoral Systems and Political Participation",
        "Judicial and Constitutional Studies",
        "Gender Politics and Representation"
      ],
      "referenced_works_count": 102,
      "url": "https://openalex.org/W2982061150"
    },
    {
      "openalex_id": "W4394994643",
      "doi": "10.1109/tnnls.2024.3384181",
      "title": "MultiFair: Model Fairness With Multiple Sensitive Attributes",
      "authors": [
        {
          "name": "Huan Tian",
          "openalex_id": "A5100701226",
          "orcid": "https://orcid.org/0000-0003-2763-8314",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Bo Liu",
          "openalex_id": "A5100461646",
          "orcid": "https://orcid.org/0000-0002-3603-6617",
          "institutions": [
            "University of Technology Sydney"
          ]
        },
        {
          "name": "Tianqing Zhu",
          "openalex_id": "A5036801346",
          "orcid": "https://orcid.org/0000-0003-3411-7947",
          "institutions": [
            "City University of Macau",
            "University of Macau"
          ]
        },
        {
          "name": "Wanlei Zhou",
          "openalex_id": "A5051406984",
          "orcid": "https://orcid.org/0000-0002-1680-2521",
          "institutions": [
            "University of Macau",
            "City University of Macau"
          ]
        },
        {
          "name": "Philip S. Yu",
          "openalex_id": "A5036357902",
          "orcid": "https://orcid.org/0000-0002-3491-5968",
          "institutions": [
            "University of Illinois Chicago"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-04-22",
      "abstract": "While existing fairness interventions show promise in mitigating biased predictions, most studies concentrate on single-attribute protections. Although a few methods consider multiple attributes, they either require additional constraints or prediction heads, incurring high computational overhead or jeopardizing the stability of the training process. More critically, they consider per-attribute protection approaches, raising concerns about fairness gerrymandering where certain attribute combinations remain unfair. This work aims to construct a neutral domain containing fused information across all subgroups and attributes. It delivers fair predictions as the fused input contains neutralized information for all considered attributes. Specifically, we adopt mixup operations to generate samples with fused information. However, our experiments reveal that directly adopting the operations leads to degraded prediction results. The excessive mixup operations result in unrecognizable training data. To this end, we design three distinct mixup schemes that balance information fusion across attributes while retaining distinct visual features critical for training valid models. Extensive experiments with multiple datasets and up to eight sensitive attributes demonstrate that the proposed MultiFair method can deliver fairness protections for multiple attributes while maintaining valid prediction results.",
      "cited_by_count": 8,
      "type": "article",
      "source": {
        "name": "IEEE Transactions on Neural Networks and Learning Systems",
        "type": "journal",
        "issn": [
          "2162-237X",
          "2162-2388"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Adversarial Robustness in Machine Learning"
      ],
      "referenced_works_count": 56,
      "url": "https://openalex.org/W4394994643"
    },
    {
      "openalex_id": "W2914514892",
      "doi": "10.1001/amajethics.2019.167",
      "title": "Can AI Help Reduce Disparities in General Medical and Mental Health Care?",
      "authors": [
        {
          "name": "Irene Y. Chen",
          "openalex_id": "A5081135036",
          "orcid": "https://orcid.org/0000-0001-5202-2111"
        },
        {
          "name": "Peter Szolovits",
          "openalex_id": "A5006650843",
          "orcid": "https://orcid.org/0000-0001-8411-6403",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        },
        {
          "name": "Marzyeh Ghassemi",
          "openalex_id": "A5070063054",
          "orcid": "https://orcid.org/0000-0001-6349-7251",
          "institutions": [
            "Massachusetts Institute of Technology",
            "Alphabet (United States)",
            "Vector Institute"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-02-01",
      "abstract": "This analysis can provide a framework for assessing and identifying disparate impacts of artificial intelligence in health care.",
      "cited_by_count": 354,
      "type": "article",
      "source": {
        "name": "The AMA Journal of Ethic",
        "type": "journal",
        "issn": [
          "2376-6980"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "diamond",
        "oa_url": "https://journalofethics.ama-assn.org/sites/journalofethics.ama-assn.org/files/2019-01/org1-1902_0.pdf"
      },
      "topics": [
        "Machine Learning in Healthcare",
        "Healthcare cost, quality, practices",
        "Chronic Disease Management Strategies"
      ],
      "referenced_works_count": 60,
      "url": "https://openalex.org/W2914514892"
    },
    {
      "openalex_id": "W3004542466",
      "doi": "10.1145/3375627.3375820",
      "title": "Saving Face",
      "authors": [
        {
          "name": "Inioluwa Deborah Raji",
          "openalex_id": "A5011015504",
          "institutions": [
            "University of Toronto"
          ]
        },
        {
          "name": "Timnit Gebru",
          "openalex_id": "A5089275971",
          "orcid": "https://orcid.org/0009-0007-4814-1944",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Margaret Mitchell",
          "openalex_id": "A5046235098",
          "orcid": "https://orcid.org/0000-0001-7043-6545",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Joy Buolamwini",
          "openalex_id": "A5047439958",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        },
        {
          "name": "Joonseok Lee",
          "openalex_id": "A5101859889",
          "orcid": "https://orcid.org/0000-0002-0786-8086",
          "institutions": [
            "Google (United States)"
          ]
        },
        {
          "name": "Emily Denton",
          "openalex_id": "A5045383831",
          "orcid": "https://orcid.org/0000-0003-4915-0512",
          "institutions": [
            "Google (United States)"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-02-04",
      "abstract": "Although essential to revealing biased performance, well intentioned attempts at algorithmic auditing can have effects that may harm the very populations these measures are meant to protect. This concern is even more salient while auditing biometric systems such as facial recognition, where the data is sensitive and the technology is often used in ethically questionable manners. We demonstrate a set of fiveethical concerns in the particular case of auditing commercial facial processing technology, highlighting additional design considerations and ethical tensions the auditor needs to be aware of so as not exacerbate or complement the harms propagated by the audited system. We go further to provide tangible illustrations of these concerns, and conclude by reflecting on what these concerns mean for the role of the algorithmic audit and the fundamental product limitations they reveal.",
      "cited_by_count": 247,
      "type": "article",
      "source": {
        "name": "Proceedings of the AAAI/ACM Conference on AI Ethics and Society",
        "type": "journal",
        "issn": [
          "3065-8365"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3375627.3375820"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Medical Malpractice and Liability Issues",
        "Face recognition and analysis"
      ],
      "referenced_works_count": 19,
      "url": "https://openalex.org/W3004542466"
    },
    {
      "openalex_id": "W2987228376",
      "doi": "10.1038/s41586-019-1657-6",
      "title": "Sex and gender analysis improves science and engineering",
      "authors": [
        {
          "name": "Cara Tannenbaum",
          "openalex_id": "A5076417160",
          "orcid": "https://orcid.org/0000-0002-7102-2333",
          "institutions": [
            "Canadian Institutes of Health Research",
            "Universit\u00e9 de Montr\u00e9al",
            "Institute of Gender and Health"
          ]
        },
        {
          "name": "Robert P. Ellis",
          "openalex_id": "A5022859748",
          "orcid": "https://orcid.org/0000-0002-3117-0075",
          "institutions": [
            "University of Exeter"
          ]
        },
        {
          "name": "Friederike Eyssel",
          "openalex_id": "A5074815650",
          "orcid": "https://orcid.org/0000-0002-4978-8922",
          "institutions": [
            "Bielefeld University"
          ]
        },
        {
          "name": "James Zou",
          "openalex_id": "A5005779176",
          "orcid": "https://orcid.org/0000-0001-8880-4764",
          "institutions": [
            "Stanford University",
            "Chan Zuckerberg Initiative (United States)"
          ]
        },
        {
          "name": "Londa Schiebinger",
          "openalex_id": "A5087340682",
          "orcid": "https://orcid.org/0000-0003-3438-3081",
          "institutions": [
            "Stanford University",
            "Health Innovations (United States)"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-11-06",
      "abstract": null,
      "cited_by_count": 547,
      "type": "review",
      "source": {
        "name": "Nature",
        "type": "journal",
        "issn": [
          "0028-0836",
          "1476-4687"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "bronze",
        "oa_url": "https://www.nature.com/articles/s41586-019-1657-6.pdf"
      },
      "topics": [
        "Sex and Gender in Healthcare",
        "Career Development and Diversity",
        "Diversity and Career in Medicine"
      ],
      "referenced_works_count": 121,
      "url": "https://openalex.org/W2987228376"
    },
    {
      "openalex_id": "W2903731725",
      "doi": "10.1089/elj.2018.0503",
      "title": "Using Outlier Analysis to Detect Partisan Gerrymanders: A Survey of Current Approaches and Future Directions",
      "authors": [
        {
          "name": "Gowri Ramachandran",
          "openalex_id": "A5052323077",
          "orcid": "https://orcid.org/0000-0001-5944-1335",
          "institutions": [
            "Southwestern Law School"
          ]
        },
        {
          "name": "Dara Gold",
          "openalex_id": "A5025558774",
          "orcid": "https://orcid.org/0000-0002-6038-3360",
          "institutions": [
            "RAND Corporation"
          ]
        }
      ],
      "publication_year": 2018,
      "publication_date": "2018-12-01",
      "abstract": "The prospect of convincing courts to intervene in partisan gerrymandering has inspired a great deal of research and, recently, public attention. But how can neutral parties such as courts and independent redistricting commissions discern when a district map is unfairly gerrymandered? We review the case law and the leading measures of substantive fairness, explaining why, alone, they are unlikely to be sufficient for neutral decision makers to ascertain gerrymanders. We then explain the concept of outlier analysis, a particularly promising intervention into the field, but one that is computationally challenging, as it requires generating a sample of reasonable district maps. We review the major approaches to assembling these samples, and we present recommendations for improvement and future research that could help lead to the development of a consensus approach to assessing whether a map is gerrymandered.",
      "cited_by_count": 14,
      "type": "article",
      "source": {
        "name": "Election Law Journal Rules Politics and Policy",
        "type": "journal",
        "issn": [
          "1533-1296",
          "1557-8062"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://www.liebertpub.com/doi/pdf/10.1089/elj.2018.0503"
      },
      "topics": [
        "Judicial and Constitutional Studies",
        "Game Theory and Voting Systems",
        "Criminal Justice and Corrections Analysis"
      ],
      "referenced_works_count": 17,
      "url": "https://openalex.org/W2903731725"
    },
    {
      "openalex_id": "W2913892882",
      "doi": "10.1089/elj.2018.0514",
      "title": "What Criteria Should Be Used for Redistricting Reform?",
      "authors": [
        {
          "name": "John F. Nagle",
          "openalex_id": "A5045652748",
          "orcid": "https://orcid.org/0000-0002-9844-5934",
          "institutions": [
            "Carnegie Mellon University"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-02-06",
      "abstract": "Congressional redistricting plans for Pennsylvania, with an emphasis on the newly enacted 2018 plan, have been evaluated for fairness and responsiveness to voters. This and other submitted plans that adhered to the traditional reform criteria of compactness and not splitting political boundaries have half as much bias favoring Republicans as the unconstitutional map of 2011. For fairer maps, it appears to be necessary to \"anti-gerrymander\" by relaxing the traditional criteria in order to overcome the political geography in Pennsylvania which apparently makes a Democratic gerrymander practically impossible. The methodology uses five statewide data bases at the precinct level and suitably constructed seats/votes curves. If fairness and responsiveness are valued more than political geography, then they should be made explicit criteria in congressional districting, at least in Pennsylvania.",
      "cited_by_count": 17,
      "type": "article",
      "source": {
        "name": "Election Law Journal Rules Politics and Policy",
        "type": "journal",
        "issn": [
          "1533-1296",
          "1557-8062"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Fiscal Policy and Economic Growth"
      ],
      "referenced_works_count": 26,
      "url": "https://openalex.org/W2913892882"
    },
    {
      "openalex_id": "W2913629796",
      "doi": "10.2139/ssrn.3335622",
      "title": "Laboratories of Democracy Reform: State Constitutions and Partisan Gerrymandering",
      "authors": [
        {
          "name": "Samuel Wang",
          "openalex_id": "A5103183176",
          "orcid": "https://orcid.org/0000-0002-4726-9184",
          "institutions": [
            "Princeton University",
            "Neuroscience Institute"
          ]
        },
        {
          "name": "Richard Ober",
          "openalex_id": "A5015965197"
        },
        {
          "name": "Ben Williams",
          "openalex_id": "A5101853916",
          "orcid": "https://orcid.org/0000-0002-8083-7876",
          "institutions": [
            "Princeton University"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-01-01",
      "abstract": null,
      "cited_by_count": 19,
      "type": "article",
      "source": {
        "name": "SSRN Electronic Journal",
        "type": "repository",
        "issn": [
          "1556-5068"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://doi.org/10.2139/ssrn.3335622"
      },
      "topics": [
        "Judicial and Constitutional Studies",
        "Legal and Constitutional Studies"
      ],
      "referenced_works_count": 1,
      "url": "https://openalex.org/W2913629796"
    },
    {
      "openalex_id": "W3173314039",
      "doi": "10.1017/pan.2021.13",
      "title": "Partisan Dislocation: A Precinct-Level Measure of Representation and Gerrymandering",
      "authors": [
        {
          "name": "Daryl DeFord",
          "openalex_id": "A5019973061",
          "orcid": "https://orcid.org/0000-0003-2032-3168",
          "institutions": [
            "Washington State University"
          ]
        },
        {
          "name": "Nicholas Eubank",
          "openalex_id": "A5041293571",
          "orcid": "https://orcid.org/0000-0001-5159-4740",
          "institutions": [
            "Social Science Research Council"
          ]
        },
        {
          "name": "Jonathan Rodden",
          "openalex_id": "A5014104052",
          "orcid": "https://orcid.org/0000-0003-1449-8527",
          "institutions": [
            "Stanford University",
            "Hoover Institution"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-06-30",
      "abstract": "Abstract We introduce a fine-grained measure of the extent to which electoral districts combine and split local communities of co-partisans in unnatural ways. Our indicator\u2014which we term Partisan Dislocation \u2014is a measure of the difference between the partisan composition of a voter\u2019s geographic nearest neighbors and that of her assigned district. We show that our measure is a good local and global indicator of district manipulation, easily identifying instances in which districts carve up clusters of co-partisans (cracking) or combine them in unnatural ways (packing). We demonstrate that our measure is related to but distinct from other approaches to the measurement of gerrymandering, and has some clear advantages, above all as a complement to simulation-based approaches, and as a way to identify the specific neighborhoods most affected by gerrymandering. It can also be used prospectively by district-drawers who wish to create maps that reflect voter geography, but according to our analysis, that goal will sometimes be in conflict with the goal of partisan fairness.",
      "cited_by_count": 26,
      "type": "article",
      "source": {
        "name": "Political Analysis",
        "type": "journal",
        "issn": [
          "1047-1987",
          "1476-4989"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "bronze",
        "oa_url": "https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C4EDEA9606F6BA2A17A9B5302F86DD43/S1047198721000139a.pdf/div-class-title-partisan-dislocation-a-precinct-level-measure-of-representation-and-gerrymandering-div.pdf"
      },
      "topics": [
        "Electoral Systems and Political Participation",
        "Opinion Dynamics and Social Influence",
        "Social Media and Politics"
      ],
      "referenced_works_count": 30,
      "url": "https://openalex.org/W3173314039"
    },
    {
      "openalex_id": "W4292373535",
      "doi": "10.1287/opre.2022.2311",
      "title": "Multiobjective Optimization for Politically Fair Districting: A Scalable Multilevel Approach",
      "authors": [
        {
          "name": "Rahul Swamy",
          "openalex_id": "A5028867933",
          "orcid": "https://orcid.org/0000-0001-9439-7499",
          "institutions": [
            "University of Illinois Urbana-Champaign"
          ]
        },
        {
          "name": "Douglas M. King",
          "openalex_id": "A5072222405",
          "orcid": "https://orcid.org/0000-0003-3846-9755",
          "institutions": [
            "University of Illinois Urbana-Champaign"
          ]
        },
        {
          "name": "Sheldon H. Jacobson",
          "openalex_id": "A5018895822",
          "orcid": "https://orcid.org/0000-0002-9042-8750",
          "institutions": [
            "University of Illinois Urbana-Champaign"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-08-19",
      "abstract": "Gerrymandering has been a fundamental issue in American democracy for more than two centuries, with significant implications for electoral representation. Traditional optimization models for political districting primarily model nonpolitical fairness metrics such as the compactness of districts. In \u201cMultiobjective Optimization for Politically Fair Districting: A Scalable Multilevel Approach,\u201d Swamy, King, and Jacobson propose optimization models that explicitly incorporate political fairness objectives using political data from past elections. These objectives model fundamental fairness principles such as vote-seat proportionality (efficiency gap), partisan (a)symmetry, and competitiveness. They propose a solution strategy, called the multilevel algorithm, that solves large instances of the problem using a series of matching-based graph contractions. A case study on congressional districting in Wisconsin demonstrates that district plans balance the interests of the voters and the political parties.",
      "cited_by_count": 23,
      "type": "article",
      "source": {
        "name": "Operations Research",
        "type": "journal",
        "issn": [
          "0030-364X",
          "1526-5463"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Game Theory and Voting Systems",
        "Electoral Systems and Political Participation"
      ],
      "referenced_works_count": 46,
      "url": "https://openalex.org/W4292373535"
    },
    {
      "openalex_id": "W4289751798",
      "doi": "10.1145/3219819.3220046",
      "title": "A Unified Approach to Quantifying Algorithmic Unfairness",
      "authors": [
        {
          "name": "Till Speicher",
          "openalex_id": "A5032165991",
          "institutions": [
            "Max Planck Institute for Software Systems"
          ]
        },
        {
          "name": "Hoda Heidari",
          "openalex_id": "A5037735812",
          "orcid": "https://orcid.org/0000-0003-3710-4076",
          "institutions": [
            "ETH Zurich"
          ]
        },
        {
          "name": "Nina Grgi\u0107-Hla\u010da",
          "openalex_id": "A5025919676",
          "orcid": "https://orcid.org/0000-0003-3397-2984",
          "institutions": [
            "Max Planck Institute for Software Systems"
          ]
        },
        {
          "name": "Krishna P. Gummadi",
          "openalex_id": "A5067688305",
          "orcid": "https://orcid.org/0000-0003-1256-8800",
          "institutions": [
            "Max Planck Institute for Software Systems"
          ]
        },
        {
          "name": "Adish Singla",
          "openalex_id": "A5027711113",
          "orcid": "https://orcid.org/0000-0001-9922-0668",
          "institutions": [
            "Max Planck Institute for Software Systems"
          ]
        },
        {
          "name": "Adrian Weller",
          "openalex_id": "A5042278493",
          "orcid": "https://orcid.org/0000-0003-1915-7158",
          "institutions": [
            "University of Cambridge",
            "The Alan Turing Institute"
          ]
        },
        {
          "name": "Muhammad Bilal Zafar",
          "openalex_id": "A5011745729",
          "orcid": "https://orcid.org/0000-0001-6329-303X",
          "institutions": [
            "Max Planck Institute for Software Systems"
          ]
        }
      ],
      "publication_year": 2018,
      "publication_date": "2018-07-19",
      "abstract": "Discrimination via algorithmic decision making has received considerable\\nattention. Prior work largely focuses on defining conditions for fairness, but\\ndoes not define satisfactory measures of algorithmic unfairness. In this paper,\\nwe focus on the following question: Given two unfair algorithms, how should we\\ndetermine which of the two is more unfair? Our core idea is to use existing\\ninequality indices from economics to measure how unequally the outcomes of an\\nalgorithm benefit different individuals or groups in a population. Our work\\noffers a justified and general framework to compare and contrast the\\n(un)fairness of algorithmic predictors. This unifying approach enables us to\\nquantify unfairness both at the individual and the group level. Further, our\\nwork reveals overlooked tradeoffs between different fairness notions: using our\\nproposed measures, the overall individual-level unfairness of an algorithm can\\nbe decomposed into a between-group and a within-group component. Earlier\\nmethods are typically designed to tackle only between-group unfairness, which\\nmay be justified for legal or other reasons. However, we demonstrate that\\nminimizing exclusively the between-group component may, in fact, increase the\\nwithin-group, and hence the overall unfairness. We characterize and illustrate\\nthe tradeoffs between our measures of (un)fairness and the prediction accuracy.\\n",
      "cited_by_count": 174,
      "type": "preprint",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3219819.3220046"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Privacy-Preserving Technologies in Data"
      ],
      "referenced_works_count": 38,
      "url": "https://openalex.org/W4289751798"
    },
    {
      "openalex_id": "W4388232509",
      "doi": "10.1038/s41598-023-45943-1",
      "title": "Ensuring generalized fairness in batch classification",
      "authors": [
        {
          "name": "Manjish Pal",
          "openalex_id": "A5101031826",
          "orcid": "https://orcid.org/0000-0002-9280-6938",
          "institutions": [
            "Indian Institute of Technology Kharagpur"
          ]
        },
        {
          "name": "Subham Pokhriyal",
          "openalex_id": "A5045355516",
          "institutions": [
            "Indian Institute of Technology Ropar"
          ]
        },
        {
          "name": "Sandipan Sikdar",
          "openalex_id": "A5015963208",
          "orcid": "https://orcid.org/0000-0001-8052-8961",
          "institutions": [
            "L3S Research Center"
          ]
        },
        {
          "name": "Niloy Ganguly",
          "openalex_id": "A5073812421",
          "orcid": "https://orcid.org/0000-0002-3967-186X",
          "institutions": [
            "Indian Institute of Technology Kharagpur"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-11-02",
      "abstract": null,
      "cited_by_count": 2,
      "type": "article",
      "source": {
        "name": "Scientific Reports",
        "type": "journal",
        "issn": [
          "2045-2322"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.nature.com/articles/s41598-023-45943-1.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Privacy-Preserving Technologies in Data",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "referenced_works_count": 29,
      "url": "https://openalex.org/W4388232509"
    },
    {
      "openalex_id": "W2886232188",
      "doi": "10.1016/j.polgeo.2023.103040",
      "title": "Discrete geometry for electoral geography",
      "authors": [
        {
          "name": "Moon Duchin",
          "openalex_id": "A5055847047",
          "orcid": "https://orcid.org/0000-0003-4498-4067",
          "institutions": [
            "Tufts University",
            "Tisch Hospital"
          ]
        },
        {
          "name": "Bridget Eileen Tenner",
          "openalex_id": "A5001438565",
          "orcid": "https://orcid.org/0000-0003-0150-9653",
          "institutions": [
            "DePaul University"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-01-17",
      "abstract": null,
      "cited_by_count": 19,
      "type": "article",
      "source": {
        "name": "Political Geography",
        "type": "journal",
        "issn": [
          "0962-6298",
          "1873-5096"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Topological and Geometric Data Analysis",
        "Advanced Combinatorial Mathematics"
      ],
      "referenced_works_count": 71,
      "url": "https://openalex.org/W2886232188"
    },
    {
      "openalex_id": "W4293072351",
      "doi": "10.1089/elj.2020.0709",
      "title": "Limits of Partisanship in Citizen Preferences on Redistricting",
      "authors": [
        {
          "name": "Devin McCarthy",
          "openalex_id": "A5086148051",
          "institutions": [
            "American Civil Liberties Union"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-04-28",
      "abstract": "A commonly accepted model of public attitudes toward election rules assumes that citizens follow the cues of their preferred party's elites and support rules that would benefit that party in elections. This article proposes an alternative theory in which most citizens prefer fair electoral institutions at the expense of partisan interest when that choice is made explicit, while a minority of committed partisans are driven by partisanship. I test this theory on the case of redistricting using two survey experiments that ask respondents to choose between a partisan gerrymander and a nonpartisan district map. While introducing party labels to a redistricting scenario makes partisans somewhat more likely to choose a gerrymandered map, a clear majority of partisans choose a nonpartisan map across all experimental conditions. Only citizens who strongly identify as members of a political party are likely to choose partisanship over fairness.",
      "cited_by_count": 10,
      "type": "article",
      "source": {
        "name": "Election Law Journal Rules Politics and Policy",
        "type": "journal",
        "issn": [
          "1533-1296",
          "1557-8062"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Electoral Systems and Political Participation",
        "Social and Intergroup Psychology",
        "Gender Politics and Representation"
      ],
      "referenced_works_count": 37,
      "url": "https://openalex.org/W4293072351"
    },
    {
      "openalex_id": "W4220760463",
      "doi": "10.1038/s41598-022-07939-1",
      "title": "A clarification of the nuances in the fairness metrics landscape",
      "authors": [
        {
          "name": "Alessandro Castelnovo",
          "openalex_id": "A5015450677",
          "orcid": "https://orcid.org/0000-0001-5234-1155",
          "institutions": [
            "University of Milano-Bicocca"
          ]
        },
        {
          "name": "Riccardo Crupi",
          "openalex_id": "A5046602284",
          "orcid": "https://orcid.org/0009-0005-6714-5161"
        },
        {
          "name": "Greta Greco",
          "openalex_id": "A5055056458",
          "orcid": "https://orcid.org/0000-0001-6328-1303",
          "institutions": [
            "University of Milano-Bicocca"
          ]
        },
        {
          "name": "Daniele Regoli",
          "openalex_id": "A5011035709",
          "orcid": "https://orcid.org/0000-0003-2711-8343"
        },
        {
          "name": "Ilaria Giuseppina Penco",
          "openalex_id": "A5078247861"
        },
        {
          "name": "Andrea Cosentini",
          "openalex_id": "A5031869151"
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-03-10",
      "abstract": "Abstract In recent years, the problem of addressing fairness in machine learning (ML) and automatic decision making has attracted a lot of attention in the scientific communities dealing with artificial intelligence. A plethora of different definitions of fairness in ML have been proposed, that consider different notions of what is a \u201cfair decision\u201d in situations impacting individuals in the population. The precise differences, implications and \u201corthogonality\u201d between these notions have not yet been fully analyzed in the literature. In this work, we try to make some order out of this zoo of definitions.",
      "cited_by_count": 181,
      "type": "article",
      "source": {
        "name": "Scientific Reports",
        "type": "journal",
        "issn": [
          "2045-2322"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.nature.com/articles/s41598-022-07939-1.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Adversarial Robustness in Machine Learning"
      ],
      "referenced_works_count": 96,
      "url": "https://openalex.org/W4220760463"
    },
    {
      "openalex_id": "W3092541244",
      "doi": "10.1145/3616865",
      "title": "Fairness in Machine Learning: A Survey",
      "authors": [
        {
          "name": "Simon Caton",
          "openalex_id": "A5021197359",
          "orcid": "https://orcid.org/0000-0001-9379-3879",
          "institutions": [
            "University College Dublin"
          ]
        },
        {
          "name": "Christian Haas",
          "openalex_id": "A5023136097",
          "orcid": "https://orcid.org/0000-0002-2690-5962",
          "institutions": [
            "Vienna University of Economics and Business",
            "University of Nebraska at Omaha"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-08-23",
      "abstract": "When Machine Learning technologies are used in contexts that affect citizens, companies as well as researchers need to be confident that there will not be any unexpected social implications, such as bias towards gender, ethnicity, and/or people with disabilities. There is significant literature on approaches to mitigate bias and promote fairness, yet the area is complex and hard to penetrate for newcomers to the domain. This article seeks to provide an overview of the different schools of thought and approaches that aim to increase the fairness of Machine Learning. It organizes approaches into the widely accepted framework of pre-processing, in-processing, and post-processing methods, subcategorizing into a further 11 method areas. Although much of the literature emphasizes binary classification, a discussion of fairness in regression, recommender systems, and unsupervised learning is also provided along with a selection of currently available open source libraries. The article concludes by summarizing open challenges articulated as five dilemmas for fairness research.",
      "cited_by_count": 375,
      "type": "review",
      "source": {
        "name": "ACM Computing Surveys",
        "type": "journal",
        "issn": [
          "0360-0300",
          "1557-7341"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3616865"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Adversarial Robustness in Machine Learning"
      ],
      "referenced_works_count": 414,
      "url": "https://openalex.org/W3092541244"
    },
    {
      "openalex_id": "W2969896603",
      "doi": "10.1145/3457607",
      "title": "A Survey on Bias and Fairness in Machine Learning",
      "authors": [
        {
          "name": "Ninareh Mehrabi",
          "openalex_id": "A5056269049",
          "institutions": [
            "Integrated Systems Incorporation (United States)"
          ]
        },
        {
          "name": "Fred Morstatter",
          "openalex_id": "A5002709735",
          "orcid": "https://orcid.org/0000-0002-0247-4328",
          "institutions": [
            "Integrated Systems Incorporation (United States)"
          ]
        },
        {
          "name": "Nripsuta Ani Saxena",
          "openalex_id": "A5091625866",
          "orcid": "https://orcid.org/0009-0004-1121-5426",
          "institutions": [
            "Integrated Systems Incorporation (United States)"
          ]
        },
        {
          "name": "Kristina Lerman",
          "openalex_id": "A5049634383",
          "orcid": "https://orcid.org/0000-0002-5071-0575",
          "institutions": [
            "Integrated Systems Incorporation (United States)"
          ]
        },
        {
          "name": "Aram Galstyan",
          "openalex_id": "A5101715504",
          "orcid": "https://orcid.org/0000-0003-4215-0886",
          "institutions": [
            "Integrated Systems Incorporation (United States)"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-07-13",
      "abstract": "With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.",
      "cited_by_count": 316,
      "type": "preprint",
      "source": {
        "name": "ACM Computing Surveys",
        "type": "journal",
        "issn": [
          "0360-0300",
          "1557-7341"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/1908.09635"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Adversarial Robustness in Machine Learning"
      ],
      "referenced_works_count": 148,
      "url": "https://openalex.org/W2969896603"
    },
    {
      "openalex_id": "W2792174932",
      "doi": "10.1017/pan.2020.36",
      "title": "Gerrymandering and Compactness: Implementation Flexibility and Abuse",
      "authors": [
        {
          "name": "Richard Barnes",
          "openalex_id": "",
          "orcid": "https://orcid.org/0000-0002-0204-6040",
          "institutions": [
            "University of California, Berkeley",
            "Berkeley College",
            "Massachusetts Institute of Technology"
          ]
        },
        {
          "name": "Justin Solomon",
          "openalex_id": "",
          "institutions": [
            "Massachusetts Institute of Technology"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-12-16",
      "abstract": "Abstract Political districts may be drawn to favor one group or political party over another, or gerrymandered . A number of measurements have been suggested as ways to detect and prevent such behavior. These measures give concrete axes along which districts and districting plans can be compared. However, measurement values are affected by both noise and the compounding effects of seemingly innocuous implementation decisions. Such issues will arise for any measure. As a case study demonstrating the effect, we show that commonly used measures of geometric compactness for district boundaries are affected by several factors irrelevant to fairness or compliance with civil rights law. We further show that an adversary could manipulate measurements to affect the assessment of a given plan. This instability complicates using these measurements as legislative or judicial standards to counteract unfair redistricting practices. This paper accompanies the release of packages in C++, Python, and R that correctly, efficiently, and reproducibly calculate a variety of compactness scores.",
      "cited_by_count": 20,
      "type": "article",
      "source": {
        "name": "Political Analysis",
        "type": "journal",
        "issn": [
          "1047-1987",
          "1476-4989"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://arxiv.org/pdf/1803.02857"
      },
      "topics": [
        "Credit Risk and Financial Regulations",
        "Internet Traffic Analysis and Secure E-voting",
        "Judicial and Constitutional Studies"
      ],
      "referenced_works_count": 27,
      "url": "https://openalex.org/W2792174932"
    },
    {
      "openalex_id": "W3001765450",
      "doi": "10.1145/3351095.3372849",
      "title": "What does it mean to 'solve' the problem of discrimination in hiring?",
      "authors": [
        {
          "name": "Javier S\u00e1nchez\u2010Monedero",
          "openalex_id": "A5034210024",
          "orcid": "https://orcid.org/0000-0001-8649-1709",
          "institutions": [
            "Cardiff University"
          ]
        },
        {
          "name": "Lina Dencik",
          "openalex_id": "A5017797236",
          "orcid": "https://orcid.org/0000-0002-1982-0901",
          "institutions": [
            "Cardiff University"
          ]
        },
        {
          "name": "Lilian Edwards",
          "openalex_id": "A5101751655",
          "institutions": [
            "Newcastle University"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-22",
      "abstract": "Discriminatory practices in recruitment and hiring are an ongoing issue that is a concern not just for workplace relations, but also for wider understandings of economic justice and inequality. The ability to get and keep a job is a key aspect of participating in society and sustaining livelihoods. Yet the way decisions are made on who is eligible for jobs, and why, are rapidly changing with the advent and growth in uptake of automated hiring systems (AHSs) powered by data-driven tools. Evidence of the extent of this uptake around the globe is scarce, but a recent report estimated that 98% of Fortune 500 companies use Applicant Tracking Systems of some kind in their hiring process, a trend driven by perceived efficiency measures and cost-savings. Key concerns about such AHSs include the lack of transparency and potential limitation of access to jobs for specific profiles. In relation to the latter, however, several of these AHSs claim to detect and mitigate discriminatory practices against protected groups and promote diversity and inclusion at work. Yet whilst these tools have a growing user-base around the world, such claims of 'bias mitigation' are rarely scrutinised and evaluated, and when done so, have almost exclusively been from a US socio-legal perspective.",
      "cited_by_count": 160,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3372849"
      },
      "topics": [
        "Names, Identity, and Discrimination Research",
        "Digital Economy and Work Transformation",
        "Ethics and Social Impacts of AI"
      ],
      "referenced_works_count": 35,
      "url": "https://openalex.org/W3001765450"
    },
    {
      "openalex_id": "W3035878793",
      "doi": "10.1080/2330443x.2020.1791773",
      "title": "The Essential Role of Empirical Validation in Legislative Redistricting Simulation",
      "authors": [
        {
          "name": "Benjamin Fifield",
          "openalex_id": "A5045890446",
          "orcid": "https://orcid.org/0000-0002-2247-0201",
          "institutions": [
            "Harvard University",
            "Quantitative BioSciences"
          ]
        },
        {
          "name": "Kosuke Imai",
          "openalex_id": "A5015451961",
          "orcid": "https://orcid.org/0000-0002-2748-1022",
          "institutions": [
            "Harvard University Press",
            "Quantitative BioSciences",
            "Harvard University"
          ]
        },
        {
          "name": "Jun Kawahara",
          "openalex_id": "A5011892434",
          "orcid": "https://orcid.org/0000-0001-7208-044X",
          "institutions": [
            "Kyoto University"
          ]
        },
        {
          "name": "Christopher T Kenny",
          "openalex_id": "A5056106270",
          "orcid": "https://orcid.org/0000-0002-9386-6860",
          "institutions": [
            "Harvard University Press"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-01",
      "abstract": "As granular data about elections and voters become available, redistricting simulation methods are playing an increasingly important role when legislatures adopt redistricting plans and courts determine their legality. These simulation methods are designed to yield a representative sample of all redistricting plans that satisfy statutory guidelines and requirements such as contiguity, population parity, and compactness. A proposed redistricting plan can be considered gerrymandered if it constitutes an outlier relative to this sample according to partisan fairness metrics. Despite their growing use, an insufficient effort has been made to empirically validate the accuracy of the simulation methods. We apply a recently developed computational method that can efficiently enumerate all possible redistricting plans and yield an independent sample from this population. We show that this algorithm scales to a state with a couple of hundred geographical units. Finally, we empirically examine how existing simulation methods perform on realistic validation datasets.",
      "cited_by_count": 18,
      "type": "article",
      "source": {
        "name": "Statistics and Public Policy",
        "type": "journal",
        "issn": [
          "2330-443X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.tandfonline.com/doi/pdf/10.1080/2330443X.2020.1791773?needAccess=true"
      },
      "topics": [
        "Electoral Systems and Political Participation",
        "Judicial and Constitutional Studies",
        "Game Theory and Voting Systems"
      ],
      "referenced_works_count": 26,
      "url": "https://openalex.org/W3035878793"
    }
  ],
  "count": 30,
  "errors": []
}
