{
  "status": "success",
  "source": "semantic_scholar",
  "query": "measurement theory fairness",
  "results": [
    {
      "paperId": "391b291fe355151208d9911079623f6b7a807b9a",
      "title": "Navigating fairness: introducing the multidimensional AIM-FAIR scale for evaluating AI decision-making",
      "authors": [
        {
          "name": "Nico Ehrhardt",
          "authorId": "2357402901"
        },
        {
          "name": "Manuela Renn",
          "authorId": "2357413915"
        },
        {
          "name": "Sonja Utz",
          "authorId": "2357421377"
        }
      ],
      "year": 2025,
      "abstract": "People\u2019s concerns regarding the fairness of algorithmic decision-making, coupled with its expanding utilization across various spheres of our lives underscores the need for robust measures to assess perceived fairness in standardized survey research. Existing fairness scales often suffer from inadequate content coverage, particularly in terms of Perceived Group Discrimination, and frequently employ suboptimal measurement methods, such as single-item assessments. This paper introduces the AIM-FAIR scale, a multidimensional tool grounded in classical test theory, employing Likert-scaled answering options and a reflective measurement model. Developed through four studies (n\u2009=\u20091777) and validated in both English and German, the scale includes 17 items across five subscales: Perceived Consistency, Perceived Equity, Perceived Group Bias, Perceived Manipulability, and Perceived (Explanatory) Transparency. Both language versions demonstrate excellent fit indices and consistent measurement invariance across diverse backgrounds, languages, and conditions. The AIM-FAIR scale offers higher ecological validity and a more comprehensive framework for evaluating fairness in ADM, enhancing cross-cultural and cross-linguistic research on AI fairness.",
      "citationCount": 0,
      "doi": "10.1007/s00146-025-02354-2",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/391b291fe355151208d9911079623f6b7a807b9a",
      "venue": "Ai & Society",
      "journal": {
        "name": "AI & SOCIETY",
        "pages": "6181 - 6199",
        "volume": "40"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "6e9d033cdb84e2632415a6b3181c08734e87fb7c",
      "title": "Pairwise Fairness in Ranking as a Dissatisfaction Measure",
      "authors": [
        {
          "name": "Alessandro Fabris",
          "authorId": "35340264"
        },
        {
          "name": "Gianmaria Silvello",
          "authorId": "1508853659"
        },
        {
          "name": "Gian Antonio Susto",
          "authorId": "3126083"
        },
        {
          "name": "Asia J. Biega",
          "authorId": "31908706"
        }
      ],
      "year": 2023,
      "abstract": "Fairness and equity have become central to ranking problems in information access systems, such as search engines, recommender systems, or marketplaces. To date, several types of fair ranking measures have been proposed, including diversity, exposure, and pairwise fairness measures. Out of those, pairwise fairness is a family of metrics whose normative grounding has not been clearly explicated, leading to uncertainty with respect to the construct that is being measured and how it relates to stakeholders' desiderata. In this paper, we develop a normative and behavioral grounding for pairwise fairness in ranking. Leveraging measurement theory and user browsing models, we derive an interpretation of pairwise fairness centered on the construct of producer dissatisfaction, tying pairwise fairness to perceptions of ranking quality. Highlighting the key limitations of prior pairwise measures, we introduce a set of reformulations that allow us to capture behavioral and practical aspects of ranking systems. These reformulations form the basis for a novel pairwise metric of producer dissatisfaction. Our analytical and empirical study demonstrates the relationship between dissatisfaction, pairwise, and exposure-based fairness metrics, enabling informed adoption of the measures.",
      "citationCount": 9,
      "doi": "10.1145/3539597.3570459",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6e9d033cdb84e2632415a6b3181c08734e87fb7c",
      "venue": "Web Search and Data Mining",
      "journal": {
        "name": "Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "8fca7b9bf6f484ab3a872ca1b457433deae300c0",
      "title": "Towards Fair Rankings: Leveraging LLMs for Gender Bias Detection and Measurement",
      "authors": [
        {
          "name": "Maryam Mousavian",
          "authorId": "2371072568"
        },
        {
          "name": "Zahra Abbasiantaeb",
          "authorId": "2277449569"
        },
        {
          "name": "Mohammad Aliannejadi",
          "authorId": "2126243285"
        },
        {
          "name": "Fabio Crestani",
          "authorId": "2362625531"
        }
      ],
      "year": 2025,
      "abstract": "The presence of social biases in Natural Language Processing (NLP) and Information Retrieval (IR) systems is an ongoing challenge, which underlines the importance of developing robust approaches to identifying and evaluating such biases. In this paper, we aim to address this issue by leveraging Large Language Models ( LLM s) to detect and measure gender bias in passage ranking. Existing gender fairness metrics rely on lexical- and frequency-based measures, leading to various limitations, e.g., missing subtle gender disparities. Building on our LLM-based gender bias detection method, we introduce a novel gender fairness metric, named Class-wise Weighted Exposure ( CWEx), aiming to address existing limitations. To measure the effectiveness of our proposed metric and study LLMs' effectiveness on detecting gender bias, we annotate a subset of the MS MARCO Passage Ranking collection and release our new gender bias collection, called MSMGenderBias, to foster future research in this area. Our extensive experimental results on various ranking models show that our proposed metric offers a more detailed evaluation of fairness compared to previous metrics, with improved alignment to human labels (58.77% for Grep-BiasIR, and 18.51% for MSMGenderBias, measured using Cohen's \u03ba agreement), effectively distinguishing gender bias in ranking. By integrating LLM-driven bias detection, an improved fairness metric, and gender bias annotations for an established dataset, this work provides a more robust framework for analyzing and mitigating bias in IR systems.",
      "citationCount": 0,
      "doi": "10.1145/3731120.3744620",
      "arxivId": "2506.22372",
      "url": "https://www.semanticscholar.org/paper/8fca7b9bf6f484ab3a872ca1b457433deae300c0",
      "venue": "International Conference on the Theory of Information Retrieval",
      "journal": {
        "name": "Proceedings of the 2025 International ACM SIGIR Conference on Innovative Concepts and Theories in Information Retrieval (ICTIR)"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle"
      ]
    },
    {
      "paperId": "8719b5185445d793153a507ba5622397183eaad1",
      "title": "Towards a Just Theory of Measurement: A Principled Social Measurement Assurance Program for Machine Learning",
      "authors": [
        {
          "name": "McKane Andrus",
          "authorId": "144916965"
        },
        {
          "name": "T. Gilbert",
          "authorId": "50708404"
        }
      ],
      "year": 2019,
      "abstract": "While formal definitions of fairness in machine learning (ML) have been proposed, its place within a broader institutional model of fair decision-making remains ambiguous. In this paper we interpret ML as a tool for revealing when and how measures fail to capture purported constructs of interest, augmenting a given institution's understanding of its own interventions and priorities. Rather than codifying \"fair\" principles into ML models directly, the use of ML can thus be understood as a form of quality assurance for existing institutions, exposing the epistemic fault lines of their own measurement practices. Drawing from Friedler et al's [2016] recent discussion of representational mappings and previous discussions on the ontology of measurement, we propose a social measurement assurance program (sMAP) in which ML encourages expert deliberation on a given decision-making procedure by examining unanticipated or previously unexamined covariates. As an example, we apply Rawlsian principles of fairness to sMAP and produce a provisional just theory of measurement that would guide the use of ML for achieving fairness in the case of child abuse in Allegheny County.",
      "citationCount": 4,
      "doi": "10.1145/3306618.3314275",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/8719b5185445d793153a507ba5622397183eaad1",
      "venue": "AAAI/ACM Conference on AI, Ethics, and Society",
      "journal": {
        "name": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "f0614083925047d81aa685e45b1a00cbb1880868",
      "title": "Shapley-Value based Contribution Measurement for Federated Learning on Blood Cells",
      "authors": [
        {
          "name": "Qihao Xu",
          "authorId": "2302514913"
        }
      ],
      "year": 2024,
      "abstract": "Federated Learning (FL) enables decentralized machine learning across multiple entities without sharing centralized datasets, making it crucial for privacy-sensitive domains like healthcare. However, the lack of fair compensation mechanisms can deter data contributions. This paper introduces a Shapley Value-based Contribution Measurement (SVCM) method for FL on blood cells, using cooperative game theory to ensure fair and accurate reward distribution. Compared to traditional Leave- One-Out (LOO) methods, SVCM offers significant improvements in fairness and computational efficiency. Experimental results indicate that SVCM effectively measures each client's contribution in imbalanced data scenarios, ensuring fair compensation and promoting sustainable collaborative learning. This advancement can enhance medical research and patient care by encouraging broader adoption of federated learning in healthcare.",
      "citationCount": 0,
      "doi": "10.1145/3700486.3700518",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f0614083925047d81aa685e45b1a00cbb1880868",
      "venue": "Proceedings of the 2024 International Conference on Biomedicine and Intelligent Technology",
      "journal": {
        "name": "Proceedings of the 2024 International Conference on Biomedicine and Intelligent Technology"
      },
      "publicationTypes": [
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "61e76588ed8bc6dc626130668de7466b8a434da4",
      "title": "Foundational Competencies in Educational Measurement",
      "authors": [
        {
          "name": "Terry A. Ackerman",
          "authorId": "2260545185"
        },
        {
          "name": "D. Bandalos",
          "authorId": "3633140"
        },
        {
          "name": "Derek C. Briggs",
          "authorId": "2260546347"
        },
        {
          "name": "Howard T. Everson",
          "authorId": "2232762943"
        },
        {
          "name": "Andrew D. Ho",
          "authorId": "2260394587"
        },
        {
          "name": "Susan M. Lottridge",
          "authorId": "2286715283"
        },
        {
          "name": "Matthew J. Madison",
          "authorId": "46206146"
        },
        {
          "name": "S. Sinharay",
          "authorId": "5107025"
        },
        {
          "name": "Michael C. Rodriguez",
          "authorId": "2241841055"
        },
        {
          "name": "Michaeline Russell",
          "authorId": "116287803"
        },
        {
          "name": "Alina A. von Davier",
          "authorId": "2244702105"
        },
        {
          "name": "Stefanie A. Wind",
          "authorId": "13269164"
        }
      ],
      "year": 2023,
      "abstract": "This article presents the consensus of an National Council on Measurement in Education Presidential Task Force on Foundational Competencies in Educational Measurement. Foundational competencies are those that support future development of additional professional and disciplinary competencies. The authors develop a framework for foundational competencies in educational measurement, illustrate how educational measurement programs can help learners develop these competencies, and demonstrate how foundational competencies continue to develop in educational measurement professions. The framework introduces three foundational competency domains: Communication and Collaboration Competencies; Technical, Statistical, and Computational Competencies; and Educational Measurement Competencies. Within the Educational Measurement Competency domain, the authors identify five subdomains: Social, Cultural, Historical, and Political Context; Validity, Validation, and Fairness; Theory and Instrumentation; Precision and Generalization; and Psychometric Modeling.",
      "citationCount": 18,
      "doi": "10.1111/emip.12581",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/61e76588ed8bc6dc626130668de7466b8a434da4",
      "venue": "Educational Measurement: Issues and Practice",
      "journal": {
        "name": "Educational Measurement: Issues and Practice"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "33c8d13791dda2cce5e7dc16f7dd47269972c5c3",
      "title": "Taxonomizing Representational Harms using Speech Act Theory",
      "authors": [
        {
          "name": "Emily Corvi",
          "authorId": "2331328154"
        },
        {
          "name": "Hannah Washington",
          "authorId": "2331328697"
        },
        {
          "name": "Stefanie Reed",
          "authorId": "2331328972"
        },
        {
          "name": "Chad Atalla",
          "authorId": "2262214618"
        },
        {
          "name": "Alexandra Chouldechova",
          "authorId": "2331327624"
        },
        {
          "name": "P. A. Dow",
          "authorId": "2331330472"
        },
        {
          "name": "J. Garcia-Gathright",
          "authorId": "1409210718"
        },
        {
          "name": "Nicholas Pangakis",
          "authorId": "2219329724"
        },
        {
          "name": "Emily Sheng",
          "authorId": "2262215122"
        },
        {
          "name": "Dan Vann",
          "authorId": "2219634949"
        },
        {
          "name": "Matthew Vogel",
          "authorId": "2331328798"
        },
        {
          "name": "Hanna M. Wallach",
          "authorId": "2058607401"
        }
      ],
      "year": 2025,
      "abstract": "Representational harms are widely recognized among fairness-related harms caused by generative language systems. However, their definitions are commonly under-specified. We make a theoretical contribution to the specification of representational harms by introducing a framework, grounded in speech act theory (Austin, 1962), that conceptualizes representational harms caused by generative language systems as the perlocutionary effects (i.e., real-world impacts) of particular types of illocutionary acts (i.e., system behaviors). Building on this argument and drawing on relevant literature from linguistic anthropology and sociolinguistics, we provide new definitions of stereotyping, demeaning, and erasure. We then use our framework to develop a granular taxonomy of illocutionary acts that cause representational harms, going beyond the high-level taxonomies presented in previous work. We also discuss the ways that our framework and taxonomy can support the development of valid measurement instruments. Finally, we demonstrate the utility of our framework and taxonomy via a case study that engages with recent conceptual debates about what constitutes a representational harm and how such harms should be measured.",
      "citationCount": 3,
      "doi": "10.48550/arXiv.2504.00928",
      "arxivId": "2504.00928",
      "url": "https://www.semanticscholar.org/paper/33c8d13791dda2cce5e7dc16f7dd47269972c5c3",
      "venue": "Annual Meeting of the Association for Computational Linguistics",
      "journal": {
        "pages": "3907-3932"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "09d68d1a24cce6887b140229f1c42ee2eeeecd24",
      "title": "Bayesian Modeling of Intersectional Fairness: The Variance of Bias",
      "authors": [
        {
          "name": "James R. Foulds",
          "authorId": "40289577"
        },
        {
          "name": "Rashidul Islam",
          "authorId": "47755547"
        },
        {
          "name": "Kamrun Keya",
          "authorId": "52028519"
        },
        {
          "name": "Shimei Pan",
          "authorId": "2239443126"
        }
      ],
      "year": 2018,
      "abstract": "Intersectionality is a framework that analyzes how interlocking systems of power and oppression affect individuals along overlapping dimensions including race, gender, sexual orientation, class, and disability. Intersectionality theory therefore implies it is important that fairness in artificial intelligence systems be protected with regard to multi-dimensional protected attributes. However, the measurement of fairness becomes statistically challenging in the multi-dimensional setting due to data sparsity, which increases rapidly in the number of dimensions, and in the values per dimension. We present a Bayesian probabilistic modeling approach for the reliable, data-efficient estimation of fairness with multi-dimensional protected attributes, which we apply to two existing intersectional fairness metrics. Experimental results on census data and the COMPAS criminal justice recidivism dataset demonstrate the utility of our methodology, and show that Bayesian methods are valuable for the modeling and measurement of fairness in an intersectional context.",
      "citationCount": 43,
      "doi": "10.1137/1.9781611976236.48",
      "arxivId": "1811.07255",
      "url": "https://www.semanticscholar.org/paper/09d68d1a24cce6887b140229f1c42ee2eeeecd24",
      "venue": "SDM",
      "journal": {
        "pages": "424-432"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "d19bfa11b79da2c36f061282413fc8f2f9f11ca2",
      "title": "Detector-Device-Independent Quantum Key Agreement Based on Single-Photon Bell State Measurement",
      "authors": [
        {
          "name": "Yuguang Yang",
          "authorId": "119607802"
        },
        {
          "name": "Xin Lv",
          "authorId": "48574888"
        },
        {
          "name": "Shang Gao",
          "authorId": "145369990"
        },
        {
          "name": "Yihua Zhou",
          "authorId": "47943320"
        },
        {
          "name": "Wei-Min shi",
          "authorId": "39934984"
        }
      ],
      "year": 2022,
      "abstract": null,
      "citationCount": 16,
      "doi": "10.1007/s10773-022-05052-7",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d19bfa11b79da2c36f061282413fc8f2f9f11ca2",
      "venue": "International Journal of Theoretical Physics",
      "journal": {
        "name": "International Journal of Theoretical Physics",
        "volume": "61"
      },
      "publicationTypes": null
    },
    {
      "paperId": "09936edd29edf31c58bc7e21cb0a656cc8e827f8",
      "title": "Measuring perceived procedural fairness in the context of power grid expansion",
      "authors": [
        {
          "name": "C. Mueller",
          "authorId": "34478520"
        },
        {
          "name": "S. I. Keil",
          "authorId": "2106054284"
        }
      ],
      "year": 2019,
      "abstract": "Governments and energy operators are often confronted with opposition to the construction of new high-voltage transmission lines. Besides other factors, a potential determinant of public opposition and acceptance that has gained increasing attention is the fairness of the planning and approval procedure as perceived by the citizens. The purpose of this study is to develop and validate a scale for measuring perceived procedural fairness (PPF).,The authors developed the ten-item \u201cperceived procedural fairness scale (PPFS)\u201d and assessed its quality by means of item response theory. By using a Rasch rating scale model, the authors tested whether the instrument met the requirements of this kind of measurement model. For conducting their research, the authors used data from two telephone surveys in Germany that were collected in areas that are affected by grid expansion.,The findings suggest that the scale can be considered a reliable and internal valid instrument for measuring citizens\u2019 PPF.,At the moment, there is no psychometrically rigorously evaluated scale available for measuring PPF in the context of power grid expansion. Therefore, the study contributes to filling this gap and provides a valuable tool for researchers and practitioners concerned with further investigating citizens\u2019 PPF and its relationships with other relevant constructs in the field.",
      "citationCount": 3,
      "doi": "10.1108/IJESM-02-2019-0002",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/09936edd29edf31c58bc7e21cb0a656cc8e827f8",
      "venue": "",
      "journal": {
        "name": "International Journal of Energy Sector Management",
        "pages": "85-107",
        "volume": "14"
      },
      "publicationTypes": [
        "Review"
      ]
    },
    {
      "paperId": "f02943be205f7ae319b5a8d497521cb7b5eed9e4",
      "title": "Scale development of decent work among logistics digital gig workers",
      "authors": [
        {
          "name": "Tu Lyu",
          "authorId": "122062095"
        },
        {
          "name": "Qixiang Geng",
          "authorId": "40756081"
        },
        {
          "name": "Hao Chen",
          "authorId": "2242179338"
        }
      ],
      "year": 2025,
      "abstract": "PurposeThis paper aims to examine the dimensional structure of decent work perception among logistics digital gig workers (LDGWs) and develop a measurement scale to capture their unique work experiences under the platform economy and algorithmic management context.Design/methodology/approachThe study used a mixed-methods approach, gathering qualitative data through semi-structured interviews with 31 LDGWs. Core dimensions of decent work perception were derived using literature review and grounded theory. A measurement scale was then developed, with 321 valid questionnaires collected and validated using exploratory factor analysis, confirmatory factor analysis and reliability and validity tests.FindingsThe decent work perception among LDGWs was conceptualized into four dimensions: respect and fairness, freedom and autonomy, safety and reliability and confidence and fulfillment. The scale exhibited strong reliability and validity, proving effective in measuring decent work perception among LDGWs.Originality/valueThis research deconstructs the conceptual framework of decent work perception among LDGWs, broadening the dimensions of decent work for this emerging group in the digital economy. It enriches theoretical studies on decent work in the context of the platform economy and algorithmic management. Furthermore, to our knowledge, this study develops the first measurement scale for this topic, offering a foundational tool for subsequent quantitative research.",
      "citationCount": 2,
      "doi": "10.1108/ijpdlm-11-2024-0463",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f02943be205f7ae319b5a8d497521cb7b5eed9e4",
      "venue": "International Journal of Physical Distribution &amp; Logistics Management",
      "journal": {
        "name": "International Journal of Physical Distribution &amp; Logistics Management"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "409fc1e7e63fc5aba1fb7a94697739ba663853ab",
      "title": "Trustworthy AI Meets Educational Assessment: Challenges and Opportunities",
      "authors": [
        {
          "name": "Sheng Li",
          "authorId": "2357328330"
        }
      ],
      "year": 2025,
      "abstract": "Artificial intelligence (AI) has made substantial impacts in numerous fields, including education. Within education, learning and assessment are two key areas. Although many AI techniques have been applied to improve teaching and learning, their potential in educational assessment remains underexplored. This paper explores the intersection of AI and educational assessment and presents a rich landscape of challenges and opportunities, especially in the context of trustworthy AI, including fairness, transparency, accountability, explainability, and robustness. We will begin by outlining the foundations of trustworthy AI and educational assessment. Next, we will delve into the application of trustworthy AI for various assessment tasks, such as test item generation, test design, and automated scoring. In addition, the talk will also discuss how insights from educational measurement theory, such as item response theory (IRT) and validity frameworks, can inform the development and evaluation of trustworthy AI models. These frameworks help ensure that AI systems in education are not only accurate, but also equitable and aligned with educational goals. Finally, we will highlight future research directions, focusing on the integration of ethical AI principles into educational technology and the need for interdisciplinary collaboration to tackle the emerging challenges in this field. The aim is to foster a new generation of AI-powered educational tools that are both innovative and trustworthy, ultimately contributing to a more equitable and more effective educational landscape.",
      "citationCount": 0,
      "doi": "10.1609/aaai.v39i27.35089",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/409fc1e7e63fc5aba1fb7a94697739ba663853ab",
      "venue": "AAAI Conference on Artificial Intelligence",
      "journal": {
        "pages": "28637-28642"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "98a5195cf723ac69ca194262fe8ea00e57008c92",
      "title": "Personalized Cluster-Based Model Adaptation for Non-IID Federated Systems",
      "authors": [
        {
          "name": "Yuncheng Ge",
          "authorId": "2375168310"
        },
        {
          "name": "Huiwei Wang",
          "authorId": "2375089877"
        }
      ],
      "year": 2025,
      "abstract": "The emergence of federated learning (FL) addresses the critical challenge of \u201cdata silos\u201d caused by privacy regulations, policy constraints, and commercial confidentiality that restrict cross-source data sharing. While FL enables collaborative model training without raw data exchange, studies demonstrate that global model performance heavily relies on consistent participation of high-quality clients. However, real-world scenarios often involve heterogeneous data quality across clients, leading to unfair treatment during training and potential client dropout. This creates a participation paradox: despite FL's privacy preservation, the substantial computational costs discourage clients lacking fair compensation from sustained engagement. Motivating active and equitable collaboration therefore remains a pivotal challenge. Current fairness-enhancing approaches exhibit notable limitations. Shapley value-based contribution measurement methods, while effective for horizontal FL, fail to generalize across federated architectures. Reputation-based iterative frameworks attempt to quantify client value but suffer from subjective evaluation metrics and lack rigorous data quality assessment protocols. To overcome these limitations, we propose FedPC - a dual-phase fairness optimization framework. Server-side label-aware clustering aggregates clients with semantic similarity, while client-side personalized model training ensures task-specific adaptation. Evaluations on EMNIST and CIFAR-10 demonstrate FedPC's superiority: it achieves higher fairness scores than baseline FL methods (e.g., FedAvg, FedProx) while maintaining competitive accuracy, striking an optimal balance between collaborative equity and model efficacy.",
      "citationCount": 0,
      "doi": "10.1109/MiTA66017.2025.11100174",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/98a5195cf723ac69ca194262fe8ea00e57008c92",
      "venue": "2025 12th International Conference on Machine Intelligence Theory and Applications (MiTA)",
      "journal": {
        "name": "2025 12th International Conference on Machine Intelligence Theory and Applications (MiTA)",
        "pages": "1-6"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "7fceea12948da25b5f17ba5938511575ba505be9",
      "title": "Where Assessment Validation and Responsible AI Meet",
      "authors": [
        {
          "name": "Jill Burstein",
          "authorId": "2320804931"
        },
        {
          "name": "Geoffrey T. LaFlair",
          "authorId": "2279237573"
        }
      ],
      "year": 2025,
      "abstract": "The core principles of validity, reliability, and fairness have been the foundation of ethical assessment practices, as discussed in classical validation theories (e.g., Chapelle et al., 2008; Kane, 1992, 2013) and the American Educational Research Association (AERA), the American Psychological Association (APA), and the National Council on Measurement in Education Standards (NCME) (AERA & APA & NCME, 2014). The Standards have provided best practices for AI use in high-stakes testing, particularly in the automated scoring of written and spoken responses. Responsible AI (RAI) is essential across industry domains, including educational assessments. With recent advancements in generative AI, new policies and guidance on applying RAI principles in assessment have emerged. Expanding on Chapelle et al.'s (2008) work, this paper introduces a unified assessment framework that integrates traditional validation theory with both assessment-specific and domain-agnostic RAI principles. This framework supports responsible AI use, aligns with ethical principles to uphold human values and oversight, and promotes broader social responsibility in AI-driven assessments.",
      "citationCount": 0,
      "doi": "10.32038/ltrq.2025.50.09",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7fceea12948da25b5f17ba5938511575ba505be9",
      "venue": "Language Teaching Research Quarterly",
      "journal": {
        "name": "Language Teaching Research Quarterly"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "eea7f46712dbd0c173b28e61033c73d9d748fa8b",
      "title": "The Influence of Cybersecurity Preventive Controls on the Effectiveness of Data Protection in Commercial Banks: A Case of NMB Bank PLC",
      "authors": [
        {
          "name": "Fikiri Lucas Matonya",
          "authorId": "2198824717"
        },
        {
          "name": "Paul Dotto Mazoya",
          "authorId": "2386755283"
        }
      ],
      "year": 2025,
      "abstract": "This study explores the influence of cybersecurity preventive controls on the effectiveness of data protection in commercial banks, using NMB Bank PLC as a case study. The study is grounded in Protection Motivation Theory (PMT). A descriptive research design was employed and adopted a quantitative approach, allowing for objective measurement and statistical analysis of data collected. The targeted population consisted of 183 employees from five key departments across NMB Bank\u2019s Dar es Salaam branches. Using Yamane\u2019s formula, a sample size of 126 respondents was determined, and participants were selected through simple random sampling to ensure fairness and reduce selection bias. Data collection was conducted through structured questionnaires utilizing a five-point Likert scale. The survey method enabled efficient and consistent data collection from a broad sample. Data were analyzed using both descriptive and inferential statistics through SPSS Version 26. Descriptive statistics summarized demographic characteristics and response patterns, while multiple linear regression was applied to examine the relationships between independent variables (cybersecurity controls) and the dependent variable (data protection). The findings revealed that access control and network security had strong, statistically significant positive effects on data protection effectiveness, while staff training did not show a significant direct impact. The study concludes that while NMB Bank has made considerable efforts in cybersecurity, ongoing improvements in technology, enforcement, and management support are essential. The study contributes practical insights for banking institutions and policymakers aiming to enhance cybersecurity resilience in the face of evolving digital threats.",
      "citationCount": 0,
      "doi": "10.22457/jmi.v29a01258",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/eea7f46712dbd0c173b28e61033c73d9d748fa8b",
      "venue": "Journal of Mathematics and Informatics",
      "journal": {
        "name": "Journal of Mathematics and Informatics"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "8a00a9513cb8c79809799155d4652c346babeb0a",
      "title": "Measurement of the Intensity of the Creative Works while RnD Projects are Carrying Out, on the Fuzzy Expert Model",
      "authors": [
        {
          "name": "V. Koretskiy",
          "authorId": "107701239"
        },
        {
          "name": "R. Galiakhmetov",
          "authorId": "90715806"
        }
      ],
      "year": 2020,
      "abstract": ". The article describes fuzzy logic approach and theory of complexity in term of work measurement for brain-creative work bound to research and development intensity to be estimated. The idea that the intensity of the creative-and brain-work can be estimated through its product complexity is put forward. It is suggested that new knowledge is a product of creative work and its complexity can be evaluated by expert linguistic rating. To turn linguistic rating of new knowledge novelty, competency and business capacity into numerical data fuzzy logic expert system, which enables linguistic assessment on the product of labor to be quantified, was developed. The relevance of this study follows from essential place of labor regulation for both economic vantage point, legal regulation and social fairness in HR-management. Reasonable labor standards for creative work not only enable productivity increasing, but also ensure fair salary and even staff loading by work pressure. The paper describes an approach to the complexity of creative work as research and development, in terms of the theory of complexity proven before for machinery, that is, based on the assessment of the complexity of the product of labor. Due to the fact that the product of creative, research, work is \"new knowledge\", to assess their complexity was developed fuzzy expert model. It enables to quantify qualitative assessment of the product of creative or brain-work - \"new knowledge\" in terms of the necessary competencies to gain demanded gains, the prospects and novelty of the results of creative work. On the basis of the proposed approach, the dependence of labor intensity in terms of the duration of work on the complexity of the designed \"product of labor\" for research and development work was obtained. This dependence is a tool for assessing the time spent on the implementation of unique research and development projects which include \u201cinvisible\u201d and undetectable brain-work. This determines the practical usage of this work\u2019s results which could be used for the planning of research and development works, the assessment",
      "citationCount": 1,
      "doi": "10.2991/aebmr.k.200312.104",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/8a00a9513cb8c79809799155d4652c346babeb0a",
      "venue": "Proceedings of the International Scientific Conference \"Far East Con\" (ISCFEC 2020)",
      "journal": {
        "name": "Proceedings of the International Scientific Conference \"Far East Con\" (ISCFEC 2020)"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "6a053b4b3cfeb21ac1eb88d4bfe1a522bc0639c8",
      "title": "Transparency: Motivations and Challenges",
      "authors": [
        {
          "name": "Adrian Weller",
          "authorId": "145689461"
        }
      ],
      "year": 2019,
      "abstract": null,
      "citationCount": 163,
      "doi": "10.1007/978-3-030-28954-6_2",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/6a053b4b3cfeb21ac1eb88d4bfe1a522bc0639c8",
      "venue": "Explainable AI",
      "journal": {
        "pages": "23-40"
      },
      "publicationTypes": [
        "Review"
      ]
    },
    {
      "paperId": "99663ad36cd86fcb37ac80934197e9160b67f0f9",
      "title": "Detecting uniform differential item functioning for continuous response computerized adaptive testing",
      "authors": [
        {
          "name": "Chun Wang",
          "authorId": "2118346982"
        },
        {
          "name": "Ruoyi Zhu",
          "authorId": "2152147011"
        }
      ],
      "year": 2024,
      "abstract": "Evaluating items for potential differential item functioning (DIF) is an essential step to ensuring measurement fairness. In this article, we focus on a specific scenario, namely, the continuous response, severely sparse, computerized adaptive testing (CAT). Continuous responses items are growingly used in performance-based tasks because they tend to generate more information than traditional dichotomous items. Severe sparsity arises when many items are automatically generated via machine learning algorithms. We propose two uniform DIF detection methods in this scenario. The first is a modified version of the CAT-SIBTEST, a non-parametric method that does not depend on any specific item response theory model assumptions. The second is a regularization method, a parametric, model-based approach. Simulation studies show that both methods are effective in correctly identifying items with uniform DIF. A real data analysis is provided in the end to illustrate the utility and potential caveats of the two methods.",
      "citationCount": 3,
      "doi": "10.1177/01466216241227544",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/99663ad36cd86fcb37ac80934197e9160b67f0f9",
      "venue": "Applied Psychological Measurement",
      "journal": {
        "name": "Applied Psychological Measurement",
        "pages": "18 - 37",
        "volume": "48"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "eda91e7b3ba0aa6c53d78ee2618ea88ff2f71c40",
      "title": "Cognitive Load Theory for Test Design",
      "authors": [
        {
          "name": "Peter A. Beddow",
          "authorId": "15143917"
        }
      ],
      "year": 2018,
      "abstract": null,
      "citationCount": 3,
      "doi": "10.1007/978-3-319-71126-3_13",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/eda91e7b3ba0aa6c53d78ee2618ea88ff2f71c40",
      "venue": "",
      "journal": {
        "name": "",
        "pages": "199-211",
        "volume": ""
      },
      "publicationTypes": [
        "Review"
      ]
    },
    {
      "paperId": "9ef80d2f1034fe251f27a5dfc2d342eb1854da5a",
      "title": "From Optimizing Engagement to Measuring Value",
      "authors": [
        {
          "name": "S. Milli",
          "authorId": "3458938"
        },
        {
          "name": "Luca Belli",
          "authorId": "1564617568"
        },
        {
          "name": "Moritz Hardt",
          "authorId": "1775622"
        }
      ],
      "year": 2020,
      "abstract": "Most recommendation engines today are based on predicting user engagement, e.g. predicting whether a user will click on an item or not. However, there is potentially a large gap between engagement signals and a desired notion of value that is worth optimizing for. We use the framework of measurement theory to (a) confront the designer with a normative question about what the designer values, (b) provide a general latent variable model approach that can be used to operationalize the target construct and directly optimize for it, and (c) guide the designer in evaluating and revising their operationalization. We implement our approach on the Twitter platform on millions of users. In line with established approaches to assessing the validity of measurements, we perform a qualitative evaluation of how well our model captures a desired notion of \"value\".",
      "citationCount": 56,
      "doi": "10.1145/3442188.3445933",
      "arxivId": "2008.12623",
      "url": "https://www.semanticscholar.org/paper/9ef80d2f1034fe251f27a5dfc2d342eb1854da5a",
      "venue": "Conference on Fairness, Accountability and Transparency",
      "journal": {
        "name": "Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "b04dd98a500d1f3937e8b672ef00012e3b75fc12",
      "title": "Psychometrics in Behavioral Software Engineering: A Methodological Introduction with Guidelines",
      "authors": [
        {
          "name": "D. Graziotin",
          "authorId": "1963315"
        },
        {
          "name": "Per Lenberg",
          "authorId": "3007951"
        },
        {
          "name": "R. Feldt",
          "authorId": "145278906"
        },
        {
          "name": "S. Wagner",
          "authorId": "49859108"
        }
      ],
      "year": 2020,
      "abstract": "A meaningful and deep understanding of the human aspects of software engineering (SE) requires psychological constructs to be considered. Psychology theory can facilitate the systematic and sound development as well as the adoption of instruments (e.g., psychological tests, questionnaires) to assess these constructs. In particular, to ensure high quality, the psychometric properties of instruments need evaluation. In this article, we provide an introduction to psychometric theory for the evaluation of measurement instruments for SE researchers. We present guidelines that enable using existing instruments and developing new ones adequately. We conducted a comprehensive review of the psychology literature framed by the Standards for Educational and Psychological Testing. We detail activities used when operationalizing new psychological constructs, such as item pooling, item review, pilot testing, item analysis, factor analysis, statistical property of items, reliability, validity, and fairness in testing and test bias. We provide an openly available example of a psychometric evaluation based on our guideline. We hope to encourage a culture change in SE research towards the adoption of established methods from psychology. To improve the quality of behavioral research in SE, studies focusing on introducing, validating, and then using psychometric instruments need to be more common.",
      "citationCount": 38,
      "doi": "10.1145/3469888",
      "arxivId": "2005.09959",
      "url": "https://www.semanticscholar.org/paper/b04dd98a500d1f3937e8b672ef00012e3b75fc12",
      "venue": "ACM Transactions on Software Engineering and Methodology",
      "journal": {
        "name": "ACM Trans. Softw. Eng. Methodol.",
        "pages": "7:1-7:36",
        "volume": "31"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "40dbd97cfba2d2d819ed3194d6a3b5717cfbe44d",
      "title": "FARMUR: Fair Adversarial Retraining to Mitigate Unfairness in Robustness",
      "authors": [
        {
          "name": "S. A. Mousavi",
          "authorId": "2111714087"
        },
        {
          "name": "H. Mousavi",
          "authorId": "2086872050"
        },
        {
          "name": "M. Daneshtalab",
          "authorId": "2066349677"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 2,
      "doi": "10.1007/978-3-031-42914-9_10",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/40dbd97cfba2d2d819ed3194d6a3b5717cfbe44d",
      "venue": "Symposium on Advances in Databases and Information Systems",
      "journal": {
        "pages": "133-145"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "c19eeeee9ad2754f4e905cfef01bc9fa61c75bfc",
      "title": "Novel Multi-Party Quantum Key Agreement Protocol with G-Like States and Bell States",
      "authors": [
        {
          "name": "Shi-Qi Min",
          "authorId": "104221187"
        },
        {
          "name": "Hua-Ying Chen",
          "authorId": "47666042"
        },
        {
          "name": "L. Gong",
          "authorId": "2610911"
        }
      ],
      "year": 2018,
      "abstract": null,
      "citationCount": 31,
      "doi": "10.1007/s10773-018-3706-6",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/c19eeeee9ad2754f4e905cfef01bc9fa61c75bfc",
      "venue": "International Journal of Theoretical Physics",
      "journal": {
        "name": "International Journal of Theoretical Physics",
        "pages": "1811 - 1822",
        "volume": "57"
      },
      "publicationTypes": null
    },
    {
      "paperId": "74c6ff31bd73a23ccb77fa99b855c8f329c05dec",
      "title": "Measuring algorithmic interpretability: A human-learning-based framework and the corresponding cognitive complexity score",
      "authors": [
        {
          "name": "John P. Lalor",
          "authorId": "9051130"
        },
        {
          "name": "Hong Guo",
          "authorId": "2166024589"
        }
      ],
      "year": 2022,
      "abstract": "Algorithmic interpretability is necessary to build trust, ensure fairness, and track accountability. However, there is no existing formal measurement method for algorithmic interpretability. In this work, we build upon programming language theory and cognitive load theory to develop a framework for measuring algorithmic interpretability. The proposed measurement framework reflects the process of a human learning an algorithm. We show that the measurement framework and the resulting cognitive complexity score have the following desirable properties - universality, computability, uniqueness, and monotonicity. We illustrate the measurement framework through a toy example, describe the framework and its conceptual underpinnings, and demonstrate the benefits of the framework, in particular for managers considering tradeoffs when selecting algorithms.",
      "citationCount": 1,
      "doi": "10.48550/arXiv.2205.10207",
      "arxivId": "2205.10207",
      "url": "https://www.semanticscholar.org/paper/74c6ff31bd73a23ccb77fa99b855c8f329c05dec",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2205.10207"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "592e4b41e3b5f689a95efd1664a496f3ce293d1c",
      "title": "Joint Update Rate Adaptation in Multiplayer Cloud-Edge Gaming Services: Spatial Geometry and Performance Tradeoffs",
      "authors": [
        {
          "name": "Saadallah Kassir",
          "authorId": "20855652"
        },
        {
          "name": "G. Veciana",
          "authorId": "1757522"
        },
        {
          "name": "N. Wang",
          "authorId": "144050305"
        },
        {
          "name": "Xi Wang",
          "authorId": "2108248630"
        },
        {
          "name": "P. Palacharla",
          "authorId": "2852679"
        }
      ],
      "year": 2021,
      "abstract": "In this paper, we analyze the performance of Multiplayer Cloud Gaming (MCG) systems. To that end, we introduce a model and new MCG-Quality of Service (QoS) metric that captures the freshness of the players' updates and fairness in their gaming experience. We introduce an efficient measurement-based Joint Multiplayer Rate Adaptation (JMRA) algorithm that optimizes the MCG-QoS by overcoming large (possibly varying) network transport delays by increasing the associated players' update rates. The resulting MCG-QoS is shown to be Schur-concave in the network delays, leading to natural characterizations and performance comparisons associated with the players' spatial geometry and network congestion. In particular, joint rate adaptation enables service providers to combat variability in network delays and players' geographic spread to achieve high service coverage. This, in turn, allows us to explore the spatial density and capacity of compute resources that need to be provisioned. Finally, we leverage tools from majorization theory, to show how service placement decisions can be made to improve the robustness of the MCG-QoS to stochastic network delays.",
      "citationCount": 2,
      "doi": "10.1145/3466772.3467048",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/592e4b41e3b5f689a95efd1664a496f3ce293d1c",
      "venue": "ACM Interational Symposium on Mobile Ad Hoc Networking and Computing",
      "journal": {
        "name": "Proceedings of the Twenty-second International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "cba25bf85872692f64c7bbcae67b6131be523a04",
      "title": "Optimal allocation of quantum resources",
      "authors": [
        {
          "name": "R. Salazar",
          "authorId": "2077461906"
        },
        {
          "name": "Tanmoy Biswas",
          "authorId": "47934086"
        },
        {
          "name": "Jakub Czartowski",
          "authorId": "102487459"
        },
        {
          "name": "K. \u017byczkowski",
          "authorId": "2360503"
        },
        {
          "name": "P. Horodecki",
          "authorId": "40546232"
        }
      ],
      "year": 2020,
      "abstract": "The optimal allocation of resources is a crucial task for their efficient use in a wide range of practical applications in science and engineering. This paper investigates the optimal allocation of resources in multipartite quantum systems. In particular, we show the relevance of proportional fairness and optimal reliability criteria for the application of quantum resources. Moreover, we present optimal allocation solutions for an arbitrary number of qudits using measurement incompatibility as an exemplary resource theory. Besides, we study the criterion of optimal equitability and demonstrate its relevance to scenarios involving several resource theories such as nonlocality vs local contextuality. Finally, we highlight the potential impact of our results for quantum networks and other multi-party quantum information processing, in particular to the future Quantum Internet.",
      "citationCount": 3,
      "doi": "10.22331/Q-2021-03-10-407",
      "arxivId": "2006.16134",
      "url": "https://www.semanticscholar.org/paper/cba25bf85872692f64c7bbcae67b6131be523a04",
      "venue": "Quantum",
      "journal": {
        "name": "Quantum",
        "pages": "407",
        "volume": "5"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "3a4b34343f5b9f6b17c864e0ca3e3c67029cfa01",
      "title": "Accounting for Digital Assets Between Accounting Measurement Theory and Financial Disclosure Requirements",
      "authors": [
        {
          "name": "Nada Salman Habib",
          "authorId": "2386277458"
        }
      ],
      "year": 2025,
      "abstract": "The current research aims to examine the accounting of digital assets by linking accounting measurement theory to financial disclosure requirements, in light of the challenges related to the absence of specialized international accounting standards for digital assets. The research was divided into two parts: theoretical and applied. The theoretical part included a review of the literature related to accounting measurement (historical cost, fair value, and impairment model) and financial disclosure requirements according to International Financial Reporting Standards (IAS/IFRS) and American standards (FASB, AICPA, and SEC). The applied part used a questionnaire and administered to a sample of financial report users, including academics and professionals, to obtain their opinions on the adequacy of current measurement models, financial disclosure requirements, and shortcomings in international standards. It also explored the possibility of formulating an integrated framework for measuring and disclosing digital assets. The results of the analysis of the questionnaire showed that fair value measurement is more appropriate for the nature of digital assets than traditional models, with the need to enhance disclosure of risks associated with price volatility, liquidity, and operational risks. It also showed that the absence of a specific accounting standard for digital assets leads to poor comparability and increased variation in accounting practices across economic entities. Based on the survey results, an integrated theoretical framework for accounting for digital assets was proposed. This framework includes principles of recognition, measurement, and disclosure, and contributes to achieving the objectives of financial reporting in accordance with the International Accounting Standards Board (IASB) conceptual framework, ensuring relevance, accurate representation, comparability, clarity, and timeliness. The study concluded that developing a specialized accounting framework for digital assets represents a strategic necessity to ensure the reliability and transparency of financial reporting and enhance user confidence, given the rapid growth in the adoption of digital assets within global economic activities. \u00a0",
      "citationCount": 0,
      "doi": "10.20525/ijfbs.v14i4.4547",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/3a4b34343f5b9f6b17c864e0ca3e3c67029cfa01",
      "venue": "International Journal of Finance &amp; Banking Studies (2147-4486)",
      "journal": {
        "name": "International Journal of Finance &amp; Banking Studies (2147-4486)"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "a30d5f2f10cef8af4efd4f929dfe2ce90c8b3010",
      "title": "Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory",
      "authors": [
        {
          "name": "Ziang Xiao",
          "authorId": "9605732"
        },
        {
          "name": "Susu Zhang",
          "authorId": "116270523"
        },
        {
          "name": "Vivian Lai",
          "authorId": "120801533"
        },
        {
          "name": "Q. Liao",
          "authorId": "144921048"
        }
      ],
      "year": 2023,
      "abstract": "We address a fundamental challenge in Natural Language Generation (NLG) model evaluation -- the design and evaluation of evaluation metrics. Recognizing the limitations of existing automatic metrics and noises from how current human evaluation was conducted, we propose MetricEval, a framework informed by measurement theory, the foundation of educational test design, for conceptualizing and evaluating the reliability and validity of NLG evaluation metrics. The framework formalizes the source of measurement error and offers statistical tools for evaluating evaluation metrics based on empirical data. With our framework, one can quantify the uncertainty of the metrics to better interpret the result. To exemplify the use of our framework in practice, we analyzed a set of evaluation metrics for summarization and identified issues related to conflated validity structure in human-eval and reliability in LLM-based metrics. Through MetricEval, we aim to promote the design, evaluation, and interpretation of valid and reliable metrics to advance robust and effective NLG models.",
      "citationCount": 41,
      "doi": "10.18653/v1/2023.emnlp-main.676",
      "arxivId": "2305.14889",
      "url": "https://www.semanticscholar.org/paper/a30d5f2f10cef8af4efd4f929dfe2ce90c8b3010",
      "venue": "Conference on Empirical Methods in Natural Language Processing",
      "journal": {
        "pages": "10967-10982"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "7a558482e817dde05dae98134243847241491cb9",
      "title": "A unifying and general account of fairness measurement in recommender systems",
      "authors": [
        {
          "name": "Enrique Amig\u00f3",
          "authorId": "1688716"
        },
        {
          "name": "Yashar Deldjoo",
          "authorId": "2614755"
        },
        {
          "name": "Stefano Mizzaro",
          "authorId": "1726978"
        },
        {
          "name": "Alejandro Bellog\u00edn",
          "authorId": "1738219"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 45,
      "doi": "10.1016/j.ipm.2022.103115",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7a558482e817dde05dae98134243847241491cb9",
      "venue": "Information Processing & Management",
      "journal": {
        "name": "Inf. Process. Manag.",
        "pages": "103115",
        "volume": "60"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "e5345c603d7fbba85af6cf6bf0b8684c9e795731",
      "title": "The Measuring Hate Speech Corpus: Leveraging Rasch Measurement Theory for Data Perspectivism",
      "authors": [
        {
          "name": "Pratik S. Sachdeva",
          "authorId": "11052891"
        },
        {
          "name": "Renata Barreto",
          "authorId": "2171360824"
        },
        {
          "name": "Geoff Bacon",
          "authorId": "48520992"
        },
        {
          "name": "A. Sahn",
          "authorId": "31287550"
        },
        {
          "name": "Claudia Von Vacano",
          "authorId": "2167139000"
        },
        {
          "name": "Chris J Kennedy",
          "authorId": "2175478907"
        }
      ],
      "year": 2022,
      "abstract": null,
      "citationCount": 81,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e5345c603d7fbba85af6cf6bf0b8684c9e795731",
      "venue": "NLPERSPECTIVES",
      "journal": {
        "pages": "83-94"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    }
  ],
  "count": 30,
  "errors": []
}
