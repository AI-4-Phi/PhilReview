{
  "status": "success",
  "source": "semantic_scholar",
  "query": "sparse data fairness",
  "results": [
    {
      "paperId": "d1919f92e1758fd4585ead0b3300b158bcd0cfb5",
      "title": "Graph Contrastive Learning for Optimizing Sparse Data in Recommender Systems with LightGCL",
      "authors": [
        {
          "name": "Aravinda Jatavallabha",
          "authorId": "2314917728"
        },
        {
          "name": "Prabhanjan Bharadwaj",
          "authorId": "2364745038"
        },
        {
          "name": "Ashish Chander",
          "authorId": "2364746822"
        }
      ],
      "year": 2025,
      "abstract": "Graph Neural Networks (GNNs) are powerful tools for recommendation systems, but they often struggle under data sparsity and noise. To address these issues, we implemented LightGCL, a graph contrastive learning model that uses Singular Value Decomposition (SVD) for robust graph augmentation, preserving semantic integrity without relying on stochastic or heuristic perturbations. LightGCL enables structural refinement and captures global collaborative signals, achieving significant gains over state-of-the-art models across benchmark datasets. Our experiments also demonstrate improved fairness and resilience to popularity bias, making it well-suited for real-world recommender systems.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2506.00048",
      "arxivId": "2506.00048",
      "url": "https://www.semanticscholar.org/paper/d1919f92e1758fd4585ead0b3300b158bcd0cfb5",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.00048"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "5a6f008a60cef2c5af266779dc3391f61e362e20",
      "title": "Optimizing sample diversity with fairness constraints on imbalanced, sparse, hiring data",
      "authors": [
        {
          "name": "Lauren R. McCarey",
          "authorId": "2176868958"
        },
        {
          "name": "Thomas S. McTavish",
          "authorId": "1825239"
        }
      ],
      "year": 2022,
      "abstract": "There are many cases where one may wish to retrieve non-random, diverse, and fair samples from an imbalanced dataset. With over 90K tech job descriptions and corresponding resumes that applied to those jobs, we describe our approach using evolutionary algorithms to derive a diverse and gender-fair subset for use in validating ML algorithms. Since 3/4 of the applicants were male, we had an imbalanced dataset. We describe how, through the use of evolutionary algorithms, we were able to discover different characteristics between genders as well as recognize issues with sparse representations. We constructed additional optimizing objectives to rectify these issues to ultimately unearth a desired sample.",
      "citationCount": 0,
      "doi": "10.1145/3520304.3529028",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/5a6f008a60cef2c5af266779dc3391f61e362e20",
      "venue": "GECCO Companion",
      "journal": {
        "name": "Proceedings of the Genetic and Evolutionary Computation Conference Companion"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book"
      ]
    },
    {
      "paperId": "48ce814c63e0a95cadc01d80f57dc8496901f3e2",
      "title": "A Federated Learning Study on Bias and Fairness in Small Data Medical Applications",
      "authors": [
        {
          "name": "Pratik Korat",
          "authorId": "2378635213"
        },
        {
          "name": "Kirthika Ashokkumar",
          "authorId": "2089489658"
        },
        {
          "name": "Sakina Rahman",
          "authorId": "2340949276"
        },
        {
          "name": "Palak Agarwal",
          "authorId": "2340529434"
        },
        {
          "name": "Mahima Agumbe Suresh",
          "authorId": "2282320075"
        }
      ],
      "year": 2025,
      "abstract": "Important concerns when using medical data for Machine Learning (ML) is patient privacy and bias. Federated Learning (FL), the training of a centralized model by using parameters from decentralized models, is alternatively used to protect patient privacy. Medical data can often be structured and sparse, where deep learning is not applicable. Besides, medical applications are at risk for biases in model accuracies for different populations, such as gender bias, age bias, etc. This work studies the efficacy of federated learning for small data medical applications and explore bias and fairness in these models arising from a federated learning setting.",
      "citationCount": 0,
      "doi": "10.1109/BigDataService65758.2025.00044",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/48ce814c63e0a95cadc01d80f57dc8496901f3e2",
      "venue": "International Conference on Big Data Computing Service and Applications",
      "journal": {
        "name": "2025 IEEE 11th International Conference on Big Data Computing Service and Machine Learning Applications (BigDataService)",
        "pages": "244-248"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "127d368c18b53b1c5abcd74283d3c2554c5d06b1",
      "title": "Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation",
      "authors": [
        {
          "name": "Saba Kublashvili",
          "authorId": "2395676474"
        }
      ],
      "year": 2025,
      "abstract": "Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N<<100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.",
      "citationCount": 0,
      "doi": null,
      "arxivId": "2512.01723",
      "url": "https://www.semanticscholar.org/paper/127d368c18b53b1c5abcd74283d3c2554c5d06b1",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "1efe2baede90ef6558c995ef83c2ce1c4777683d",
      "title": "SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents",
      "authors": [
        {
          "name": "Dawei Li",
          "authorId": "2161635474"
        },
        {
          "name": "Zhen Tan",
          "authorId": "2329877609"
        },
        {
          "name": "Peijia Qian",
          "authorId": "2329183307"
        },
        {
          "name": "Yifan Li",
          "authorId": "2267393864"
        },
        {
          "name": "Kumar Satvik Chaudhary",
          "authorId": "2353089861"
        },
        {
          "name": "Lijie Hu",
          "authorId": "2329392212"
        },
        {
          "name": "Jiayi Shen",
          "authorId": "2329363913"
        }
      ],
      "year": 2024,
      "abstract": "While multi-agent systems have been shown to significantly enhance the performance of Large Language Models (LLMs) across various tasks and applications, the dense interaction between scaling agents potentially hampers their efficiency and diversity. To address these challenges, we draw inspiration from the sparse mixture-of-agents (SMoE) and propose a sparse mixture-of-agents (SMoA) framework to improve the efficiency and diversity of multi-agent LLMs. Unlike completely connected structures, SMoA introduces novel Response Selection and Early Stopping mechanisms to sparsify information flows among individual LLM agents, striking a balance between performance and efficiency. Additionally, inspired by the expert diversity principle in SMoE frameworks for workload balance between experts, we assign distinct role descriptions to each LLM agent, fostering diverse and divergent thinking. Extensive experiments on reasoning, alignment, and fairness benchmarks demonstrate that SMoA achieves performance comparable to traditional mixture-of-agents approaches but with significantly lower computational costs. Further analysis reveals that SMoA is more stable, has a greater capacity to scale, and offers considerable potential through hyper-parameter optimization. Code and data will be available at: https://github.com/David-Li0406/SMoA.",
      "citationCount": 22,
      "doi": "10.48550/arXiv.2411.03284",
      "arxivId": "2411.03284",
      "url": "https://www.semanticscholar.org/paper/1efe2baede90ef6558c995ef83c2ce1c4777683d",
      "venue": "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
      "journal": {
        "pages": "54-65"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "8f489fdfe974d128fb38a7511496d5d9fbe90439",
      "title": "Improving Group Fairness in Tensor Completion via Imbalance Mitigating Entity Augmentation",
      "authors": [
        {
          "name": "Dawon Ahn",
          "authorId": "2308098862"
        },
        {
          "name": "Jun-Gi Jang",
          "authorId": "2370172276"
        },
        {
          "name": "Evangelos E. Papalexakis",
          "authorId": "2058719607"
        }
      ],
      "year": 2025,
      "abstract": "Group fairness is important to consider in tensor decomposition to prevent discrimination based on social grounds such as gender or age. Although few works have studied group fairness in tensor decomposition, they suffer from performance degradation. To address this, we propose STAFF(Sparse Tensor Augmentation For Fairness) to improve group fairness by minimizing the gap in completion errors of different groups while reducing the overall tensor completion error. Our main idea is to augment a tensor with augmented entities including sufficient observed entries to mitigate imbalance and group bias in the sparse tensor. We evaluate \\method on tensor completion with various datasets under conventional and deep learning-based tensor models. STAFF consistently shows the best trade-off between completion error and group fairness; at most, it yields 36% lower MSE and 59% lower MADE than the second-best baseline.",
      "citationCount": 0,
      "doi": "10.1007/978-981-96-8173-0_3",
      "arxivId": "2507.20542",
      "url": "https://www.semanticscholar.org/paper/8f489fdfe974d128fb38a7511496d5d9fbe90439",
      "venue": "Pacific-Asia Conference on Knowledge Discovery and Data Mining",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2507.20542"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "bd5d6fa21dd68363891ffa5dbe38d2194c9dc65f",
      "title": "Reinforcement Learning for Airport Slot Allocation: Incorporating Fairness and Trade-off Analysis",
      "authors": [
        {
          "name": "Anh Nguyen-Duy",
          "authorId": "2310257523"
        },
        {
          "name": "D. Pham",
          "authorId": "9648272"
        }
      ],
      "year": 2025,
      "abstract": "Airport Slot Allocation plays a vital role in managing airport congestion. Approaches for Airport Slot Allocation range from exact methods to searching-based methods. Due to the scalability problem of exact methods, the literature is shifting to using searching-based methods, such as heuristics and learning-based methods. While heuristics are prone to changing scenarios, learning-based methods, on the other hand, can self-evolve with updated data. Reinforcement Learning, a learning-based approach, can automate the search and explore new solutions when the search space changes. Reinforcement Learning has been studied for Airport Slot Allocation. However, few have incorporated fairness, an important criterion in resource allocation. Incorporating fairness into Reinforcement Learning formulations heavily depends on the reward design. A sparse reward design can lead to non-convergence. A dense reward design, on the contrary, may not closely resemble the objectives, minimizing the total displacement and maintaining fairness. In this paper, we study how to efficiently incorporate fairness, via the mini-max criterion, the principle of proportionality, and the constrained-based approach, into Reinforcement Learning formulations. To incorporate via the constrained-based approach, we limit the number of actions, which correspondingly depict the maximum displacement the Reinforcement Learning agent can assign to a movement. For the other two remaining fairness approaches, we represent the fairness objective along with the minimizing displacement objective in terms of reward signals either at each time step (i.e., dense rewards) or only at terminal states (i.e., spare rewards). We perform validations with the OAG data of the Hong Kong-Singapore-Bangkok hub. Results show that giving dense reward signals significantly optimizes the objective of minimizing the total displacement, from an average of 297.53 to 124.07, for the principle-of-proportionality models. The extra dense reward signals for maintaining fairness, however, fail to achieve convergence. Removing the reward signals for the minimizing displacement objective at each time step helps to maintain proportional fairness, but increases the total displacement.",
      "citationCount": 0,
      "doi": "10.1109/ICNS65417.2025.10976764",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/bd5d6fa21dd68363891ffa5dbe38d2194c9dc65f",
      "venue": "International Conference on Networking and Services",
      "journal": {
        "name": "2025 Integrated Communications, Navigation and Surveillance Conference (ICNS)",
        "pages": "1-9"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "f9f1e88d887fee4e1baea70658c24fb2484c75d5",
      "title": "Dual-Channel Adaptive Graph Convolutional Network for Long-Tail Fairness in Recommender Systems",
      "authors": [
        {
          "name": "Zihan Wu",
          "authorId": "2396308463"
        },
        {
          "name": "Kai Zhu",
          "authorId": "2396455529"
        },
        {
          "name": "Haibo Ye",
          "authorId": "2286942032"
        }
      ],
      "year": 2025,
      "abstract": "Recommender systems, widely adopted in e-commerce and social media, face growing fairness challenges due to imbalanced data distributions. Existing systems often struggle with sparse interactions from long-tail users, whose preferences are overshadowed by the dominant interactions of head users, resulting in biased recommendations. This limits the scope of personalized services and undermines user trust. To address this issue, we propose the Dual-Channel Adaptive Graph Convolutional Network (DCAGCN), which incorporates degree-aware weighted aggregation and dual-channel representation learning. Specifically, we introduce a degree-aware weighted aggregation mechanism, applied post-convolution, to dynamically assign weights and enhance representation learning for low-degree nodes. Additionally, a dual-channel architecture separately models the dense interaction patterns of head users and the sparse features of tail users, effectively reducing representation overlap. Experiments show that DCAGCN surpasses existing methods in recommendation performance and fairness optimization, providing an efficient solution for personalized recommendations in sparse scenarios.",
      "citationCount": 0,
      "doi": "10.1109/AANN66429.2025.11257679",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/f9f1e88d887fee4e1baea70658c24fb2484c75d5",
      "venue": "2025 5th International Conference on Advanced Algorithms and Neural Networks (AANN)",
      "journal": {
        "name": "2025 5th International Conference on Advanced Algorithms and Neural Networks (AANN)",
        "pages": "426-430"
      },
      "publicationTypes": [
        "Conference"
      ]
    },
    {
      "paperId": "eec34094dce613a56a21d17faa6f894c06612538",
      "title": "Size-adaptive Hypothesis Testing for Fairness",
      "authors": [
        {
          "name": "Antonio Ferrara",
          "authorId": "2363021345"
        },
        {
          "name": "Francesco Cozzi",
          "authorId": "2363020699"
        },
        {
          "name": "Alan Perotti",
          "authorId": "2305344957"
        },
        {
          "name": "Andr\u00e9 Panisson",
          "authorId": "2326949752"
        },
        {
          "name": "Francesco Bonchi",
          "authorId": "2302649716"
        }
      ],
      "year": 2025,
      "abstract": "Determining whether an algorithmic decision-making system discriminates against a specific demographic typically involves comparing a single point estimate of a fairness metric against a predefined threshold. This practice is statistically brittle: it ignores sampling error and treats small demographic subgroups the same as large ones. The problem intensifies in intersectional analyses, where multiple sensitive attributes are considered jointly, giving rise to a larger number of smaller groups. As these groups become more granular, the data representing them becomes too sparse for reliable estimation, and fairness metrics yield excessively wide confidence intervals, precluding meaningful conclusions about potential unfair treatments. In this paper, we introduce a unified, size-adaptive, hypothesis-testing framework that turns fairness assessment into an evidence-based statistical decision. Our contribution is twofold. (i) For sufficiently large subgroups, we prove a Central-Limit result for the statistical parity difference, leading to analytic confidence intervals and a Wald test whose type-I (false positive) error is guaranteed at level $\\alpha$. (ii) For the long tail of small intersectional groups, we derive a fully Bayesian Dirichlet-multinomial estimator; Monte-Carlo credible intervals are calibrated for any sample size and naturally converge to Wald intervals as more data becomes available. We validate our approach empirically on benchmark datasets, demonstrating how our tests provide interpretable, statistically rigorous decisions under varying degrees of data availability and intersectionality.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2506.10586",
      "arxivId": "2506.10586",
      "url": "https://www.semanticscholar.org/paper/eec34094dce613a56a21d17faa6f894c06612538",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2506.10586"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "966d392f41f350121f0a4334938ecd167c810df5",
      "title": "Multi-User Sparse Vector Coding for eXtreme Ultra-Reliable Low-Latency Communication in Beyond 5G",
      "authors": [
        {
          "name": "Sundaresan Sabapathy",
          "authorId": "2043636164"
        },
        {
          "name": "Surendar Maruthu",
          "authorId": "95323510"
        },
        {
          "name": "DushanthaNalin K. Jayakody",
          "authorId": "1581170567"
        }
      ],
      "year": 2025,
      "abstract": "Short A short packet transmission scheme, such as Sparse Vector Coding (SVC), is a primary candidate for achieving ultra-low latency and high-reliability communication (URLLC). This paper proposes a spectral-efficient multi-user SVC (MU-SVC) scheme for achieving next-generation URLLC or eXtreme URLLC (xURLLC) in beyond 5G (B5G) communications. The key idea is to transmit multiple user information within a single sparse vector where the users are segregated into far users (FU) and near users (NU) depending on the distance from the base station. The classification into FU and NU paves way to optimize resource allocation, user fairness, manage interference, ensure reliable communication and quality of service requirements. Firstly, the FU binary data is converted into a sparse vector and secondly, the NU data is modulated and embedded into the non-zero positions of the sparse vector to form an MU-SVC. On transmission, the FU data is obtained through sparse demapping, while the NU adopts symbol detection techniques like the maximum likelihood detector. A new performance metric, called position error rate (PoER), is introduced to study the performance of the FU since it is based on the correct identification of the non-zero positions. Theoretical analyses of PoER and symbol error rate (SER) were carried out for FU and NU, respectively and the results are also validated through Monte-Carlo simulations. Further, the bit error rate, complexity, spectral and latency analyses are performed for MU-SVC and compared with the SVC and enhanced SVC schemes. The simulation results demonstrate an improved spectral efficiency and low latency with high reliability for the proposed MU-SVC scheme, thus, achieving xURLLC with reduced complexity in the multi-user scenario for B5G.",
      "citationCount": 0,
      "doi": "10.1109/ACCESS.2025.3551398",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/966d392f41f350121f0a4334938ecd167c810df5",
      "venue": "IEEE Access",
      "journal": {
        "name": "IEEE Access",
        "pages": "56780-56792",
        "volume": "13"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "52c26cf62cb1439e51cfff55febef518ad59bad6",
      "title": "Integrating Sparse Reward Handling, Ethical Considerations, And Domain-Specific Adaptation In RlBased Machine Translation For Low-Resource Languages",
      "authors": [
        {
          "name": "Aakansha Jagga",
          "authorId": "2327926228"
        }
      ],
      "year": 2024,
      "abstract": "Effective communication across languages remains a critical challenge, particularly in low-resource settings where conventional machine translation approaches falter due to sparse data and limited quality feedback. This paper presents a holistic framework to enhance reinforcement learning (RL) based machine translation systems tailored for such environments. We address the trifecta of challenges: sparse feedback on translation quality, ethical implications in algorithmic decision-making, and the imperative to adapt models to nuanced linguistic domains. This approach integrates advanced techniques in sparse reward handling, ensuring RL models learn efficiently despite limited feedback. Ethical considerations drive our methodology, emphasizing fairness, bias mitigation, and cultural sensitivity to uphold ethical standards in AI-driven translations. Additionally, domain-specific adaptation strategies are explored to tailor models to diverse linguistic contexts, from technical jargon to colloquialisms, enhancing translation accuracy and relevance. Through a rigorous experimental framework, including evaluation metrics like BLEU score and user feedback, we demonstrate substantial improvements in translation quality and ethical compliance compared to traditional methods. This research contributes to the evolution of robust, inclusive translation technologies pivotal for fostering global understanding and equitable access to information. This paper not only addresses current challenges but also sets a precedent for future research in AI ethics and machine learning applications, advocating for responsible innovation in crosscultural communication technologies",
      "citationCount": 0,
      "doi": "10.9790/0661-2605035660",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/52c26cf62cb1439e51cfff55febef518ad59bad6",
      "venue": "IOSR Journal of Computer Engineering",
      "journal": {
        "name": "IOSR Journal of Computer Engineering"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "763db652794422c6f159a3d0540f45c4a030f916",
      "title": "Deep Neural Network Denoising Model Based on Sparse Representation Algorithm for ECG Signal",
      "authors": [
        {
          "name": "Yanrong Hou",
          "authorId": "2211064306"
        },
        {
          "name": "Rui-xia Liu",
          "authorId": "144603882"
        },
        {
          "name": "M. Shu",
          "authorId": "8006041"
        },
        {
          "name": "Xiaoyun Xie",
          "authorId": "2035524379"
        },
        {
          "name": "Changfang Chen",
          "authorId": "2874907"
        }
      ],
      "year": 2023,
      "abstract": "Electrocardiogram (ECG) denoising is very important for heart disease diagnosis. The traditional ECG denoising models have problems such as single noise type and poor interpretability of deep neural networks. The innovation of the proposed method is to incorporate the precious achievements of traditional methods into the design of neural networks and to build a bridge between them. Therefore, a novel interpretable deep denoising framework based on sparse representation is proposed in this study, and the half quadratic splitting (HQS) algorithm is applied to decompose the denoising method into sparse representations as an iterative solution process. In addition, a new weight distribution (WD) module is designed to extract adaptive hyperparameters based on ECG correlation instead of empirical values and greatly improves the efficiency of hyperparameter selection. To demonstrate the fairness and effectiveness of the proposed method, four different denoising models with different data preprocessing techniques are used for comparison. The extensive experimental validation and simulation studies demonstrated that the proposed framework has an excellent performance in quantitative and visual evaluation.",
      "citationCount": 30,
      "doi": "10.1109/TIM.2023.3251408",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/763db652794422c6f159a3d0540f45c4a030f916",
      "venue": "IEEE Transactions on Instrumentation and Measurement",
      "journal": {
        "name": "IEEE Transactions on Instrumentation and Measurement",
        "pages": "1-11",
        "volume": "72"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "8b5289e0742ea077a808e3d00df95feb5b16915d",
      "title": "Batched Online Contextual Sparse Bandits with Sequential Inclusion of Features",
      "authors": [
        {
          "name": "Rowan Swiers",
          "authorId": "2051304171"
        },
        {
          "name": "Subash Prabanantham",
          "authorId": "73323272"
        },
        {
          "name": "Andrew Maher",
          "authorId": "2063976610"
        }
      ],
      "year": 2024,
      "abstract": "Multi-armed Bandits (MABs) are increasingly employed in online platforms and e-commerce to optimize decision making for personalized user experiences. In this work, we focus on the Contextual Bandit problem with linear rewards, under conditions of sparsity and batched data. We address the challenge of fairness by excluding irrelevant features from decision-making processes using a novel algorithm, Online Batched Sequential Inclusion (OBSI), which sequentially includes features as confidence in their impact on the reward increases. Our experiments on synthetic data show the superior performance of OBSI compared to other algorithms in terms of regret, relevance of features used, and compute.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2409.09199",
      "arxivId": "2409.09199",
      "url": "https://www.semanticscholar.org/paper/8b5289e0742ea077a808e3d00df95feb5b16915d",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2409.09199"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "82f537b09319fd57ac3c08d09bdb817eb0c64779",
      "title": "Towards Gender Fairness for Mental Health Prediction",
      "authors": [
        {
          "name": "Jiaee Cheong",
          "authorId": "2139995247"
        },
        {
          "name": "S. Kuzucu",
          "authorId": "2191683599"
        },
        {
          "name": "Sinan Kalkan",
          "authorId": "48382704"
        },
        {
          "name": "Hatice Gunes",
          "authorId": "150122398"
        }
      ],
      "year": 2023,
      "abstract": "Mental health is becoming an increasingly prominent health challenge. Despite a plethora of studies analysing and mitigating bias for a variety of tasks such as face recognition and credit scoring, research on machine learning (ML) fairness for mental health has been sparse to date. In this work, we focus on gender bias in mental health and make the following contributions. First, we examine whether bias exists in existing mental health datasets and algorithms. Our experiments were conducted using Depresjon, Psykose and D-Vlog. We identify that both data and algorithmic bias exist. Second, we analyse strategies that can be deployed at the pre-processing, in-processing and post-processing stages to mitigate for bias and evaluate their effectiveness. Third, we investigate factors that impact the efficacy of existing bias mitigation strategies and outline recommendations to achieve greater gender fairness for mental health. Upon obtaining counter-intuitive results on D-Vlog dataset, we undertake further experiments and analyses, and provide practical suggestions to avoid hampering bias mitigation efforts in ML for mental health.",
      "citationCount": 19,
      "doi": "10.24963/ijcai.2023/658",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/82f537b09319fd57ac3c08d09bdb817eb0c64779",
      "venue": "International Joint Conference on Artificial Intelligence",
      "journal": {
        "pages": "5932-5940"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "e11b0019357cb30a55d69808b630ee6715903f7e",
      "title": "KGFlex: Efficient Recommendation with Sparse Feature Factorization and Knowledge Graphs",
      "authors": [
        {
          "name": "Antonio Ferrara",
          "authorId": "2056226695"
        },
        {
          "name": "V. W. Anelli",
          "authorId": "2431124"
        },
        {
          "name": "Alberto Carlo Maria Mancino",
          "authorId": "2121913506"
        },
        {
          "name": "T. D. Noia",
          "authorId": "1737962"
        },
        {
          "name": "E. Sciascio",
          "authorId": "1738818"
        }
      ],
      "year": 2023,
      "abstract": "Collaborative filtering models have undoubtedly dominated the scene of recommender systems in recent years. However, due to the little use of content information, they narrowly focus on accuracy, disregarding a higher degree of personalization. Meanwhile, knowledge graphs are arousing considerable interest in recommendation models thanks to their ability to enrich the system with content features that captures subtle user-item relations. Nevertheless, with many high-quality features, the models become more complex and challenging to train. We extend KGFlex [16], a hybrid model that analyzes historical data to understand the semantic features the user decisions depend on. KGFlex represents item features as embeddings, and it models user-item interactions as a factorized entropy-driven combination of the item attributes relevant to the user, thus reducing the complexity and raising the degree of personalization. The method does not neglect long tail items, reducing the popularity bias and ensuring a high level of fairness. The user-item prediction is mediated by the user\u2019s personal views of the embeddings that grant a high degree of expressiveness. This extension analyzes different entropy measurement strategies, an enhanced user negative decision modeling, and assesses the fairness of KGFlex and the impact of its hyperparameters. KGFlex is available at https://split.to/kgflex.",
      "citationCount": 17,
      "doi": "10.1145/3588901",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/e11b0019357cb30a55d69808b630ee6715903f7e",
      "venue": "Trans. Recomm. Syst.",
      "journal": {
        "name": "ACM Transactions on Recommender Systems",
        "pages": "1 - 30",
        "volume": "1"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "d798ff8b0e155c75de642764dd621ccd0a95010a",
      "title": "InFoRM: Individual Fairness on Graph Mining",
      "authors": [
        {
          "name": "Jian Kang",
          "authorId": "2111625448"
        },
        {
          "name": "Jingrui He",
          "authorId": "31108652"
        },
        {
          "name": "Ross Maciejewski",
          "authorId": "1786514"
        },
        {
          "name": "Hanghang Tong",
          "authorId": "8163721"
        }
      ],
      "year": 2020,
      "abstract": "Algorithmic bias and fairness in the context of graph mining have largely remained nascent. The sparse literature on fair graph mining has almost exclusively focused on group-based fairness notation. However, the notion of individual fairness, which promises the fairness notion at a much finer granularity, has not been well studied. This paper presents the first principled study of Individual Fairness on gRaph Mining (InFoRM). First, we present a generic definition of individual fairness for graph mining which naturally leads to a quantitative measure of the potential bias in graph mining results. Second, we propose three mutually complementary algorithmic frameworks to mitigate the proposed individual bias measure, namely debiasing the input graph, debiasing the mining model and debiasing the mining results. Each algorithmic framework is formulated from the optimization perspective, using effective and efficient solvers, which are applicable to multiple graph mining tasks. Third, accommodating individual fairness is likely to change the original graph mining results without the fairness consideration. We conduct a thorough analysis to develop an upper bound to characterize the cost (i.e., the difference between the graph mining results with and without the fairness consideration). We perform extensive experimental evaluations on real-world datasets to demonstrate the efficacy and generality of the proposed methods.",
      "citationCount": 153,
      "doi": "10.1145/3394486.3403080",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d798ff8b0e155c75de642764dd621ccd0a95010a",
      "venue": "Knowledge Discovery and Data Mining",
      "journal": {
        "name": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "86c4bb73bcc10a17faee13034a1742008cb001df",
      "title": "Subgroup Generalization and Fairness of Graph Neural Networks",
      "authors": [
        {
          "name": "Jiaqi W. Ma",
          "authorId": "47793019"
        },
        {
          "name": "Junwei Deng",
          "authorId": "2153368600"
        },
        {
          "name": "Qiaozhu Mei",
          "authorId": "1743469"
        }
      ],
      "year": 2021,
      "abstract": "Despite enormous successful applications of graph neural networks (GNNs), theoretical understanding of their generalization ability, especially for node-level tasks where data are not independent and identically-distributed (IID), has been sparse. The theoretical investigation of the generalization performance is beneficial for understanding fundamental issues (such as fairness) of GNN models and designing better learning methods. In this paper, we present a novel PAC-Bayesian analysis for GNNs under a non-IID semi-supervised learning setup. Moreover, we analyze the generalization performances on different subgroups of unlabeled nodes, which allows us to further study an accuracy-(dis)parity-style (un)fairness of GNNs from a theoretical perspective. Under reasonable assumptions, we demonstrate that the distance between a test subgroup and the training set can be a key factor affecting the GNN performance on that subgroup, which calls special attention to the training node selection for fair learning. Experiments across multiple GNN models and datasets support our theoretical results.",
      "citationCount": 91,
      "doi": null,
      "arxivId": "2106.15535",
      "url": "https://www.semanticscholar.org/paper/86c4bb73bcc10a17faee13034a1742008cb001df",
      "venue": "Neural Information Processing Systems",
      "journal": {
        "pages": "1048-1061"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "9e7904eb77efac909bcf9667a9236de30ebbb48c",
      "title": "Fairness and Sum-Rate Maximization via Joint Subcarrier and Power Allocation in Uplink SCMA Transmission",
      "authors": [
        {
          "name": "Joao V. C. Evangelista",
          "authorId": "143969023"
        },
        {
          "name": "Zeeshan Sattar",
          "authorId": "2561813"
        },
        {
          "name": "Georges Kaddoum",
          "authorId": "2379122"
        },
        {
          "name": "Anas Chaaban",
          "authorId": "3067700"
        }
      ],
      "year": 2018,
      "abstract": "In this work, we consider a sparse code multiple access uplink system, where <inline-formula> <tex-math notation=\"LaTeX\">$J$ </tex-math></inline-formula> users simultaneously transmit data over <inline-formula> <tex-math notation=\"LaTeX\">$K$ </tex-math></inline-formula> subcarriers, such that <inline-formula> <tex-math notation=\"LaTeX\">$J > K$ </tex-math></inline-formula>, with a constraint on the power transmitted by each user. To jointly optimize the subcarrier assignment and the transmitted power per subcarrier, two new iterative algorithms are proposed, the first one aims to maximize the sum-rate (Max-SR) of the network, while the second aims to maximize the fairness (Max-Min). In both cases, the optimization problem is of the mixed-integer nonlinear programming (MINLP) type, with non-convex objective functions, which are generally not tractable. We prove that both joint allocation problems are NP-hard. To address these issues, we employ a variant of the block successive upper-bound minimization (BSUM) framework, obtaining polynomial-time approximation algorithms to the original problem. Moreover, we evaluate the algorithms\u2019 robustness against outdated channel state information (CSI), present an analysis of the convergence of the algorithms, and a comparison of the sum-rate and Jain\u2019s fairness index of the novel algorithms with three other algorithms proposed in the literature. The Max-SR algorithm outperforms the others in the sum-rate sense, while the Max-Min outperforms them in the fairness sense.",
      "citationCount": 43,
      "doi": "10.1109/TWC.2019.2939820",
      "arxivId": "1805.11722",
      "url": "https://www.semanticscholar.org/paper/9e7904eb77efac909bcf9667a9236de30ebbb48c",
      "venue": "IEEE Transactions on Wireless Communications",
      "journal": {
        "name": "IEEE Transactions on Wireless Communications",
        "pages": "5855-5867",
        "volume": "18"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "094d5d4e3df9e1e716b6fe6e1ba1f9088e0001e7",
      "title": "Data-Driven Intelligent Outage Management for High Shadowing Environments in 5G&B Networks",
      "authors": [
        {
          "name": "Waseem Raza",
          "authorId": "48188885"
        },
        {
          "name": "M. Farooq",
          "authorId": "2143502103"
        },
        {
          "name": "Aneeqa Ijaz",
          "authorId": "145032646"
        },
        {
          "name": "Ali Imran",
          "authorId": "2273999536"
        }
      ],
      "year": 2024,
      "abstract": "In the evolving landscape of 5G and forthcoming 6G networks, managing outages becomes increasingly complex due to higher Base Station (BS) densities and the consequent rise in outage instances. Addressing this, we introduce a sophisticated, two-tiered outage management framework that leverages artificial intelligence for enhanced efficiency and automation. Our approach features an innovative AI -based cell outage detection strategy, named Impv-XGBoost, which excels in high-shadowing conditions and with sparse training data, outperforming traditional methods. The framework's second tier employs an actor-critic reinforcement learning scheme for cell outage compensation, finely tuning compensating BS's tilt and transmit power. This method uniquely integrates outage and compensating base station's user equipment coverage, ensuring equitable service quality. By incorporating Jain's fairness index and the geometric mean in its reward mechanism, our approach achieves fair and efficient outage management, demonstrating notable improvements in user coverage during BS outages.",
      "citationCount": 1,
      "doi": "10.1109/SmartNets61466.2024.10577674",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/094d5d4e3df9e1e716b6fe6e1ba1f9088e0001e7",
      "venue": "International Conference on Smart Communications and Networking",
      "journal": {
        "name": "2024 International Conference on Smart Applications, Communications and Networking (SmartNets)",
        "pages": "1-6"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "942a50949d550da3f2ad7dc064d17c2f46791269",
      "title": "VTruST: Controllable value function based subset selection for Data-Centric Trustworthy AI",
      "authors": [
        {
          "name": "Soumili Das",
          "authorId": "89297338"
        },
        {
          "name": "Shubhadip Nag",
          "authorId": "2214199174"
        },
        {
          "name": "Shreyyash Sharma",
          "authorId": "2290671068"
        },
        {
          "name": "Suparna Bhattacharya",
          "authorId": "2238221125"
        },
        {
          "name": "Sourangshu Bhattacharya",
          "authorId": "1609913602"
        }
      ],
      "year": 2024,
      "abstract": "Trustworthy AI is crucial to the widespread adoption of AI in high-stakes applications with fairness, robustness, and accuracy being some of the key trustworthiness metrics. In this work, we propose a controllable framework for data-centric trustworthy AI (DCTAI)- VTruST, that allows users to control the trade-offs between the different trustworthiness metrics of the constructed training datasets. A key challenge in implementing an efficient DCTAI framework is to design an online value-function-based training data subset selection algorithm. We pose the training data valuation and subset selection problem as an online sparse approximation formulation. We propose a novel online version of the Orthogonal Matching Pursuit (OMP) algorithm for solving this problem. Experimental results show that VTruST outperforms the state-of-the-art baselines on social, image, and scientific datasets. We also show that the data values generated by VTruST can provide effective data-centric explanations for different trustworthiness metrics.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2403.05174",
      "arxivId": "2403.05174",
      "url": "https://www.semanticscholar.org/paper/942a50949d550da3f2ad7dc064d17c2f46791269",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2403.05174"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "565377f83dd38dd080b675078e181cf34e5b13c9",
      "title": "Who's the (Multi-)Fairest of Them All: Rethinking Interpolation-Based Data Augmentation Through the Lens of Multicalibration",
      "authors": [
        {
          "name": "Karina Halevy",
          "authorId": "2106627578"
        },
        {
          "name": "Karly Hou",
          "authorId": "2335568210"
        },
        {
          "name": "Charumathi Badrinath",
          "authorId": "2224843950"
        }
      ],
      "year": 2024,
      "abstract": "Data augmentation methods, especially SoTA interpolation-based methods such as Fair Mixup, have been widely shown to increase model fairness. However, this fairness is evaluated on metrics that do not capture model uncertainty and on datasets with only one, relatively large, minority group. As a remedy, multicalibration has been introduced to measure fairness while accommodating uncertainty and accounting for multiple minority groups. However, existing methods of improving multicalibration involve reducing initial training data to create a holdout set for post-processing, which is not ideal when minority training data is already sparse. This paper uses multicalibration to more rigorously examine data augmentation for classification fairness. We stress-test four versions of Fair Mixup on two structured data classification problems with up to 81 marginalized groups, evaluating multicalibration violations and balanced accuracy. We find that on nearly every experiment, Fair Mixup worsens baseline performance and fairness, but the simple vanilla Mixup outperforms both Fair Mixup and the baseline, especially when calibrating on small groups. Combining vanilla Mixup with multicalibration post-processing, which enforces multicalibration through post-processing on a holdout set, further increases fairness.",
      "citationCount": 0,
      "doi": "10.48550/arXiv.2412.10575",
      "arxivId": "2412.10575",
      "url": "https://www.semanticscholar.org/paper/565377f83dd38dd080b675078e181cf34e5b13c9",
      "venue": "AAAI Conference on Artificial Intelligence",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2412.10575"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "a8977adf0d89767b451994e5f563d79bf27d9afc",
      "title": "Privacy-Preserving near Neighbor Search via Sparse Coding with Ambiguation",
      "authors": [
        {
          "name": "Behrooz Razeghi",
          "authorId": "1805092"
        },
        {
          "name": "Sohrab Ferdowsi",
          "authorId": "1682792"
        },
        {
          "name": "Dimche Kostadinov",
          "authorId": "36133844"
        },
        {
          "name": "F. Calmon",
          "authorId": "144717568"
        },
        {
          "name": "S. Voloshynovskiy",
          "authorId": "9428112"
        }
      ],
      "year": 2021,
      "abstract": "In this paper, we propose a framework for privacy-preserving approximate near neighbor search via stochastic sparsifying encoding. The core of the framework relies on sparse coding with ambiguation (SCA) mechanism that introduces the notion of inherent shared secrecy based on the support intersection of sparse codes. This approach is \u2018fairness-aware\u2019, in the sense that any point in the neighborhood has an equiprobable chance to be chosen. Our approach can be applied to raw data, latent representation of autoencoders, and aggregated local descriptors. The proposed method is tested on both synthetic i.i.d data and real image databases.",
      "citationCount": 3,
      "doi": "10.1109/ICASSP39728.2021.9414115",
      "arxivId": "2102.04274",
      "url": "https://www.semanticscholar.org/paper/a8977adf0d89767b451994e5f563d79bf27d9afc",
      "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing",
      "journal": {
        "name": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "pages": "2635-2639"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "7a6d2c880409f70fb730cd77536575561276fcb2",
      "title": "MSE minimized joint transmission in coordinated multipoint systems with sparse feedback and constrained backhaul requirements",
      "authors": [
        {
          "name": "M. B. Nezafati",
          "authorId": "103600880"
        },
        {
          "name": "M. Taki",
          "authorId": "2567023"
        },
        {
          "name": "T. Svensson",
          "authorId": "144793629"
        }
      ],
      "year": 2020,
      "abstract": "In a joint transmission coordinated multipoint (JT-CoMP) system, a shared spectrum is utilized by all neighbor cells. In the downlink, a group of base stations (BSs) coordinately transmit the users\u2019 data to avoid serious interference at the users in the boundary of the cells, thus substantially improving area fairness. However, this comes at the cost of high feedback and backhaul load; In a frequency division duplex system, all users at the cell boundaries have to collect and send feedback of the downlink channel state information (CSI). In centralized JT-CoMP, although with capabilities for perfect coordination, a central coordination node have to send the computed precoding weights and corresponding data to all cells which can overwhelm the backhaul resources. In this paper, we design a JT-CoMP scheme, by which the sum of the mean square error (MSE) at the boundary users is minimized, while feedback and backhaul loads are constrained and the load is balanced between BSs. Our design is based on the singular value decomposition of CSI matrix and optimization of a binary link selection matrix to provide sparse feedback\u2014constrained backhaul link. For comparison, we adopt the previously presented schemes for feedback and backhaul reduction in the physical layer. Extensive numerical evaluations show that the proposed scheme can reduce the MSE with at least 25%\\documentclass[12pt]{minimal} \\usepackage{amsmath} \\usepackage{wasysym} \\usepackage{amsfonts} \\usepackage{amssymb} \\usepackage{amsbsy} \\usepackage{mathrsfs} \\usepackage{upgreek} \\setlength{\\oddsidemargin}{-69pt} \\begin{document}$$25\\%$$\\end{document}, compared to the adopted and existing schemes.",
      "citationCount": 2,
      "doi": "10.1186/s13638-021-01979-3",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/7a6d2c880409f70fb730cd77536575561276fcb2",
      "venue": "EURASIP Journal on Wireless Communications and Networking",
      "journal": {
        "name": "EURASIP Journal on Wireless Communications and Networking",
        "volume": "2021"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "a536e5e27518458e6de17b678c86c77f48c0a47a",
      "title": "TUM Data Innovation Lab",
      "authors": [
        {
          "name": "Paraskevi",
          "authorId": "2230657491"
        },
        {
          "name": "Kiriakidou",
          "authorId": "2231522379"
        },
        {
          "name": "Carlos Llano",
          "authorId": "143691989"
        }
      ],
      "year": 2023,
      "abstract": null,
      "citationCount": 0,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/a536e5e27518458e6de17b678c86c77f48c0a47a",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "fd8f8ce73ea8cf44dbcbd9f303dfc3d97c362347",
      "title": "Fairness and Sum-Rate Maximization via Joint Channel and Power Allocation in Uplink SCMA Networks",
      "authors": [
        {
          "name": "Joao V. C. Evangelista",
          "authorId": "2328294644"
        },
        {
          "name": "Zeeshan Sattar",
          "authorId": "2561813"
        },
        {
          "name": "Georges Kaddoum",
          "authorId": "2319819583"
        },
        {
          "name": "Anas Chaaban",
          "authorId": "2328296755"
        }
      ],
      "year": 2018,
      "abstract": null,
      "citationCount": 3,
      "doi": null,
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/fd8f8ce73ea8cf44dbcbd9f303dfc3d97c362347",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/1805.11722"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2bad289a77848c4e1c2451ddf323d6bb5a9139eb",
      "title": "Evaluate Bias without Manual Test Sets: A Concept Representation Perspective for LLMs",
      "authors": [
        {
          "name": "Lang Gao",
          "authorId": "2336919989"
        },
        {
          "name": "Kaiyang Wan",
          "authorId": "2362633000"
        },
        {
          "name": "Wei Liu",
          "authorId": "2362689122"
        },
        {
          "name": "Chenxi Wang",
          "authorId": "2323526659"
        },
        {
          "name": "Zirui Song",
          "authorId": "2269766748"
        },
        {
          "name": "Zixiang Xu",
          "authorId": "2343776295"
        },
        {
          "name": "Yanbo Wang",
          "authorId": "2362643587"
        },
        {
          "name": "Veselin Stoyanov",
          "authorId": "2362631559"
        },
        {
          "name": "Xiuying Chen",
          "authorId": "2323528016"
        }
      ],
      "year": 2025,
      "abstract": "Bias in Large Language Models (LLMs) significantly undermines their reliability and fairness. We focus on a common form of bias: when two reference concepts in the model's concept space, such as sentiment polarities (e.g.,\"positive\"and\"negative\"), are asymmetrically correlated with a third, target concept, such as a reviewing aspect, the model exhibits unintended bias. For instance, the understanding of\"food\"should not skew toward any particular sentiment. Existing bias evaluation methods assess behavioral differences of LLMs by constructing labeled data for different social groups and measuring model responses across them, a process that requires substantial human effort and captures only a limited set of social concepts. To overcome these limitations, we propose BiasLens, a test-set-free bias analysis framework based on the structure of the model's vector space. BiasLens combines Concept Activation Vectors (CAVs) with Sparse Autoencoders (SAEs) to extract interpretable concept representations, and quantifies bias by measuring the variation in representational similarity between the target concept and each of the reference concepts. Even without labeled data, BiasLens shows strong agreement with traditional bias evaluation metrics (Spearman correlation r>0.85). Moreover, BiasLens reveals forms of bias that are difficult to detect using existing methods. For example, in simulated clinical scenarios, a patient's insurance status can cause the LLM to produce biased diagnostic assessments. Overall, BiasLens offers a scalable, interpretable, and efficient paradigm for bias discovery, paving the way for improving fairness and transparency in LLMs.",
      "citationCount": 3,
      "doi": "10.48550/arXiv.2505.15524",
      "arxivId": "2505.15524",
      "url": "https://www.semanticscholar.org/paper/2bad289a77848c4e1c2451ddf323d6bb5a9139eb",
      "venue": "arXiv.org",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2505.15524"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "d3f12b6410486d004d9119f9745b159dfa461de3",
      "title": "The Role of AI and ML in Alternative Credit Scoring in Fintech Lending",
      "authors": [
        {
          "name": "Dr Preeti S Desai",
          "authorId": "2355018780"
        }
      ],
      "year": 2025,
      "abstract": "This research examines the influence of artificial intelligence (AI) and machine learning (ML) on alternative credit scoring in fintech lending, highlighting the effect of alternative data on financial inclusion and confidence in AI-based credit assessments.\u00a0 The study, using a sample size of 384 and evaluated via quantitative methodologies with SPSS and Structural Equation Modeling (SEM), emphasizes the need for ethical frameworks and transparent governance to guarantee fairness and accountability in AI-driven credit assessments. Conventional credit assessment techniques often exclude persons with sparse credit histories, whereas AI/ML-driven models use digital footprints, utility payments, and behavioral data to provide a more thorough credit review.\u00a0 The results demonstrate that alternative data substantially improves the perceived precision of AI/ML credit rating, resulting in heightened confidence in automated conclusions.\u00a0 Moreover, increased consumer understanding of AI/ML enhances trust in digital lending systems, hence promoting broader financial inclusion.",
      "citationCount": 1,
      "doi": "10.52783/jisem.v10i31s.4956",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/d3f12b6410486d004d9119f9745b159dfa461de3",
      "venue": "Journal of Information Systems Engineering & Management",
      "journal": {
        "name": "Journal of Information Systems Engineering and Management"
      },
      "publicationTypes": [
        "JournalArticle",
        "Review"
      ]
    },
    {
      "paperId": "82897bc8f96b39ba45e2cffb6f843525b74e0799",
      "title": "The Deep Learning for Recommender System: Architecture, Advancements and Future Trends",
      "authors": [
        {
          "name": "Jeet",
          "authorId": "2374258354"
        },
        {
          "name": "Dhiraj Khurana",
          "authorId": "14802240"
        }
      ],
      "year": 2025,
      "abstract": "Deep learning is becoming a game-changing technology in the field of recommender systems, which have grown as a result of the exponential growth of digital information and user data. This paper gives an extensive overview of deep learning architectures used in recommender systems, including emerging paradigms like Graph Neural Networks (GNNs), Autoencoders, Transformer-based models, and foundational models like Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs), Deep Neural Networks (DNNs). This study aims to examine how recommendation systems, including content-based filtering, collaborative filtering, and hybrid techniques, can be integrated with improvements in contextawareness, scalability, and customization. Moreover, it investigates advancements in multi-modal information integration, handling sparse data, and model interpretability. This paper outlines on future research directions that focus on fairness, transparency, and real-time adaptation while addressing current issues including overfitting, computational complexity, and cold-start challenges. It aims to help researchers and practitioners use deep learning for next-generation recommender systems using the latest developments in technology and trends.",
      "citationCount": 0,
      "doi": "10.1109/ICIRCA65293.2025.11089530",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/82897bc8f96b39ba45e2cffb6f843525b74e0799",
      "venue": "2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)",
      "journal": {
        "name": "2025 6th International Conference on Inventive Research in Computing Applications (ICIRCA)",
        "pages": "2022-2029"
      },
      "publicationTypes": [
        "Conference",
        "Review"
      ]
    },
    {
      "paperId": "79c94c07778a8e2a3a28c3d3a1c9b197371fbf06",
      "title": "PFLIC: A novel personalized federated learning-based iterative clustering",
      "authors": [
        {
          "name": "Shiwen Zhang",
          "authorId": "2298280185"
        },
        {
          "name": "Shuang Chen",
          "authorId": "2346514590"
        },
        {
          "name": "Wei Liang",
          "authorId": "2363513378"
        },
        {
          "name": "Kuanching Li",
          "authorId": "2329899728"
        },
        {
          "name": "Arcangelo Castiglione",
          "authorId": "2888412"
        },
        {
          "name": "Junsong Yuan",
          "authorId": "2363294894"
        }
      ],
      "year": 2025,
      "abstract": "Federated learning (FL) is a machine learning framework that effectively\n helps multiple organizations perform data usage and machine learning models\n while meeting the requirements of user privacy protection, data security,\n and government regulations. However, in practical applications, existing\n federated learning mechanisms face many challenges, including system\n inefficiency due to data heterogeneity and how to achieve fairness to\n incentivize clients to participate in federated training. Due to this fact,\n we propose PFLIC, a novel personalized federated learning based on an\n iterative clustering algorithm, to estimate clusters to mitigate data\n heterogeneity and improve the efficiency of FL. It is combined with sparse\n sharing to facilitate knowledge sharing within the system for personalized\n federated learning. To ensure fairness, a client selection strategy is\n proposed to choose relatively ?good? clients to achieve fairer federated\n learning without sacrificing system efficiency. Extensive experiments\n demonstrate the superior performance and effectiveness of the proposed PFLIC\n compared to the baseline.",
      "citationCount": 0,
      "doi": "10.2298/csis250131052z",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/79c94c07778a8e2a3a28c3d3a1c9b197371fbf06",
      "venue": "Computer Science and Information Systems",
      "journal": {
        "name": "Comput. Sci. Inf. Syst.",
        "pages": "945-970",
        "volume": "22"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "518a092109ee8e142537f3893894c3d3877cd142",
      "title": "Research on Dynamic Hyperparameter Optimization Algorithm for University Financial Risk Early Warning Based on Multi-Objective Bayesian Optimization",
      "authors": [
        {
          "name": "Yu Chao",
          "authorId": "2333385497"
        },
        {
          "name": "Nur Fazidah Elias",
          "authorId": "2282998821"
        },
        {
          "name": "Y. Yahya",
          "authorId": "2275791"
        },
        {
          "name": "Ruzzakiah Jenal",
          "authorId": "39000753"
        }
      ],
      "year": 2025,
      "abstract": "Financial sustainability in higher education is increasingly fragile due to policy shifts, rising costs, and funding volatility. Legacy early-warning systems based on static thresholds or rules struggle to adapt to these dynamics and often overlook fairness and interpretability\u2014two essentials in public-sector governance. We propose a university financial risk early-warning framework that couples a causal-attention Transformer with Multi-Objective Bayesian Optimization (MBO). The optimizer searches a constrained Pareto frontier to jointly improve predictive accuracy (AUC\u2191), fairness (demographic parity gap, DP_Gap\u2193), and computational efficiency (time\u2193). A sparse kernel surrogate (SKO) accelerates convergence in high-dimensional tuning; a dual-head output (risk probability and health score) and SHAP-based attribution enhance transparency and regulatory alignment. On multi-year, multi-institution data, the approach surpasses mainstream baselines in AUC, reduces DP_Gap, and yields expert-consistent explanations. Methodologically, the design aligns with LLM-style time-series forecasting by exploiting causal masking and long-range dependencies while providing governance-oriented explainability. The framework delivers earlier, data-driven signals of financial stress, supporting proactive resource allocation, funding restructuring, and long-term planning in higher education finance.",
      "citationCount": 0,
      "doi": "10.3390/forecast7040061",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/518a092109ee8e142537f3893894c3d3877cd142",
      "venue": "Forecasting",
      "journal": {
        "name": "Forecasting"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "18b6397238ad80d4026c117d2e6e5f2a1fef1a80",
      "title": "A Structure-Aware Fair Recommendation Approach Based on Counterfactual Dynamic Hypergraphs",
      "authors": [
        {
          "name": "Shanshan Wan",
          "authorId": "2332180015"
        },
        {
          "name": "Zebin Fu",
          "authorId": "2333407844"
        },
        {
          "name": "Qiyi Zhou",
          "authorId": "2388299083"
        },
        {
          "name": "Chuyuan Wei",
          "authorId": "2298873621"
        },
        {
          "name": "Changdong Wang",
          "authorId": "2245634645"
        }
      ],
      "year": 2025,
      "abstract": "Unfair recommendations stem from user sensitive attributes and information transmission biases. Graph-structured data can provide more balanced information for fair recommendations by capturing multidimensional user-item interactions. However, graph-based fair recommendation still faces some challenges: Traditional graphs rely on static edge-connected topology, struggling to dynamically update many-to-many relationships, which impairs the long-term fairness modeling; Most existing graph mining algorithms overlook individual differences arising from filtered sensitive information, thereby exacerbating the fairness-accuracy trade-off; Hypergraph neural networks\u2019 propagation relies on structural density, while sparse connections reduce it, leading to inaccurate representations in sparse regions and uneven diffusion. To address these issues, we propose a structure-aware fair recommendation approach based on counterfactual dynamic hypergraphs (FairCH). First, we propose a multidimensional user fairness model that captures many-to-many higher-order user-item relationships and their preference-fairness co-evolution via dynamic hypergraphs. Second, sensitive information is filtered through adversarial learning and counterfactual hyperedges is reconstructed by counterfactual reasoning, compensating for information loss. Finally, a cross-hierarchy structure-aware model is proposed, which extracts counterfactual fairness layers, global preference layers, and shared evolution layers from hypergraphs and integrates them via an inter-layer interactive attention mechanism to enhance information propagation and mitigate structural biases. Experimental results demonstrate that FairCH exhibits superior recommendation performance to the baselines.",
      "citationCount": 0,
      "doi": "10.1145/3773913",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/18b6397238ad80d4026c117d2e6e5f2a1fef1a80",
      "venue": "ACM Transactions on Intelligent Systems and Technology",
      "journal": {
        "name": "ACM Transactions on Intelligent Systems and Technology"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "d72997bdab31b74b0e85778ef7425bb4a0450c24",
      "title": "Fair GLASSO: Estimating Fair Graphical Models with Unbiased Statistical Behavior",
      "authors": [
        {
          "name": "Madeline Navarro",
          "authorId": "1936823928"
        },
        {
          "name": "Samuel Rey",
          "authorId": "1605975703"
        },
        {
          "name": "Andrei Buciulea",
          "authorId": "1605989428"
        },
        {
          "name": "Antonio G. Marques",
          "authorId": "2241339650"
        },
        {
          "name": "Santiago Segarra",
          "authorId": "2239197971"
        }
      ],
      "year": 2024,
      "abstract": "We propose estimating Gaussian graphical models (GGMs) that are fair with respect to sensitive nodal attributes. Many real-world models exhibit unfair discriminatory behavior due to biases in data. Such discrimination is known to be exacerbated when data is equipped with pairwise relationships encoded in a graph. Additionally, the effect of biased data on graphical models is largely underexplored. We thus introduce fairness for graphical models in the form of two bias metrics to promote balance in statistical similarities across nodal groups with different sensitive attributes. Leveraging these metrics, we present Fair GLASSO, a regularized graphical lasso approach to obtain sparse Gaussian precision matrices with unbiased statistical dependencies across groups. We also propose an efficient proximal gradient algorithm to obtain the estimates. Theoretically, we express the tradeoff between fair and accurate estimated precision matrices. Critically, this includes demonstrating when accuracy can be preserved in the presence of a fairness regularizer. On top of this, we study the complexity of Fair GLASSO and demonstrate that our algorithm enjoys a fast convergence rate. Our empirical validation includes synthetic and real-world simulations that illustrate the value and effectiveness of our proposed optimization problem and iterative algorithm.",
      "citationCount": 12,
      "doi": "10.48550/arXiv.2406.09513",
      "arxivId": "2406.09513",
      "url": "https://www.semanticscholar.org/paper/d72997bdab31b74b0e85778ef7425bb4a0450c24",
      "venue": "Neural Information Processing Systems",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2406.09513"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "4d2b0a71e381b456ad0951bd37be113be9ad8397",
      "title": "Privacy-Preserving Fair Machine Learning Without Collecting Sensitive Demographic Data",
      "authors": [
        {
          "name": "Hui Hu",
          "authorId": "2116486375"
        },
        {
          "name": "Mike Borowczak",
          "authorId": "2935022"
        },
        {
          "name": "Zhengzhang Chen",
          "authorId": "1766853"
        }
      ],
      "year": 2021,
      "abstract": "With the rising concerns over privacy and fairness in machine learning, privacy-preserving fair machine learning has received tremendous attention in recent years. However, most existing fair models still need to collect sensitive demographic data, which may be impossible given privacy regulations. To address the dilemma between model fairness and sensitive data collection, we propose DicPF, a distributed and privacy-preserving fair learning framework that operates without collecting sensitive demographic data. In particular, DicPF assumes multiple local agents and a modeler are distributed, and sensitive demographic data is separately held by multiple local agents. To assist fair learning at the modeler, each agent learns a fair local dictionary and send it to the modeler. The modeler learns a fair model based on an aggregated dictionary. Under DicPF framework, we propose a private z-Sparse Fair Learner. Extensive experiments on three real-world datasets demonstrate the efficiency of the proposed model. Compared with the state-of-the-art fair learners, the proposed z-Sparse Fair Learner achieves superior fairness performance by lowering prediction disparity. We also develop a privacy inference model to demonstrate the excellent privacy-preserving performance of DicPF. Finally, we theoretically analyze z-Sparse Fair Learner and prove upper bounds on its model fairness and accuracy.",
      "citationCount": 4,
      "doi": "10.1109/IJCNN52387.2021.9534017",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/4d2b0a71e381b456ad0951bd37be113be9ad8397",
      "venue": "IEEE International Joint Conference on Neural Network",
      "journal": {
        "name": "2021 International Joint Conference on Neural Networks (IJCNN)",
        "pages": "1-9"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "99663ad36cd86fcb37ac80934197e9160b67f0f9",
      "title": "Detecting uniform differential item functioning for continuous response computerized adaptive testing",
      "authors": [
        {
          "name": "Chun Wang",
          "authorId": "2118346982"
        },
        {
          "name": "Ruoyi Zhu",
          "authorId": "2152147011"
        }
      ],
      "year": 2024,
      "abstract": "Evaluating items for potential differential item functioning (DIF) is an essential step to ensuring measurement fairness. In this article, we focus on a specific scenario, namely, the continuous response, severely sparse, computerized adaptive testing (CAT). Continuous responses items are growingly used in performance-based tasks because they tend to generate more information than traditional dichotomous items. Severe sparsity arises when many items are automatically generated via machine learning algorithms. We propose two uniform DIF detection methods in this scenario. The first is a modified version of the CAT-SIBTEST, a non-parametric method that does not depend on any specific item response theory model assumptions. The second is a regularization method, a parametric, model-based approach. Simulation studies show that both methods are effective in correctly identifying items with uniform DIF. A real data analysis is provided in the end to illustrate the utility and potential caveats of the two methods.",
      "citationCount": 3,
      "doi": "10.1177/01466216241227544",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/99663ad36cd86fcb37ac80934197e9160b67f0f9",
      "venue": "Applied Psychological Measurement",
      "journal": {
        "name": "Applied Psychological Measurement",
        "pages": "18 - 37",
        "volume": "48"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "a853b37c233906b14962e8079b998c97f88fada2",
      "title": "Pantypes: Diverse Representatives for Self-Explainable Models",
      "authors": [
        {
          "name": "R. Kj\u00e6rsgaard",
          "authorId": "2141581217"
        },
        {
          "name": "Ahc\u00e8ne Boubekki",
          "authorId": "3428712"
        },
        {
          "name": "Line H. Clemmensen",
          "authorId": "2291139937"
        }
      ],
      "year": 2024,
      "abstract": "Prototypical self-explainable classifiers have emerged to meet the growing demand for interpretable AI systems. These classifiers are designed to incorporate high transparency in their decisions by basing inference on similarity with learned prototypical objects. While these models are designed with diversity in mind, the learned prototypes often do not sufficiently represent all aspects of the input distribution, particularly those in low density regions. \nSuch lack of sufficient data representation, known as representation bias, has been associated with various detrimental properties related to machine learning diversity and fairness. In light of this, we introduce pantypes, a new family of prototypical objects designed to capture the full diversity of the input distribution through a sparse set of objects. We show that pantypes can empower prototypical self-explainable models by occupying divergent regions of the latent space and thus fostering high diversity, interpretability and fairness.",
      "citationCount": 3,
      "doi": "10.1609/aaai.v38i12.29223",
      "arxivId": "2403.09383",
      "url": "https://www.semanticscholar.org/paper/a853b37c233906b14962e8079b998c97f88fada2",
      "venue": "AAAI Conference on Artificial Intelligence",
      "journal": {
        "name": "ArXiv",
        "volume": "abs/2403.09383"
      },
      "publicationTypes": [
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "fea22b28fd55018c273ef28b06e46032ae6c6818",
      "title": "DeepRing: Convolution Neural Network based on Blockchain Technology",
      "authors": [
        {
          "name": "Sura Hamed Mousa",
          "authorId": "2302595233"
        },
        {
          "name": "N. M. Shati",
          "authorId": "72853202"
        },
        {
          "name": "Nageswari Sakthivadivel",
          "authorId": "2308054964"
        }
      ],
      "year": 2024,
      "abstract": "Background: This paper addresses specific challenges in predictive modeling, namely transparency issues, susceptibility to data manipulation, and fairness concerns. To overcome these obstacles, the study introduces DeepRing, approach that combines Convolutional Neural Networks (CNNs) and blockchain technology. Objective: DeepRing aims to enhance prediction integrity, data security, and fairness, thereby improving the ethical considerations, reliability, and accountability of predictive models. Methods: involves iterative training of a CNN model on five diverse datasets, including CIFAR-10, Fashion-MNIST, MNIST, CIFAR-100, and a Hands dataset. The CNN architecture incorporates Conv2D layers, MaxPooling2D layers, and Dense layers. Training metrics such as accuracy and sparse categorical cross-entropy loss are monitored, with the Adam optimizer employed. While achieving high accuracy on Plam (0.5300), MNIST (0.9978) and Fashion MNIST (0.9673), DeepRing exhibits moderate performance on CIFAR-10 (0.9296) and lower accuracy on CIFAR-100 (0.5973). Results: demonstrate the effectiveness of DeepRing in improving accuracy and enhancing model performance across various datasets. However, further development and validation are essential for successful model implementation, further development and validation are essential for successful model implementation. Conclusions: Introduces DeepRing as an innovative solution to address key challenges in predictive modeling, specifically focusing on transparency issues, susceptibility to data manipulation, and fairness concerns. By combining Convolutional Neural Networks (CNNs) with blockchain technology, DeepRing aims to elevate prediction integrity, enhance data security, and promote fairness, thereby contributing to the improvement of ethical considerations, reliability, and accountability in predictive modelling.",
      "citationCount": 3,
      "doi": "10.23851/mjs.v35i2.1476",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/fea22b28fd55018c273ef28b06e46032ae6c6818",
      "venue": "Al-Mustansiriyah Journal of Science",
      "journal": {
        "name": "Al-Mustansiriyah Journal of Science"
      },
      "publicationTypes": [
        "JournalArticle"
      ]
    },
    {
      "paperId": "2cfb0693f8150a305bc04ec42027ad6d4f22ad4e",
      "title": "Distributionally-robust Recommendations for Improving Worst-case User Experience",
      "authors": [
        {
          "name": "Hongyi Wen",
          "authorId": "1949263871"
        },
        {
          "name": "Xinyang Yi",
          "authorId": "2838461"
        },
        {
          "name": "Tiansheng Yao",
          "authorId": "2026127"
        },
        {
          "name": "Jiaxi Tang",
          "authorId": "3431394"
        },
        {
          "name": "Lichan Hong",
          "authorId": "2217278"
        },
        {
          "name": "Ed H. Chi",
          "authorId": "2226805"
        }
      ],
      "year": 2022,
      "abstract": "Modern recommender systems have evolved rapidly along with deep learning models that are well-optimized for overall performance, especially those trained under Empirical Risk Minimization (ERM). However, a recommendation algorithm that focuses solely on the average performance may reinforce the exposure bias and exacerbate the \u201crich-get-richer\u201d effect, leading to unfair user experience. In a simulation study, we demonstrate that such performance gap among various user groups is enlarged by an ERM-trained recommender in the long-term. To mitigate such amplification effects, we propose to optimize for the worst-case performance under the Distributionally Robust Optimization (DRO) framework, with the goal of improving long-term fairness for disadvantaged subgroups. In addition, we propose a simple-yet-effective streaming optimization improvement called Streaming-DRO (S-DRO), which effectively reduces loss variances for recommendation problems with sparse and long-tailed data distributions. Our results on two large-scale datasets suggest that (1) DRO is a flexible and effective technique for improving worst-case performance, and (2) Streaming-DRO outperforms vanilla DRO and other strong baselines by improving the worst-case and overall performance at the same time.",
      "citationCount": 58,
      "doi": "10.1145/3485447.3512255",
      "arxivId": null,
      "url": "https://www.semanticscholar.org/paper/2cfb0693f8150a305bc04ec42027ad6d4f22ad4e",
      "venue": "The Web Conference",
      "journal": {
        "name": "Proceedings of the ACM Web Conference 2022"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle",
        "Conference"
      ]
    },
    {
      "paperId": "dff9dfcf70e2611c959d709cf47de8a86024bf6d",
      "title": "Towards Fair Disentangled Online Learning for Changing Environments",
      "authors": [
        {
          "name": "Chenxu Zhao",
          "authorId": "36681034"
        },
        {
          "name": "Feng Mi",
          "authorId": "2058930366"
        },
        {
          "name": "Xintao Wu",
          "authorId": "7916525"
        },
        {
          "name": "Kai Jiang",
          "authorId": "2052123160"
        },
        {
          "name": "L. Khan",
          "authorId": "1685603"
        },
        {
          "name": "Christan Earl Grant",
          "authorId": "4985351"
        },
        {
          "name": "Feng Chen",
          "authorId": "1399870469"
        }
      ],
      "year": 2023,
      "abstract": "In the problem of online learning for changing environments, data are sequentially received one after another over time, and their distribution assumptions may vary frequently. Although existing methods demonstrate the effectiveness of their learning algorithms by providing a tight bound on either dynamic regret or adaptive regret, most of them completely ignore learning with model fairness, defined as the statistical parity across different sub-population (e.g., race and gender). Another drawback is that when adapting to a new environment, an online learner needs to update model parameters with a global change, which is costly and inefficient. Inspired by the sparse mechanism shift hypothesis [22], we claim that changing environments in online learning can be attributed to partial changes in learned parameters that are specific to environments and the rest remain invariant to changing environments. To this end, in this paper, we propose a novel algorithm under the assumption that data collected at each time can be disentangled with two representations, an environment-invariant semantic factor and an environment-specific variation factor. The semantic factor is further used for fair prediction under a group fairness constraint. To evaluate the sequence of model parameters generated by the learner, a novel regret is proposed in which it takes a mixed form of dynamic and static regret metrics followed by a fairness-aware long-term constraint. The detailed analysis provides theoretical guarantees for loss regret and violation of cumulative fairness constraints. Empirical evaluations on real-world datasets demonstrate our proposed method sequentially outperforms baseline methods in model accuracy and fairness.",
      "citationCount": 18,
      "doi": "10.1145/3580305.3599523",
      "arxivId": "2306.01007",
      "url": "https://www.semanticscholar.org/paper/dff9dfcf70e2611c959d709cf47de8a86024bf6d",
      "venue": "Knowledge Discovery and Data Mining",
      "journal": {
        "name": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining"
      },
      "publicationTypes": [
        "JournalArticle",
        "Book",
        "Conference"
      ]
    },
    {
      "paperId": "dc8da3541af776de51c1f1072da2cc5af842bcdb",
      "title": "debiaSAE: Benchmarking and Mitigating Vision-Language Model Bias",
      "authors": [
        {
          "name": "Kuleen Sasse",
          "authorId": "2003602481"
        },
        {
          "name": "Shan Chen",
          "authorId": "2323579106"
        },
        {
          "name": "Jackson Pond",
          "authorId": "2307076471"
        },
        {
          "name": "Danielle S. Bitterman",
          "authorId": "2260340486"
        },
        {
          "name": "John D. Osborne",
          "authorId": "2325150670"
        }
      ],
      "year": 2024,
      "abstract": "As Vision Language Models (VLMs) gain widespread use, their fairness remains under-explored. In this paper, we analyze demographic biases across five models and six datasets. We find that portrait datasets like UTKFace and CelebA are the best tools for bias detection, finding gaps in performance and fairness for both LLaVa and CLIP models. Scene-based datasets like PATA and VLStereoSet fail to be useful benchmarks for bias due to their text prompts allowing the model to guess the answer without a picture. As for pronoun-based datasets like VisoGender, we receive mixed signals as only some subsets of the data are useful in providing insights. To alleviate these two problems, we introduce a more rigorous evaluation dataset and a debiasing method based on Sparse Autoencoders to help reduce bias in models. We find that our data set generates more meaningful errors than the previous data sets. Furthermore, our debiasing method improves fairness, gaining 5-15 points in performance over the baseline. This study displays the problems with the current benchmarks for measuring demographic bias in Vision Language Models and introduces both a more effective dataset for measuring bias and a novel and interpretable debiasing method based on Sparse Autoencoders.",
      "citationCount": 0,
      "doi": null,
      "arxivId": "2410.13146",
      "url": "https://www.semanticscholar.org/paper/dc8da3541af776de51c1f1072da2cc5af842bcdb",
      "venue": "",
      "journal": null,
      "publicationTypes": null
    },
    {
      "paperId": "52293339ff7de3e5bf4b83539052de04ee962513",
      "title": "Seeing without Looking: Analysis Pipeline for Child Sexual Abuse Datasets",
      "authors": [
        {
          "name": "Camila Laranjeira",
          "authorId": "24055450"
        },
        {
          "name": "Jo\u00e3o Macedo",
          "authorId": "2066720012"
        },
        {
          "name": "S. Avila",
          "authorId": "145438759"
        },
        {
          "name": "J. A. D. Santos",
          "authorId": "6141311"
        }
      ],
      "year": 2022,
      "abstract": "The online sharing and viewing of Child Sexual Abuse Material (CSAM) are growing fast, such that human experts can no longer handle the manual inspection. However, the automatic classification of CSAM is a challenging field of research, largely due to the inaccessibility of target data that is \u2014 and should forever be \u2014 private and in sole possession of law enforcement agencies. To aid researchers in drawing insights from unseen data and safely providing further understanding of CSAM images, we propose an analysis template that goes beyond the statistics of the dataset and respective labels. It focuses on the extraction of automatic signals, provided both by pre-trained machine learning models, e.g., object categories and pornography detection, as well as image metrics such as luminance and sharpness. Only aggregated statistics of sparse signals are provided to guarantee the anonymity of children and adolescents victimized. The pipeline allows filtering the data by applying thresholds to each specified signal and provides the distribution of such signals within the subset, correlations between signals, as well as a bias evaluation. We demonstrated our proposal on the Region-based annotated Child Pornography Dataset (RCPD), one of the few CSAM benchmarks in the literature, composed of over 2000 samples among regular and CSAM images, produced in partnership with Brazil\u2019s Federal Police. Although noisy and limited in several senses, we argue that automatic signals can highlight important aspects of the overall distribution of data, which is valuable for databases that can not be disclosed. Our goal is to safely publicize the characteristics of CSAM datasets, encouraging researchers to join the field and perhaps other institutions to provide similar reports on their benchmarks.",
      "citationCount": 21,
      "doi": "10.1145/3531146.3534636",
      "arxivId": "2204.14110",
      "url": "https://www.semanticscholar.org/paper/52293339ff7de3e5bf4b83539052de04ee962513",
      "venue": "Conference on Fairness, Accountability and Transparency",
      "journal": {
        "name": "Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency"
      },
      "publicationTypes": [
        "Book",
        "JournalArticle"
      ]
    }
  ],
  "count": 40,
  "errors": []
}
