{
  "status": "success",
  "source": "arxiv",
  "query": "all:fairness metrics construct validity AND cat:cs.AI",
  "results": [
    {
      "arxiv_id": "2012.00106",
      "title": "Towards Auditability for Fairness in Deep Learning",
      "authors": [
        "Ivoline C. Ngong",
        "Krystal Maughan",
        "Joseph P. Near"
      ],
      "abstract": "Group fairness metrics can detect when a deep learning model behaves differently for advantaged and disadvantaged groups, but even models that score well on these metrics can make blatantly unfair predictions. We present smooth prediction sensitivity, an efficiently computed measure of individual fairness for deep learning models that is inspired by ideas from interpretability in deep learning. smooth prediction sensitivity allows individual predictions to be audited for fairness. We present preliminary experimental results suggesting that smooth prediction sensitivity can help distinguish between fair and unfair predictions, and that it may be helpful in detecting blatantly unfair predictions from \"group-fair\" models.",
      "published": "2020-11-30",
      "updated": "2020-11-30",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2012.00106v1",
      "url": "https://arxiv.org/abs/2012.00106"
    },
    {
      "arxiv_id": "2001.09784",
      "title": "Algorithmic Fairness",
      "authors": [
        "Dana Pessach",
        "Erez Shmueli"
      ],
      "abstract": "An increasing number of decisions regarding the daily lives of human beings are being controlled by artificial intelligence (AI) algorithms in spheres ranging from healthcare, transportation, and education to college admissions, recruitment, provision of loans and many more realms. Since they now touch on many aspects of our lives, it is crucial to develop AI algorithms that are not only accurate but also objective and fair. Recent studies have shown that algorithmic decision-making may be inherently prone to unfairness, even when there is no intention for it. This paper presents an overview of the main concepts of identifying, measuring and improving algorithmic fairness when using AI algorithms. The paper begins by discussing the causes of algorithmic bias and unfairness and the common definitions and measures for fairness. Fairness-enhancing mechanisms are then reviewed and divided into pre-process, in-process and post-process mechanisms. A comprehensive comparison of the mechanisms is then conducted, towards a better understanding of which mechanisms should be used in different scenarios. The paper then describes the most commonly used fairness-related datasets in this field. Finally, the paper ends by reviewing several emerging research sub-fields of algorithmic fairness.",
      "published": "2020-01-21",
      "updated": "2020-01-21",
      "primary_category": "cs.CY",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2001.09784v1",
      "url": "https://arxiv.org/abs/2001.09784"
    }
  ],
  "count": 2,
  "errors": []
}
