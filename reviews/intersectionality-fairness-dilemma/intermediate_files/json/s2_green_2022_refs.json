{
  "status": "success",
  "source": "semantic_scholar",
  "query": "DOI:10.1007/s13347-022-00584-6",
  "results": [
    {
      "paper": {
        "paperId": "736960b0a4c53abc819f34304200c3dea0fe0ea0",
        "title": "Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness",
        "authors": [
          {
            "name": "Ben Green",
            "authorId": "87122962"
          }
        ],
        "year": 2021,
        "abstract": "Efforts to promote equitable public policy with algorithms appear to be fundamentally constrained by the \u201cimpossibility of fairness\u201d (an incompatibility between mathematical definitions of fairness). This technical limitation raises a central question about algorithmic fairness: How can computer scientists and policymakers support equitable policy reforms with algorithms? In this article, I argue that promoting justice with algorithms requires reforming the methodology of algorithmic fairness. First, I diagnose the problems of the current methodology for algorithmic fairness, which I call \u201cformal algorithmic fairness.\u201d Because formal algorithmic fairness restricts analysis to isolated decision-making procedures, it leads to the impossibility of fairness and to models that exacerbate oppression despite appearing \u201cfair.\u201d Second, I draw on theories of substantive equality from law and philosophy to propose an alternative methodology, which I call \u201csubstantive algorithmic fairness.\u201d Because substantive algorithmic fairness takes a more expansive scope of analysis, it enables an escape from the impossibility of fairness and provides a rigorous guide for alleviating injustice with algorithms. In sum, substantive algorithmic fairness presents a new direction for algorithmic fairness: away from formal mathematical models of \u201cfair\u201d decision-making and toward substantive evaluations of whether and how algorithms can promote justice in practice.",
        "citationCount": 40,
        "doi": "10.1007/s13347-022-00584-6",
        "arxivId": "2107.04642",
        "url": "https://www.semanticscholar.org/paper/736960b0a4c53abc819f34304200c3dea0fe0ea0",
        "venue": "Philosophy & Technology"
      },
      "references": [
        {
          "paperId": "1e65947c681d94ef3d13cb42a27f7d335fb20b0b",
          "title": "Design Justice: Community-Led Practices to Build the Worlds We Need",
          "authors": [
            {
              "name": "Rachael Jordan",
              "authorId": "2286430112"
            }
          ],
          "year": 2022,
          "abstract": null,
          "citationCount": 922,
          "doi": "10.1080/10572252.2022.2130671",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/1e65947c681d94ef3d13cb42a27f7d335fb20b0b",
          "venue": "Technical Communication Quarterly",
          "isInfluential": true,
          "contexts": [
            "This result suggests that the best way for algorithm developers to promote fairness or justice in practice is to select some (limited) fairness definitions at the expense of others (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "Similarly, a proponent of algorithmic justice acknowledges that, because of the legal implications of these tradeoffs, \u201cit is highly unlikely that an algorithmic justice approach will advance\u201d (Costanza-Chock, 2020).",
            "\u2026a particular challenge for proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017;\u2026",
            "\u2026proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017; Costanza-Chock, 2020; Hellman, 2020).",
            ", 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017; Costanza-Chock, 2020; Hellman, 2020).",
            "algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al.",
            "In shifting away from formal mathematical models (and associated interventions such as pretrial risk assessments), this reorientation prompts a new positive agenda for how to act on recent calls to shift the field\u2019s emphasis from \u201cfairness\u201d to \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al.",
            "Similarly, a proponent of algorithmic justice acknowledges that, because of the legal implications of these trade-offs, \u201cit is highly unlikely that an algorithmic justice approach will advance\u201d (Costanza-Chock, 2020).",
            "The impossibility of fairness suggests that reformers can either (a) choose a single fairness definition at the expense of others or (b) rigorously balance the tradeoffs between multiple definitions (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al.",
            "In doing so, substantive algorithmic fairness aligns the field with recent calls for algorithmic \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al.",
            "Recent work provides several examples of how data analysis and technology design can be incorporated into community-driven reform efforts that challenge oppression (Asad, 2019; Costanza-Chock, 2020; Lewis et al., 2018; Maharawal & McElroy, 2018; Meng & DiSalvo, 2018).",
            "into community-driven reform efforts that challenge oppression (Asad, 2019; Costanza-Chock, 2020; Lewis et al., 2018; Maharawal & McElroy, 2018; Meng & DiSalvo, 2018).",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al., 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "bac79658f3bf437cf76891a43478eed99fb857c6",
          "title": "The Smart Enough City: Putting Technology in Its Place to Reclaim Our Urban Future",
          "authors": [
            {
              "name": "Andr\u00e9 Furlani",
              "authorId": "87259484"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 86,
          "doi": "10.1080/10848770.2021.2010304",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/bac79658f3bf437cf76891a43478eed99fb857c6",
          "venue": "The European Legacy",
          "isInfluential": false,
          "contexts": [
            "Computer science pedagogy, corporate advertising, and the media promote the idea that technology provides solutions to social issues (Broussard, 2018; Green, 2019; Morozov, 2014).",
            "Algorithms can best help to promote social change when deployed in conjunction with broader policy and governance reforms (Abebe et al., 2020; Green, 2019)."
          ],
          "intents": []
        },
        {
          "paperId": "209f4fe42868f2d9ce8523b60ce3bed37cd435fd",
          "title": "Design Justice: Community-Led Practices to Build the Worlds We Need (Information Policy) by Sasha Costanza-Chock",
          "authors": [
            {
              "name": "Kriti Bhalla",
              "authorId": "101907529"
            },
            {
              "name": "Sanjana Shivakumar",
              "authorId": "1564579009"
            },
            {
              "name": "Tarun Kumar",
              "authorId": "1576004969"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 34,
          "doi": "10.1162/desi_r_00661",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/209f4fe42868f2d9ce8523b60ce3bed37cd435fd",
          "venue": "Design Issues",
          "isInfluential": true,
          "contexts": [
            "This result suggests that the best way for algorithm developers to promote fairness or justice in practice is to select some (limited) fairness definitions at the expense of others (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "\u2026a particular challenge for proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017;\u2026",
            "\u2026proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017; Costanza-Chock, 2020; Hellman, 2020).",
            "Similarly, a proponent of algorithmic justice acknowledges that, because of the legal implications of these trade-offs, \u201cit is highly unlikely that an algorithmic justice approach will advance\u201d (Costanza-Chock, 2020).",
            "inequalities [23, 39], and empower communities advocating for criminal justice reform [8, 21]\u2014 all of which would help to inform and enable structural responses.",
            "The impossibility of fairness suggests that reformers can either (a) choose a single fairness definition at the expense of others or (b) rigorously balance the tradeoffs between multiple definitions (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "Recent work provides several examples of how data analysis and technology design can be incorporated into community-driven reform efforts that challenge oppression (Asad, 2019; Costanza-Chock, 2020; Lewis et al., 2018; Maharawal & McElroy, 2018; Meng & DiSalvo, 2018).",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al., 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "d755077975b5010dab466ccc5ae26994690a796a",
          "title": "EQUALITY VS. EQUITY",
          "authors": [
            {
              "name": "M. Minow",
              "authorId": "1771760"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 72,
          "doi": "10.1162/ajle_a_00019",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/d755077975b5010dab466ccc5ae26994690a796a",
          "venue": "American Journal of Law and Equality",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "bd066d7eb87e26eed15d8a67c1457b51948900a3",
          "title": "Algorithmic reparation",
          "authors": [
            {
              "name": "Jenny L. Davis",
              "authorId": "152658412"
            },
            {
              "name": "Apryl A. Williams",
              "authorId": "2110028533"
            },
            {
              "name": "Michael W. Yang",
              "authorId": "2155579768"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 120,
          "doi": "10.1177/20539517211044808",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/bd066d7eb87e26eed15d8a67c1457b51948900a3",
          "venue": "Big Data & Society",
          "isInfluential": true,
          "contexts": [
            "This result suggests that the best way for algorithm developers to promote fairness or justice in practice is to select some (limited) fairness definitions at the expense of others (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "In doing so, substantive algorithmic fairness brings the field in line with recent calls for algorithmic \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "standards often reproduce inequities and legitimize unjust institutions [26, 45, 55, 76, 77, 80].",
            "In doing so, substantive algorithmic fairness provides a new orientation for algorithmic fairness, demonstrating how to act on recent calls to shift the field\u2019s emphasis from \u201cfairness\u201d to \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "Thus, in addition to reforms such as shifting the power structures behind algorithmic fairness [14, 24, 26, 89], it is also necessary to reform the methodology of algorithmic fairness.",
            "The impossibility of fairness suggests that reformers can either (a) choose a single fairness definition at the expense of others or (b) rigorously balance the tradeoffs between multiple definitions (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "Algorithms that satisfy fairness standards often exacerbate oppression and legiti-mize unjust institutions (Davis et al., 2021; Green, 2020; Kalluri, 2020; Ochig-ame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018).",
            "Algorithmic justice cannot be achieved merely by selecting a particular fairness definition at the expense of others or by evaluating the tradeoffs between fairness definitions, as some scholars have proposed [26, 56].",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al., 2021).",
            "\u2026for proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017; Costanza-Chock, 2020; Hellman,\u2026"
          ],
          "intents": []
        },
        {
          "paperId": "dd7c8b557350cb4d88c77ff2b34e08573c68f053",
          "title": "The (Im)possibility of fairness",
          "authors": [
            {
              "name": "Sorelle A. Friedler",
              "authorId": "34597147"
            },
            {
              "name": "C. Scheidegger",
              "authorId": "1786183"
            },
            {
              "name": "Suresh Venkatasubramanian",
              "authorId": "1747652"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 461,
          "doi": "10.1145/3433949",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/dd7c8b557350cb4d88c77ff2b34e08573c68f053",
          "venue": "Communications of the ACM",
          "isInfluential": false,
          "contexts": [
            "Substantive algorithmic fairness could present similar paths forward in other domains in which the impossibility of fairness has been interpreted as a significant and intractable barrier to reform, such as child welfare (Chouldechova et al., 2018) and college admissions (Friedler et al., 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "2bc7a72795b692c4ac3175e6b55f2ffe3a4bfe1b",
          "title": "Bias Preservation in Machine Learning: The Legality of Fairness Metrics Under EU Non-Discrimination Law",
          "authors": [
            {
              "name": "Sandra Wachter",
              "authorId": "12806133"
            },
            {
              "name": "B. Mittelstadt",
              "authorId": "3127701"
            },
            {
              "name": "Chris Russell",
              "authorId": "2052380526"
            }
          ],
          "year": 2021,
          "abstract": null,
          "citationCount": 159,
          "doi": "10.2139/SSRN.3792772",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/2bc7a72795b692c4ac3175e6b55f2ffe3a4bfe1b",
          "venue": "Social Science Research Network",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "1251ce38b191203d77a4d203ac449c584c4eb9ae",
          "title": "Algorithmic Risk Assessments Can Alter Human Decision-Making Processes in High-Stakes Government Contexts",
          "authors": [
            {
              "name": "Ben Green",
              "authorId": "87122962"
            },
            {
              "name": "Yiling Chen",
              "authorId": "117745152"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 73,
          "doi": "10.1145/3479562",
          "arxivId": "2012.05370",
          "url": "https://www.semanticscholar.org/paper/1251ce38b191203d77a4d203ac449c584c4eb9ae",
          "venue": "Proc. ACM Hum. Comput. Interact.",
          "isInfluential": false,
          "contexts": [
            "One strategy for anticipating the downstream impacts of a given algorithm is to run pre-deployment experiments that test how people interact with its advice (Green & Chen, 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "f3167f4ee325e7dc16c37da70bb18ea271f3effe",
          "title": "Redistribution and Rekognition",
          "authors": [
            {
              "name": "S. West",
              "authorId": "40962859"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 14,
          "doi": "10.28968/cftt.v6i2.33043",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/f3167f4ee325e7dc16c37da70bb18ea271f3effe",
          "venue": "",
          "isInfluential": false,
          "contexts": [
            "The impossibility of fairness suggests that reformers can either (a) choose a single fairness definition at the expense of others or (b) rigorously balance the tradeoffs between multiple definitions (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "Prior work has argued that choosing a fairness metric and its parameters is a political task that should be made democratically (Wachter et al., 2021; Wong, 2020).",
            "This result suggests that the best way for algorithm developers to promote fairness or justice in practice is to select some (limited) fairness definitions at the expense of others (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020)."
          ],
          "intents": []
        },
        {
          "paperId": "b8aeaaeabfa10886cb269cd88eeee22db3591d11",
          "title": "Data feminism",
          "authors": [
            {
              "name": "Natalia V. Kovalyova",
              "authorId": "123908022"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 1265,
          "doi": "10.1080/1369118X.2020.1836249",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/b8aeaaeabfa10886cb269cd88eeee22db3591d11",
          "venue": "Information, Communication & Society",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "cf78d3bafb5cd820ca02ccaf9bb2f91878db8a34",
          "title": "Formalising trade-offs beyond algorithmic fairness: lessons from ethical philosophy and welfare economics",
          "authors": [
            {
              "name": "M. S. Lee",
              "authorId": "1739477817"
            },
            {
              "name": "L. Floridi",
              "authorId": "1982425"
            },
            {
              "name": "Jatinder Singh",
              "authorId": "2109471576"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 74,
          "doi": "10.1007/s43681-021-00067-y",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/cf78d3bafb5cd820ca02ccaf9bb2f91878db8a34",
          "venue": "AI and Ethics",
          "isInfluential": false,
          "contexts": [
            "Efforts to formulate mathematical definitions of fairness overlook the contextual and philosophical meanings of fairness (Binns, 2018; Green & Hu, 2018; Jacobs & Wallach, 2021; Lee et al., 2021; Selbst et al., 2019).",
            "Furthermore, egalitarian scholars have confronted many questions that overlap with central debates in algorithmic fairness (Binns, 2018; Lee et al., 2021).",
            "1 Although no mathematical definition of algorithmic fairness fully encapsulates the philosophical notion of fairness or justice (Binns, 2018; Green & Hu, 2018; Jacobs & Wallach, 2021; Lee et al., 2021; Selbst et al., 2019), each definition captures a normatively desirable principle."
          ],
          "intents": []
        },
        {
          "paperId": "970069616c73a86c10b328c04a43644132cad22f",
          "title": "We\u2019re Missing a Moral Framework of Justice in Artificial Intelligence",
          "authors": [
            {
              "name": "Matthew Le Bui",
              "authorId": "2207420878"
            },
            {
              "name": "S. Noble",
              "authorId": "72273447"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 41,
          "doi": "10.1093/oxfordhb/9780190067397.013.9",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/970069616c73a86c10b328c04a43644132cad22f",
          "venue": "",
          "isInfluential": true,
          "contexts": [
            "In doing so, substantive algorithmic fairness brings the field in line with recent calls for algorithmic \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "Many governments and technology companies benefit from and promote formal algorithmic fairness, as it allows them to embrace \u201cfairness\u201d without making significant political or economic concessions [14, 45, 80].",
            "This challenge is exacerbated by the fact that many political actors and technology companies benefit from formal algorithmic fairness, which allows them to embrace \u201cfairness\u201d without making significant political or economic concessions (Bui & Noble, 2020; Green, 2020; Powles & Nissenbaum, 2018).",
            "In doing so, substantive algorithmic fairness provides a new orientation for algorithmic fairness, demonstrating how to act on recent calls to shift the field\u2019s emphasis from \u201cfairness\u201d to \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d [14, 43], \u201cequity\u201d [24], and \u201creparation\u201d [26].",
            "Thus, in addition to reforms such as shifting the power structures behind algorithmic fairness [14, 24, 26, 89], it is also necessary to reform the methodology of algorithmic fairness.",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al., 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "61fc451fc27df73052ff24d807f282481779818a",
          "title": "The Oxford Handbook of Ethics of AI",
          "authors": [],
          "year": 2020,
          "abstract": null,
          "citationCount": 200,
          "doi": "10.1093/oxfordhb/9780190067397.001.0001",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/61fc451fc27df73052ff24d807f282481779818a",
          "venue": "",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "e0d8768e4759eb16674c7b1e495ccaa4f7752694",
          "title": "Don\u2019t ask if artificial intelligence is good or fair, ask how it shifts power",
          "authors": [
            {
              "name": "Pratyusha Kalluri",
              "authorId": "13014201"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 195,
          "doi": "10.1038/d41586-020-02003-2",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/e0d8768e4759eb16674c7b1e495ccaa4f7752694",
          "venue": "Nature",
          "isInfluential": false,
          "contexts": [
            "Algorithms that satisfy fairness standards often exacerbate oppression and legiti-mize unjust institutions (Davis et al., 2021; Green, 2020; Kalluri, 2020; Ochig-ame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018).",
            "standards often reproduce inequities and legitimize unjust institutions [26, 45, 55, 76, 77, 80]."
          ],
          "intents": []
        },
        {
          "paperId": "be589b3f11f3782d7077b08df4956d875d2b475b",
          "title": "The Responsibility to Not Design and the Need for Citizen Professionalism",
          "authors": [
            {
              "name": "E. Graeff",
              "authorId": "31618908"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 9,
          "doi": "10.21428/93B2C832.C8387014",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/be589b3f11f3782d7077b08df4956d875d2b475b",
          "venue": "",
          "isInfluential": true,
          "contexts": [
            "3 Like other pretrial risk assessments, COMPAS predicts the likelihood that pretrial defendants will recidivate; these predictions are presented to judges to inform their decisions to release or detain each defendant until their trial (Green, 2020; Koepke & Robinson, 2018).",
            "This challenge is exacerbated by the fact that many political actors and technology companies benefit from formal algorithmic fairness, which allows them to embrace \u201cfairness\u201d without making significant political or economic concessions (Bui & Noble, 2020; Green, 2020; Powles & Nissenbaum, 2018).",
            "Thus, for instance, in light of concerns about the biases of judges, many court systems in the USA have adopted pretrial risk assessment algorithms as a central component of criminal justice reforms (Green, 2020; Koepke & Robinson, 2018; Porrino, 2017).",
            "Implementing pretrial risk assessments thus legitimizes preventative detention as the appropriate response to high-risk defendants and hinders efforts to promote less carceral alternatives (Green, 2020).",
            "Pretrial risk assessments define risk in ways that fail to account for the harms of detention on defendants and their communities, which are often more severe for marginalized defendants (Green, 2020; Yang, 2017).",
            "Algorithms that satisfy fairness standards often exacerbate oppression and legiti-mize unjust institutions (Davis et al., 2021; Green, 2020; Kalluri, 2020; Ochig-ame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018)."
          ],
          "intents": []
        },
        {
          "paperId": "46ef8d7926008577b7de3baf7a43d89489aa45f0",
          "title": "Design Justice",
          "authors": [
            {
              "name": "Sasha Costanza-Chock",
              "authorId": "1405024101"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 355,
          "doi": "10.7551/mitpress/12255.001.0001",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/46ef8d7926008577b7de3baf7a43d89489aa45f0",
          "venue": "",
          "isInfluential": true,
          "contexts": [
            "This result suggests that the best way for algorithm developers to promote fairness or justice in practice is to select some (limited) fairness definitions at the expense of others (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "\u2026a particular challenge for proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017;\u2026",
            "\u2026proponents of algorithmic justice: because their proposals involve violating sufficiency in favor of alternate measures (Costanza-Chock, 2020; Davis et al., 2021), such attempts would generally be barred by antidiscrimination law (Corbett-Davies et al., 2017; Costanza-Chock, 2020; Hellman, 2020).",
            "Similarly, a proponent of algorithmic justice acknowledges that, because of the legal implications of these trade-offs, \u201cit is highly unlikely that an algorithmic justice approach will advance\u201d (Costanza-Chock, 2020).",
            "The impossibility of fairness suggests that reformers can either (a) choose a single fairness definition at the expense of others or (b) rigorously balance the tradeoffs between multiple definitions (Berk et al., 2018; Costanza-Chock, 2020; Davis et al., 2021; Kleinberg et al., 2019; Wong, 2020).",
            "Recent work provides several examples of how data analysis and technology design can be incorporated into community-driven reform efforts that challenge oppression (Asad, 2019; Costanza-Chock, 2020; Lewis et al., 2018; Maharawal & McElroy, 2018; Meng & DiSalvo, 2018).",
            "In turn, some scholars have called for rejecting the frame of \u201cfairness\u201d altogether, proposing alternative frames of \u201cjustice\u201d (Bui & Noble, 2020; Costanza-Chock, 2020; Green, 2018), \u201cequity\u201d (D\u2019Ignazio & Klein, 2020), and \u201creparation\u201d (Davis et al., 2021)."
          ],
          "intents": []
        },
        {
          "paperId": "2c4cc62a1fe667e41ac7f577f173d57cbf26dec5",
          "title": "The false promise of risk assessments: epistemic reform and the limits of fairness",
          "authors": [
            {
              "name": "Ben Green",
              "authorId": "87122962"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 88,
          "doi": "10.1145/3351095.3372869",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/2c4cc62a1fe667e41ac7f577f173d57cbf26dec5",
          "venue": "FAT*",
          "isInfluential": true,
          "contexts": [
            "3 Like other pretrial risk assessments, COMPAS predicts the likelihood that pretrial defendants will recidivate; these predictions are presented to judges to inform their decisions to release or detain each defendant until their trial (Green, 2020; Koepke & Robinson, 2018).",
            "This challenge is exacerbated by the fact that many political actors and technology companies benefit from formal algorithmic fairness, which allows them to embrace \u201cfairness\u201d without making significant political or economic concessions (Bui & Noble, 2020; Green, 2020; Powles & Nissenbaum, 2018).",
            "Thus, for instance, in light of concerns about the biases of judges, many court systems in the USA have adopted pretrial risk assessment algorithms as a central component of criminal justice reforms (Green, 2020; Koepke & Robinson, 2018; Porrino, 2017).",
            "Implementing pretrial risk assessments thus legitimizes preventative detention as the appropriate response to high-risk defendants and hinders efforts to promote less carceral alternatives (Green, 2020).",
            "Pretrial risk assessments define risk in ways that fail to account for the harms of detention on defendants and their communities, which are often more severe for marginalized defendants (Green, 2020; Yang, 2017).",
            "Algorithms that satisfy fairness standards often exacerbate oppression and legiti-mize unjust institutions (Davis et al., 2021; Green, 2020; Kalluri, 2020; Ochig-ame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018).",
            "Algorithms that satisfy fairness standards often exacerbate oppression and legitimize unjust institutions (Davis et  al., 2021; Green, 2020; Kalluri, 2020; Ochigame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018)."
          ],
          "intents": []
        },
        {
          "paperId": "6e2f91deecafbc876b25fe04c95207ad2ccc9789",
          "title": "Algorithmic realism: expanding the boundaries of algorithmic thought",
          "authors": [
            {
              "name": "Ben Green",
              "authorId": "87122962"
            },
            {
              "name": "Salom\u00e9 Vilj\u00f6en",
              "authorId": "1442065023"
            }
          ],
          "year": 2020,
          "abstract": null,
          "citationCount": 147,
          "doi": "10.1145/3351095.3372840",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/6e2f91deecafbc876b25fe04c95207ad2ccc9789",
          "venue": "FAT*",
          "isInfluential": true,
          "contexts": [
            "3 Like other pretrial risk assessments, COMPAS predicts the likelihood that pretrial defendants will recidivate; these predictions are presented to judges to inform their decisions to release or detain each defendant until their trial (Green, 2020; Koepke & Robinson, 2018).",
            "This challenge is exacerbated by the fact that many political actors and technology companies benefit from formal algorithmic fairness, which allows them to embrace \u201cfairness\u201d without making significant political or economic concessions (Bui & Noble, 2020; Green, 2020; Powles & Nissenbaum, 2018).",
            "Algorithmic interventions are indeterminate, often leading to impacts that differ from what was expected based on technical evaluations of the model (Green & Viljoen, 2020).",
            "Algorithmic interventions should be considered through an \u201cagnostic approach\u201d that prioritizes reform, without assuming any necessary or particular role for algorithms (Green & Viljoen, 2020).",
            "Thus, for instance, in light of concerns about the biases of judges, many court systems in the USA have adopted pretrial risk assessment algorithms as a central component of criminal justice reforms (Green, 2020; Koepke & Robinson, 2018; Porrino, 2017).",
            "Implementing pretrial risk assessments thus legitimizes preventative detention as the appropriate response to high-risk defendants and hinders efforts to promote less carceral alternatives (Green, 2020).",
            "Pretrial risk assessments define risk in ways that fail to account for the harms of detention on defendants and their communities, which are often more severe for marginalized defendants (Green, 2020; Yang, 2017).",
            "As a result, there is often a significant gap between mathematical evaluations of fairness and an algorithm\u2019s real-world impacts (Green & Viljoen, 2020).",
            "Algorithms that satisfy fairness standards often exacerbate oppression and legiti-mize unjust institutions (Davis et al., 2021; Green, 2020; Kalluri, 2020; Ochig-ame, 2020; Ochigame et al., 2018; Powles & Nissenbaum, 2018).",
            "Grounded primarily in computer science, algorithmic fairness applies the tools of algorithm design and analysis\u2014in particular, an emphasis on formal mathematical reasoning (Green & Viljoen, 2020)\u2014to fairness.",
            "Instead, substantive algorithmic fairness follows the approach of \u201calgorithmic realism\u201d (Green & Viljoen, 2020), expanding the scope of analysis to encompass the relational and structural considerations that surround particular decision points."
          ],
          "intents": []
        },
        {
          "paperId": "ff55d8a10d13543b22bca36e6bb5ec1374e65e99",
          "title": "Essentially Contested Concepts",
          "authors": [
            {
              "name": "W. B. Gallie",
              "authorId": "16817202"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 1178,
          "doi": "10.7591/9781501741319-010",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/ff55d8a10d13543b22bca36e6bb5ec1374e65e99",
          "venue": "The Importance of Language",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "e52017a3c3928033bca2ed3e7a75a7079c818572",
          "title": "The Condemnation of Blackness",
          "authors": [
            {
              "name": "K. Muhammad",
              "authorId": "120706898"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 358,
          "doi": "10.4159/9780674240919",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/e52017a3c3928033bca2ed3e7a75a7079c818572",
          "venue": "",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "681f4fbce872f138cbac9cdd92e8f6ed89ba6f8d",
          "title": "Measurement and Fairness",
          "authors": [
            {
              "name": "Abigail Z. Jacobs",
              "authorId": "47786922"
            },
            {
              "name": "Hanna M. Wallach",
              "authorId": "1831395"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 448,
          "doi": "10.1145/3442188.3445901",
          "arxivId": "1912.05511",
          "url": "https://www.semanticscholar.org/paper/681f4fbce872f138cbac9cdd92e8f6ed89ba6f8d",
          "venue": "Conference on Fairness, Accountability and Transparency",
          "isInfluential": true,
          "contexts": [
            "As with fairness more generally [13, 47, 53, 85], attempting to reduce substantive equality to mathematical definitions is likely to narrow and distort the concept.",
            "of fairness overlook the contextual and philosophical meanings of fairness [13, 47, 53, 85].",
            "For a broader discussion of the relationship between measurement and algorithmic fairness, see [53].",
            "Although no mathematical definitions of algorithmic fairness fully encapsulate the philosophical notion of fairness [13, 47, 53, 85], each captures a normatively desirable principle.",
            "Efforts to formulate mathematical definitions of fairness overlook the contextual and philosophical meanings of fairness (Binns, 2018; Green & Hu, 2018; Jacobs & Wallach, 2021; Lee et al., 2021; Selbst et al., 2019).",
            "1 Although no mathematical definition of algorithmic fairness fully encapsulates the philosophical notion of fairness or justice (Binns, 2018; Green & Hu, 2018; Jacobs & Wallach, 2021; Lee et al., 2021; Selbst et al., 2019), each definition captures a normatively desirable principle."
          ],
          "intents": []
        },
        {
          "paperId": "e9dd8f892052fcdecb0852bc422dd79bce5ce7e8",
          "title": "Roles for computing in social change",
          "authors": [
            {
              "name": "Rediet Abebe",
              "authorId": "5651696"
            },
            {
              "name": "Solon Barocas",
              "authorId": "2881033"
            },
            {
              "name": "J. Kleinberg",
              "authorId": "3371403"
            },
            {
              "name": "K. Levy",
              "authorId": "144463523"
            },
            {
              "name": "Manish Raghavan",
              "authorId": "38009222"
            },
            {
              "name": "D. G. Robinson",
              "authorId": "144440321"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 232,
          "doi": "10.1145/3351095.3372871",
          "arxivId": "1912.04883",
          "url": "https://www.semanticscholar.org/paper/e9dd8f892052fcdecb0852bc422dd79bce5ce7e8",
          "venue": "FAT*",
          "isInfluential": false,
          "contexts": [
            "Algorithms can best help to promote social change when deployed in conjunction with broader policy and governance reforms (Abebe et al., 2020; Green, 2019).",
            "Algorithms can play productive roles in support of broader efforts for social change [1], particularly when deployed in conjunction with policy and governance reforms [44]."
          ],
          "intents": []
        },
        {
          "paperId": "fefbdc35eb0ef052954eeaaf80015d21ccc97b4e",
          "title": "Prefigurative Design as a Method for Research Justice",
          "authors": [
            {
              "name": "M. Asad",
              "authorId": "1576309595"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 108,
          "doi": "10.1145/3359302",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/fefbdc35eb0ef052954eeaaf80015d21ccc97b4e",
          "venue": "Proc. ACM Hum. Comput. Interact.",
          "isInfluential": false,
          "contexts": [
            "inequalities [23, 39], and empower communities advocating for criminal justice reform [8, 21]\u2014 all of which would help to inform and enable structural responses.",
            "Recent work provides several examples of how data analysis and technology design can be incorporated into community-driven reform efforts that challenge oppression (Asad, 2019; Costanza-Chock, 2020; Lewis et al., 2018; Maharawal & McElroy, 2018; Meng & DiSalvo, 2018)."
          ],
          "intents": []
        },
        {
          "paperId": "4e40cdf1e44c820096865da63180ddaf583e1ed5",
          "title": "Dissecting racial bias in an algorithm used to manage the health of populations",
          "authors": [
            {
              "name": "Z. Obermeyer",
              "authorId": "3797258"
            },
            {
              "name": "Brian W. Powers",
              "authorId": "34593484"
            },
            {
              "name": "C. Vogeli",
              "authorId": "4744063"
            },
            {
              "name": "S. Mullainathan",
              "authorId": "2062143"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 4478,
          "doi": "10.1126/science.aax2342",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/4e40cdf1e44c820096865da63180ddaf583e1ed5",
          "venue": "Science",
          "isInfluential": false,
          "contexts": [],
          "intents": []
        },
        {
          "paperId": "30bcfe3a6e7191547c1d437a1b18d1ef2b3cdb76",
          "title": "Replication data for: The Effects of Pretrial Detention on Conviction, Future Crime, and Employment: Evidence from Randomly Assigned Judges",
          "authors": [
            {
              "name": "Will Dobbie",
              "authorId": "66709376"
            },
            {
              "name": "Jacob Goldin",
              "authorId": "82126230"
            },
            {
              "name": "Crystal S. Yang",
              "authorId": "3802711"
            }
          ],
          "year": 2019,
          "abstract": null,
          "citationCount": 87,
          "doi": "10.3886/E113163V1",
          "arxivId": null,
          "url": "https://www.semanticscholar.org/paper/30bcfe3a6e7191547c1d437a1b18d1ef2b3cdb76",
          "venue": "",
          "isInfluential": true,
          "contexts": [
            "Although detention reduces defendants\u2019 short-term likelihood of crime, it also increases their long-term propensity for crime, yielding no net effect on future crime (Dobbie et al., 2018).",
            "13 including the loss of freedom, an increased likelihood of conviction, and a reduction in future employment (Dobbie et al., 2018).",
            "\u2026and exacerbating mass incarceration (Bara-daran, 2011; Koepke & Robinson, 2018; United States Supreme Court, 1987) Pretrial detention imposes severe costs on defendants, including the loss of freedom, an increased likelihood of conviction, and a reduction in future employment (Dobbie et al., 2018).",
            "13 As an added benefit, these reforms would reduce the future crime rate of defendants (Dobbie et al., 2018)."
          ],
          "intents": []
        }
      ],
      "citations": [],
      "references_count": 25,
      "citations_count": 0
    }
  ],
  "count": 1,
  "errors": []
}
