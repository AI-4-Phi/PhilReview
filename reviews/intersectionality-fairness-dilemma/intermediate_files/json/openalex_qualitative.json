{
  "status": "success",
  "source": "openalex",
  "query": "qualitative fairness AI",
  "results": [
    {
      "openalex_id": "W4382133845",
      "doi": "10.1016/j.caeai.2023.100152",
      "title": "Fairness, Accountability, Transparency, and Ethics (FATE) in Artificial Intelligence (AI) and higher education: A systematic review",
      "authors": [
        {
          "name": "Bahar Memarian",
          "openalex_id": "A5017925086",
          "orcid": "https://orcid.org/0000-0003-0671-3127",
          "institutions": [
            "Simon Fraser University"
          ]
        },
        {
          "name": "Tenzin Doleck",
          "openalex_id": "A5017704287",
          "orcid": "https://orcid.org/0000-0002-1279-689X",
          "institutions": [
            "Simon Fraser University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "Background: The use of Artificial Intelligence or AI is rising in higher education. With this rise, the morality of AI programs is being questioned. There is, as such, a need to understand how notions of Fairness, Accountability, Transparency, and Ethics or FATE are identified in the AI and higher education studies to date. Purpose: This systematic review paper aims to understand definitions and studies on FATE and AI in the higher education literature. The contribution of this work is to provide a summary of FATE development and the synthesis of the challenges and potentials of each of the reviewed studies. Method: A total of 33 publications from SCOPUS and Web of Science (WoS) were included in this systematic literature review. We examined definitions of FATE noted in the reviewed articles (may have been multiple in each study) and grouped them into descriptive (understandable by laypeople) and technical (containing jargon) definitions. We also examined the main FATE term studied in detail in each reviewed article and grouped them into qualitative and quantitative studies. Results: Findings show more descriptive definitions exist (especially for fairness) and similarly quantitative definitions mostly emerge for Fairness. Findings also show more quantitative studies exist (especially for fairness) and qualitative definitions mostly emerge for ethics. Generally, though, there are more definitions than relevant studies conducted in the literature. Conclusion: This systematic literature review offers a summary of definitions and studies conducted for FATE terms and AI in the higher education literature. Future work may benefit from bridging the gap between laypeople and experts by linking descriptive definitions with technical ones as well as qualitative studies with quantitative ones. Moreover, future work can study accountability and transparency further and make the study of FATE terms more longitudinal, open-access, and reproducible.",
      "cited_by_count": 264,
      "type": "review",
      "source": {
        "name": "Computers and Education Artificial Intelligence",
        "type": "journal",
        "issn": [
          "2666-920X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1016/j.caeai.2023.100152"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Artificial Intelligence in Healthcare and Education",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "referenced_works_count": 65,
      "url": "https://openalex.org/W4382133845"
    },
    {
      "openalex_id": "W4323041949",
      "doi": "10.1016/j.jjimei.2023.100165",
      "title": "How can we manage biases in artificial intelligence systems \u2013 A systematic literature review",
      "authors": [
        {
          "name": "P. S. Varsha",
          "openalex_id": "A5000563468",
          "institutions": [
            "Presidency University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-03-03",
      "abstract": null,
      "cited_by_count": 204,
      "type": "article",
      "source": {
        "name": "International Journal of Information Management Data Insights",
        "type": "journal",
        "issn": [
          "2667-0968"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1016/j.jjimei.2023.100165"
      },
      "topics": [
        "Ethics and Social Impacts of AI"
      ],
      "referenced_works_count": 116,
      "url": "https://openalex.org/W4323041949"
    },
    {
      "openalex_id": "W4210708600",
      "doi": "10.1007/s10796-021-10223-8",
      "title": "AI Decision Making with Dignity? Contrasting Workers\u2019 Justice Perceptions of Human and AI Decision Making in a Human Resource Management Context",
      "authors": [
        {
          "name": "Sarah Bankins",
          "openalex_id": "A5009459648",
          "orcid": "https://orcid.org/0000-0003-2290-3086",
          "institutions": [
            "Macquarie University"
          ]
        },
        {
          "name": "Paul Formosa",
          "openalex_id": "A5067925382",
          "orcid": "https://orcid.org/0000-0002-7490-0242",
          "institutions": [
            "Macquarie University"
          ]
        },
        {
          "name": "Yannick Griep",
          "openalex_id": "A5054045559",
          "orcid": "https://orcid.org/0000-0002-5005-5443",
          "institutions": [
            "Radboud University Nijmegen"
          ]
        },
        {
          "name": "Deborah Richards",
          "openalex_id": "A5025995864",
          "orcid": "https://orcid.org/0000-0002-7363-1511",
          "institutions": [
            "Macquarie University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-02-02",
      "abstract": "Abstract Using artificial intelligence (AI) to make decisions in human resource management (HRM) raises questions of how fair employees perceive these decisions to be and whether they experience respectful treatment (i.e., interactional justice). In this experimental survey study with open-ended qualitative questions, we examine decision making in six HRM functions and manipulate the decision maker (AI or human) and decision valence (positive or negative) to determine their impact on individuals\u2019 experiences of interactional justice, trust, dehumanization, and perceptions of decision-maker role appropriateness. In terms of decision makers, the use of human decision makers over AIs generally resulted in better perceptions of respectful treatment. In terms of decision valence, people experiencing positive over negative decisions generally resulted in better perceptions of respectful treatment. In instances where these cases conflict, on some indicators people preferred positive AI decisions over negative human decisions. Qualitative responses show how people identify justice concerns with both AI and human decision making. We outline implications for theory, practice, and future research.",
      "cited_by_count": 149,
      "type": "article",
      "source": {
        "name": "Information Systems Frontiers",
        "type": "journal",
        "issn": [
          "1387-3326",
          "1572-9419"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s10796-021-10223-8.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Psychology of Moral and Emotional Judgment",
        "Social and Intergroup Psychology"
      ],
      "referenced_works_count": 58,
      "url": "https://openalex.org/W4210708600"
    },
    {
      "openalex_id": "W4283788756",
      "doi": "10.1007/s00146-022-01525-9",
      "title": "Understanding user sensemaking in fairness and transparency in algorithms: algorithmic sensemaking in over-the-top platform",
      "authors": [
        {
          "name": "Donghee Shin",
          "openalex_id": "A5033766968",
          "orcid": "https://orcid.org/0000-0002-5439-4493",
          "institutions": [
            "Zayed University"
          ]
        },
        {
          "name": "Joon Soo Lim",
          "openalex_id": "A5037240885",
          "orcid": "https://orcid.org/0000-0003-0519-4169",
          "institutions": [
            "Syracuse University"
          ]
        },
        {
          "name": "Norita Ahmad",
          "openalex_id": "A5061643029",
          "orcid": "https://orcid.org/0000-0001-5129-1133",
          "institutions": [
            "American University of Sharjah"
          ]
        },
        {
          "name": "Mohammed Ibahrine",
          "openalex_id": "A5052202107",
          "orcid": "https://orcid.org/0000-0002-2782-3029",
          "institutions": [
            "American University of Sharjah"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-07-03",
      "abstract": null,
      "cited_by_count": 85,
      "type": "article",
      "source": {
        "name": "AI & Society",
        "type": "journal",
        "issn": [
          "0951-5666",
          "1435-5655"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Psychology of Moral and Emotional Judgment",
        "Privacy, Security, and Data Protection"
      ],
      "referenced_works_count": 27,
      "url": "https://openalex.org/W4283788756"
    },
    {
      "openalex_id": "W4388103298",
      "doi": "10.5267/j.ijdns.2023.9.014",
      "title": "Ethical implications of artificial intelligence in accounting: A framework for responsible ai adoption in multinational corporations in Jordan",
      "authors": [
        {
          "name": "Ahmad Y. A. Bani Ahmad",
          "openalex_id": "A5100642305",
          "orcid": "https://orcid.org/0000-0003-4517-8788",
          "institutions": [
            "Middle East University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-30",
      "abstract": "The accelerated progress of Artificial Intelligence (AI) within the accounting field has resulted in a heightened use of this technology in international enterprises, therefore generating noteworthy ethical concerns. This research investigates the ethical implications that arise from the use of AI in accounting practices, focusing on international corporations operating in Jordan. The objective of this research is to provide a comprehensive framework for the ethical and responsible integration of AI within the accounting domain. The research used a survey methods approach while 379 respondents were selected using cluster and proportional sampling. The qualitative component of the research investigates the viewpoints and concerns of persons pertaining to the use of AI. The study results provide significant contributions to the development of a context-specific paradigm for AI ethics that prioritizes concepts such as transparency, fairness, and accountability. The findings of this study have substantial value for multinational corporations engaged in commercial operations in Jordan and similar regions. The results provide organizations with the necessary tools to proficiently address the ethical dilemmas that emerge as a result of using artificial intelligence in accounting procedures.",
      "cited_by_count": 67,
      "type": "article",
      "source": {
        "name": "International Journal of Data and Network Science",
        "type": "journal",
        "issn": [
          "2561-8148",
          "2561-8156"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "diamond",
        "oa_url": "https://doi.org/10.5267/j.ijdns.2023.9.014"
      },
      "topics": [
        "Blockchain Technology Applications and Security",
        "Impact of AI and Big Data on Business and Society"
      ],
      "referenced_works_count": 1,
      "url": "https://openalex.org/W4388103298"
    },
    {
      "openalex_id": "W4291197616",
      "doi": "10.1007/s11023-022-09611-z",
      "title": "Contestable AI by Design: Towards a Framework",
      "authors": [
        {
          "name": "Kars Alfrink",
          "openalex_id": "A5042409595",
          "orcid": "https://orcid.org/0000-0001-7562-019X",
          "institutions": [
            "Delft University of Technology"
          ]
        },
        {
          "name": "Ianus Keller",
          "openalex_id": "A5012446172",
          "orcid": "https://orcid.org/0000-0002-2369-248X",
          "institutions": [
            "Delft University of Technology"
          ]
        },
        {
          "name": "Gerd Kortuem",
          "openalex_id": "A5043360227",
          "orcid": "https://orcid.org/0000-0003-3500-0046",
          "institutions": [
            "Delft University of Technology"
          ]
        },
        {
          "name": "Neelke Doorn",
          "openalex_id": "A5061290782",
          "orcid": "https://orcid.org/0000-0002-1090-579X",
          "institutions": [
            "Delft University of Technology"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-08-13",
      "abstract": null,
      "cited_by_count": 53,
      "type": "article",
      "source": {
        "name": "Minds and Machines",
        "type": "journal",
        "issn": [
          "0924-6495",
          "1572-8641"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s11023-022-09611-z.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Information Systems Theories and Implementation",
        "Innovative Human-Technology Interaction"
      ],
      "referenced_works_count": 79,
      "url": "https://openalex.org/W4291197616"
    },
    {
      "openalex_id": "W4205454992",
      "doi": "10.1148/ryai.210059",
      "title": "Clinical Assessment of Deep Learning\u2013based Super-Resolution for 3D Volumetric Brain MRI",
      "authors": [
        {
          "name": "Jeffrey D. Rudie",
          "openalex_id": "A5078562544",
          "orcid": "https://orcid.org/0000-0001-8609-8421",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Tyler Gleason",
          "openalex_id": "A5073734002",
          "orcid": "https://orcid.org/0000-0003-0752-8329",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Matthew J. Barkovich",
          "openalex_id": "A5021165094",
          "orcid": "https://orcid.org/0000-0002-8257-423X",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "David M. Wilson",
          "openalex_id": "A5026285477",
          "orcid": "https://orcid.org/0000-0002-1095-046X",
          "institutions": [
            "Stanford University",
            "University of California, San Francisco"
          ]
        },
        {
          "name": "Ajit Shankaranarayanan",
          "openalex_id": "A5056309373",
          "orcid": "https://orcid.org/0000-0001-9395-8768",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Tao Zhang",
          "openalex_id": "A5080402038",
          "orcid": "https://orcid.org/0000-0002-3147-794X",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Long Wang",
          "openalex_id": "A5100447536",
          "orcid": "https://orcid.org/0000-0001-5600-8157",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Enhao Gong",
          "openalex_id": "A5035343735",
          "orcid": "https://orcid.org/0000-0002-4002-909X",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Greg Zaharchuk",
          "openalex_id": "A5065577825",
          "orcid": "https://orcid.org/0000-0001-5781-8848",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        },
        {
          "name": "Javier Villanueva-Meyer",
          "openalex_id": "A5051765330",
          "orcid": "https://orcid.org/0000-0002-5910-0757",
          "institutions": [
            "University of California, San Francisco",
            "Stanford University"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-01-12",
      "abstract": "Artificial intelligence (AI)-based image enhancement has the potential to reduce scan times while improving signal-to-noise ratio (SNR) and maintaining spatial resolution. This study prospectively evaluated AI-based image enhancement in 32 consecutive patients undergoing clinical brain MRI. Standard-of-care (SOC) three-dimensional (3D) T1 precontrast, 3D T2 fluid-attenuated inversion recovery, and 3D T1 postcontrast sequences were performed along with 45% faster versions of these sequences using half the number of phase-encoding steps. Images from the faster sequences were processed by a Food and Drug Administration-cleared AI-based image enhancement software for resolution enhancement. Four board-certified neuroradiologists scored the SOC and AI-enhanced image series independently on a five-point Likert scale for image SNR, anatomic conspicuity, overall image quality, imaging artifacts, and diagnostic confidence. While interrater \u03ba was low to fair, the AI-enhanced scans were noninferior for all metrics and actually demonstrated a qualitative SNR improvement. Quantitative analyses showed that the AI software restored the high spatial resolution of small structures, such as the septum pellucidum. In conclusion, AI-based software can achieve noninferior image quality for 3D brain MRI sequences with a 45% scan time reduction, potentially improving the patient experience and scanner efficiency without sacrificing diagnostic quality. <b>Keywords:</b> MR Imaging, CNS, Brain/Brain Stem, Reconstruction Algorithms \u00a9 RSNA, 2022.",
      "cited_by_count": 80,
      "type": "article",
      "source": {
        "name": "Radiology Artificial Intelligence",
        "type": "journal",
        "issn": [
          "2638-6100"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/8980882"
      },
      "topics": [
        "Medical Imaging Techniques and Applications",
        "Advanced MRI Techniques and Applications",
        "Radiomics and Machine Learning in Medical Imaging"
      ],
      "referenced_works_count": 15,
      "url": "https://openalex.org/W4205454992"
    },
    {
      "openalex_id": "W4391706746",
      "doi": "10.30574/ijsra.2024.11.1.0218",
      "title": "Ethical AI in practice: Balancing technological advancements with human values",
      "authors": [
        {
          "name": "Benjamin Samson Ayinla",
          "openalex_id": "A5093902225",
          "institutions": [
            "The University of Law"
          ]
        },
        {
          "name": "Olukunle Oladipupo Amoo",
          "openalex_id": "A5093902226",
          "institutions": [
            "University of Nebraska at Omaha"
          ]
        },
        {
          "name": "Akoh Atadoga",
          "openalex_id": "A5093828504",
          "institutions": [
            "Film Independent"
          ]
        },
        {
          "name": "Temitayo Oluwaseun Abrahams",
          "openalex_id": "A5093631503",
          "institutions": [
            "University of Adelaide"
          ]
        },
        {
          "name": "Femi Osasona",
          "openalex_id": "A5093839160",
          "institutions": [
            "Scottish Water (United Kingdom)"
          ]
        },
        {
          "name": "Oluwatoyin Ajoke Farayola",
          "openalex_id": "A5093337338",
          "institutions": [
            "IFMR Graduate School of Business"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-02-09",
      "abstract": "In an era where artificial intelligence (AI) increasingly intersects with every facet of human life, the imperative for ethical AI has never been more pronounced. This paper delves into the complex interplay between technological advancements in AI and the overarching human values that guide societal norms. The background of the study establishes the urgency of addressing ethical challenges inherent in AI, such as privacy, bias, and accountability, within the broader context of regulatory and policy frameworks. Aiming to critically evaluate the integration and effectiveness of ethical principles in AI applications, the paper navigates through a qualitative analysis, employing theoretical frameworks to dissect the ethical dimensions of AI. The scope encompasses a diverse range of topics, including global trends in ethical AI development, the impact of AI on human rights and personal freedoms, and the analysis of bias and fairness in AI algorithms. Real-world case studies provide insights into the successes and failures of ethical AI implementation, while the role of public perception and trust in AI adoption is scrutinized. The main conclusions reveal a dynamic global landscape of ethical AI, emphasizing the need for robust ethical frameworks and proactive strategies to mitigate biases and ensure equitable outcomes. Recommendations advocate for clear ethical guidelines, integration of ethics in AI development, transparency, accountability, multi-stakeholder collaboration, public engagement, and continuous ethical evaluation. The study concludes that balancing technological innovation with ethical constraints is crucial for the responsible development of AI. It underscores the importance of ethical vigilance, ensuring AI aligns with societal values and individual rights.",
      "cited_by_count": 49,
      "type": "article",
      "source": {
        "name": "International Journal of Science and Research Archive",
        "type": "journal",
        "issn": [
          "2582-8185"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://ijsra.net/sites/default/files/IJSRA-2024-0218.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI"
      ],
      "referenced_works_count": 57,
      "url": "https://openalex.org/W4391706746"
    },
    {
      "openalex_id": "W4386246835",
      "doi": "10.1145/3600211.3604712",
      "title": "Supporting Human-AI Collaboration in Auditing LLMs with LLMs",
      "authors": [
        {
          "name": "Charvi Rastogi",
          "openalex_id": "A5053419988",
          "orcid": "https://orcid.org/0000-0003-0820-4115",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Marco T\u00falio Ribeiro",
          "openalex_id": "A5019726734",
          "orcid": "https://orcid.org/0000-0002-3301-1297",
          "institutions": [
            "Microsoft (United States)"
          ]
        },
        {
          "name": "Nicholas S. P. King",
          "openalex_id": "A5101636045",
          "orcid": "https://orcid.org/0009-0002-2126-5115",
          "institutions": [
            "Microsoft (United States)"
          ]
        },
        {
          "name": "Harsha Nori",
          "openalex_id": "A5050672320",
          "orcid": "https://orcid.org/0000-0002-5442-1359",
          "institutions": [
            "Microsoft (United States)"
          ]
        },
        {
          "name": "Saleema Amershi",
          "openalex_id": "A5057541630",
          "orcid": "https://orcid.org/0000-0002-3294-7288",
          "institutions": [
            "Microsoft (United States)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-08-08",
      "abstract": "Large language models (LLMs) are increasingly becoming all-powerful and pervasive via deployment in sociotechnical systems. Yet these language models, be it for classification or generation, have been shown to be biased, behave irresponsibly, causing harm to people at scale. It is crucial to audit these language models rigorously before deployment. Existing auditing tools use either or both humans and AI to find failures. In this work, we draw upon literature in human-AI collaboration and sensemaking, and interview research experts in safe and fair AI, to build upon the auditing tool: AdaTest [36], which is powered by a generative LLM. Through the design process we highlight the importance of sensemaking and human-AI communication to leverage complementary strengths of humans and generative models in collaborative auditing. To evaluate the effectiveness of AdaTest++, the augmented tool, we conduct user studies with participants auditing two commercial language models: OpenAI's GPT-3 and Azure's sentiment analysis model. Qualitative analysis shows that AdaTest++ effectively leverages human strengths such as schematization, hypothesis testing. Further, with our tool, users identified a variety of failures modes, covering 26 different topics over 2 tasks, that have been shown in formal audits and also those previously under-reported.",
      "cited_by_count": 57,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3600211.3604712"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Software Engineering Research",
        "Explainable Artificial Intelligence (XAI)"
      ],
      "referenced_works_count": 32,
      "url": "https://openalex.org/W4386246835"
    },
    {
      "openalex_id": "W4380369890",
      "doi": "10.1145/3593013.3594005",
      "title": "Envisioning Equitable Speech Technologies for Black Older Adults",
      "authors": [
        {
          "name": "Robin Brewer",
          "openalex_id": "A5009534537",
          "orcid": "https://orcid.org/0000-0003-3790-5834",
          "institutions": [
            "University of Michigan\u2013Ann Arbor"
          ]
        },
        {
          "name": "Christina Harrington",
          "openalex_id": "A5072208377",
          "orcid": "https://orcid.org/0000-0003-1850-6459",
          "institutions": [
            "Carnegie Mellon University"
          ]
        },
        {
          "name": "Courtney Heldreth",
          "openalex_id": "A5033168947",
          "orcid": "https://orcid.org/0000-0002-9921-7247",
          "institutions": [
            "Google (United States)"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-06-12",
      "abstract": "There is increasing concern that how researchers currently define and measure fairness is inadequate. Recent calls push to move beyond traditional concepts of fairness and consider related constructs through qualitative and community-based approaches, particularly for underrepresented communities most at-risk for AI harm. One in context, previous research has identified that voice technologies are unfair due to racial and age disparities. This paper uses voice technologies as a case study to unpack how Black older adults value and envision fair and equitable AI systems. We conducted design workshops and interviews with 16 Black older adults, exploring how participants envisioned voice technologies that better understand cultural context and mitigate cultural dissonance. Our findings identify tensions between what it means to have fair, inclusive, and representative voice technologies. This research raises questions about how and whether researchers can model cultural representation with large language models.",
      "cited_by_count": 35,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3593013.3594005"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Hate Speech and Cyberbullying Detection",
        "Social Robot Interaction and HRI"
      ],
      "referenced_works_count": 42,
      "url": "https://openalex.org/W4380369890"
    },
    {
      "openalex_id": "W4402635151",
      "doi": "10.1016/j.caeai.2024.100306",
      "title": "Navigating the ethical terrain of AI in education: A systematic review on framing responsible human-centered AI practices",
      "authors": [
        {
          "name": "Yao Fu",
          "openalex_id": "A5013102842",
          "orcid": "https://orcid.org/0000-0002-4256-335X"
        },
        {
          "name": "Zhenjie Weng",
          "openalex_id": "A5107452043"
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-09-19",
      "abstract": "With the rapid development of artificial intelligence (AI) in recent years, there has been an increasing number of studies on integrating AI in various educational contexts, ranging from early childhood to higher education. Although systematic reviews have widely reported the effects of AI on teaching and learning, limited reviews have examined and defined responsible AI in education (AIED). To fill this gap, we conducted a convergent systematic mixed studies review to analyze key themes emerging from primary research. Following the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) guidelines, we searched Scopus and Web of Science and identified 40 empirical studies that satisfied our inclusion criteria. Specifically, we used four criteria for the screening process: (1) the study's full text was available in English; (2) the study was published before April 10th, 2024 in peer-reviewed journals or conference proceedings; (3) the study was primary research that collected original data and applied qualitative, quantitative, or mixed-methods as the study methodology; and (4) the study had a clear focus on ethical and/or responsible AI in one or multiple educational context(s). Our findings identified essential stakeholders and characteristics of responsible AI in K-20 educational contexts and expanded understanding of responsible human-centered AI (HCAI). We unveiled characteristics vital to HCAI, encompassing Fairness and Equity, Privacy and Security, Non-maleficence and Beneficence, Agency and Autonomy, and Transparency and Intelligibility. In addition, we provided suggestions on how to achieve responsible HCAI via collaborative efforts of stakeholders, including roles of users (e.g., students and educators), developers, researchers, and policy and decision-makers.",
      "cited_by_count": 70,
      "type": "review",
      "source": {
        "name": "Computers and Education Artificial Intelligence",
        "type": "journal",
        "issn": [
          "2666-920X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1016/j.caeai.2024.100306"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Explainable Artificial Intelligence (XAI)",
        "Artificial Intelligence in Healthcare and Education"
      ],
      "referenced_works_count": 111,
      "url": "https://openalex.org/W4402635151"
    },
    {
      "openalex_id": "W4226315956",
      "doi": "10.55539/jesd",
      "title": "Journal of economic and social development",
      "authors": [
        {
          "name": "Lehlohonolo Josiaya Malope",
          "openalex_id": ""
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-04-05",
      "abstract": "The study titled \"Unlocking the Potential: Examining the Impact of Artificial Intelligence on Improving EHealth in South Africa\" examines how artificial intelligence (AI) can help solve the substantial inequalities in healthcare access and quality in South Africa. Despite persistent actions to enhance healthcare services, a significant disparity persists, especially in remote and disadvantaged areas. This study seeks to investigate the ways in which AI can improve e-health services, with a specific focus on its ability to address the healthcare gap and enhance results throughout the entire country. The study utilizes a qualitative approach, examining pre-existing literature, policy papers, and expert viewpoints to clarify the influence of AI on the provision of healthcare. The results emphasize that AI technologies, such as Virtual Health Assistants (VHAs) and remote monitoring systems, can greatly reduce the workload on public healthcare institutions, improve the management of chronic diseases, and automate administrative duties. Through the optimization of these processes, artificial intelligence (AI) has the potential to allocate more time for healthcare workers to prioritize patient care. Furthermore, the article highlights the need of tackling obstacles such as concerns around the protection of data and the requirement for strong digital infrastructure to facilitate the deployment of AI. Suggested measures involve allocating resources towards customized artificial intelligence solutions, improving the training of healthcare professionals, and promoting cooperation among relevant parties to develop efficient electronic health initiatives. In conclusion, the article highlights the capacity of AI to transform healthcare in South Africa, by ensuring fair availability of high-quality treatments and enhancing health results for the entire population. Through addressing current barriers and harnessing the potential of artificial intelligence, South Africa has the potential to make substantial progress in attaining universal healthcare coverage and guaranteeing universal access to vital healthcare services.",
      "cited_by_count": 75,
      "type": "paratext",
      "source": {
        "name": "Journal of economic and social development",
        "type": "journal",
        "issn": [
          "1849-3327",
          "1849-6628"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "diamond",
        "oa_url": "https://doi.org/10.55539/jesd"
      },
      "topics": [],
      "referenced_works_count": 0,
      "url": "https://openalex.org/W4226315956"
    },
    {
      "openalex_id": "W4376622637",
      "doi": "10.51244/ijrsi.2023.10412",
      "title": "Analyzing the Impact of Artificial Intelligence in Personalized Learning and Adaptive Assessment in Higher Education",
      "authors": [
        {
          "name": "Bundit Anuyahong",
          "openalex_id": "A5056910552",
          "orcid": "https://orcid.org/0000-0003-2752-0092",
          "institutions": [
            "TAFE Queensland Gold Coast"
          ]
        },
        {
          "name": "Chalong Rattanapong",
          "openalex_id": "A5050054443",
          "institutions": [
            "Rajamangala University of Technology Rattanakosin"
          ]
        },
        {
          "name": "Inteera Patcha",
          "openalex_id": "A5091950890",
          "institutions": [
            "Nakhon Pathom Rajabhat University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-01-01",
      "abstract": "This This research aims to examine the impact of AI on personalized learning and adaptive assessment in higher education and investigate the ethical and social implications of using AI in these contexts. A mixed-methods approach was used, involving surveys, interviews, focus groups, institutional records, and system logs to collect both quantitative and qualitative data. The population included higher education institutions that use AI in personalized learning and adaptive assessment systems, as well as students and educators who use these systems. The results of the study showed that AI-based systems had a positive impact on student engagement and motivation, as well as providing personalized learning experiences. However, the analysis also revealed some limitations and potential concerns, such as technical issues and the potential for bias in the AI algorithms used in these systems. Ethical and social implications were analyzed using ethical frameworks such as the Belmont Report and principles of distributive justice. To ensure ethical and socially responsible use of AI in personalized learning and adaptive assessment, clear guidelines and standards for the development and implementation of these systems need to be established. This includes promoting transparency and accountability in the use of student data, ensuring that algorithms are developed and validated in a fair and unbiased manner, and involving diverse stakeholders in the design and implementation of these systems to promote equity and fairness. Informed consent should also be obtained from students and other stakeholders, and measures should be taken to ensure that student data is kept confidential and secure. Ongoing monitoring and evaluation should be conducted to assess the impact of AI-based systems on student outcomes and to identify and address any unintended consequences or biases.",
      "cited_by_count": 38,
      "type": "article",
      "source": {
        "name": "International journal of research and scientific innovation",
        "type": "journal",
        "issn": [
          "2320-5520",
          "2321-2705"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "bronze",
        "oa_url": "https://doi.org/10.51244/ijrsi.2023.10412"
      },
      "topics": [
        "Artificial Intelligence in Healthcare and Education",
        "Online Learning and Analytics"
      ],
      "referenced_works_count": 7,
      "url": "https://openalex.org/W4376622637"
    },
    {
      "openalex_id": "W3196804154",
      "doi": "10.1007/s00146-021-01267-0",
      "title": "Operationalising AI ethics: how are companies bridging the gap between practice and principles? An exploratory study",
      "authors": [
        {
          "name": "Javier Camacho Ib\u00e1\u00f1ez",
          "openalex_id": "A5041584502",
          "orcid": "https://orcid.org/0000-0001-7565-5480",
          "institutions": [
            "Comillas Pontifical University"
          ]
        },
        {
          "name": "M\u00f3nica Villas Olmeda",
          "openalex_id": "A5006945816",
          "institutions": [
            "National University of Distance Education"
          ]
        }
      ],
      "publication_year": 2021,
      "publication_date": "2021-08-31",
      "abstract": null,
      "cited_by_count": 65,
      "type": "article",
      "source": {
        "name": "AI & Society",
        "type": "journal",
        "issn": [
          "0951-5666",
          "1435-5655"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Psychology of Moral and Emotional Judgment",
        "Neuroethics, Human Enhancement, Biomedical Innovations"
      ],
      "referenced_works_count": 58,
      "url": "https://openalex.org/W3196804154"
    },
    {
      "openalex_id": "W4402858717",
      "doi": "10.1093/jamia/ocae209",
      "title": "Toward a responsible future: recommendations for AI-enabled clinical decision support",
      "authors": [
        {
          "name": "Steven E. Labkoff",
          "openalex_id": "A5058840375",
          "orcid": "https://orcid.org/0000-0002-2337-5185",
          "institutions": [
            "Beth Israel Deaconess Medical Center"
          ]
        },
        {
          "name": "Bilikis Oladimeji",
          "openalex_id": "A5018817602",
          "orcid": "https://orcid.org/0000-0001-7349-3350",
          "institutions": [
            "UnitedHealth Group (United States)"
          ]
        },
        {
          "name": "Joseph Kannry",
          "openalex_id": "A5075934122",
          "orcid": "https://orcid.org/0000-0002-6089-1488",
          "institutions": [
            "Icahn School of Medicine at Mount Sinai"
          ]
        },
        {
          "name": "Anthony Solomonides",
          "openalex_id": "A5006479392",
          "orcid": "https://orcid.org/0000-0003-2117-2461",
          "institutions": [
            "NorthShore University HealthSystem"
          ]
        },
        {
          "name": "Russell Leftwich",
          "openalex_id": "A5006516749",
          "orcid": "https://orcid.org/0009-0007-9722-5386",
          "institutions": [
            "Vanderbilt University"
          ]
        },
        {
          "name": "Eileen Koski",
          "openalex_id": "A5068438294",
          "orcid": "https://orcid.org/0000-0003-3621-9613",
          "institutions": [
            "IBM (United States)"
          ]
        },
        {
          "name": "Amanda L. Joseph",
          "openalex_id": "A5009773245",
          "orcid": "https://orcid.org/0000-0002-5869-037X",
          "institutions": [
            "University of Victoria"
          ]
        },
        {
          "name": "M\u00f3nica L\u00f3pez-Gonz\u00e1lez",
          "openalex_id": "A5062849275",
          "orcid": "https://orcid.org/0000-0001-9153-6852"
        },
        {
          "name": "Lee A. Fleisher",
          "openalex_id": "A5000934027",
          "orcid": "https://orcid.org/0000-0003-2899-2294",
          "institutions": [
            "University of Pennsylvania"
          ]
        },
        {
          "name": "Kimberly Nolen",
          "openalex_id": "A5054206119",
          "orcid": "https://orcid.org/0000-0001-8821-254X",
          "institutions": [
            "Pfizer (United States)"
          ]
        },
        {
          "name": "Sayon Dutta",
          "openalex_id": "A5063026397",
          "orcid": "https://orcid.org/0000-0002-0381-6860",
          "institutions": [
            "Harvard University",
            "Massachusetts General Hospital",
            "Mass General Brigham"
          ]
        },
        {
          "name": "Deborah R Levy",
          "openalex_id": "A5070345489",
          "orcid": "https://orcid.org/0000-0002-7324-3455",
          "institutions": [
            "VA Connecticut Healthcare System",
            "Yale University"
          ]
        },
        {
          "name": "Amy Price",
          "openalex_id": "A5071658432",
          "orcid": "https://orcid.org/0000-0002-5200-7322",
          "institutions": [
            "Dartmouth Institute for Health Policy and Clinical Practice"
          ]
        },
        {
          "name": "Paul Barr",
          "openalex_id": "A5054299570",
          "orcid": "https://orcid.org/0000-0002-6868-7625",
          "institutions": [
            "Dartmouth Institute for Health Policy and Clinical Practice"
          ]
        },
        {
          "name": "Jonathan D. Hron",
          "openalex_id": "A5085053401",
          "orcid": "https://orcid.org/0000-0003-2198-6174",
          "institutions": [
            "Harvard University",
            "Boston Children's Hospital"
          ]
        },
        {
          "name": "Baihan Lin",
          "openalex_id": "A5018612055",
          "orcid": "https://orcid.org/0000-0002-7979-5509",
          "institutions": [
            "Icahn School of Medicine at Mount Sinai",
            "Internet Society"
          ]
        },
        {
          "name": "Gyana Srivastava",
          "openalex_id": "A5102844971",
          "orcid": "https://orcid.org/0000-0002-7414-8062",
          "institutions": [
            "Harvard University",
            "Beth Israel Deaconess Medical Center"
          ]
        },
        {
          "name": "N\u00faria Pastor",
          "openalex_id": "A5015122068",
          "orcid": "https://orcid.org/0000-0003-3172-7459"
        },
        {
          "name": "Unai S\u00e1nchez Luque",
          "openalex_id": "A5029025374",
          "orcid": "https://orcid.org/0000-0002-5262-8778"
        },
        {
          "name": "Tien Thi Thuy Bui",
          "openalex_id": "A5102828872",
          "orcid": "https://orcid.org/0009-0004-5283-8494",
          "institutions": [
            "MCPHS University"
          ]
        },
        {
          "name": "Reva Singh",
          "openalex_id": "A5032118853",
          "orcid": "https://orcid.org/0000-0002-1168-0983",
          "institutions": [
            "American Medical Informatics Association"
          ]
        },
        {
          "name": "T. A. Williams",
          "openalex_id": "A5103428413",
          "orcid": "https://orcid.org/0009-0008-4482-6556",
          "institutions": [
            "American Medical Informatics Association"
          ]
        },
        {
          "name": "Mark G. Weiner",
          "openalex_id": "A5005654647",
          "orcid": "https://orcid.org/0000-0001-5586-9940",
          "institutions": [
            "Weill Cornell Medicine",
            "Cornell University"
          ]
        },
        {
          "name": "Tristan Naumann",
          "openalex_id": "A5023123863",
          "orcid": "https://orcid.org/0000-0003-2150-1747",
          "institutions": [
            "Microsoft (United States)"
          ]
        },
        {
          "name": "Dean F. Sittig",
          "openalex_id": "A5010098013",
          "orcid": "https://orcid.org/0000-0001-5811-8915",
          "institutions": [
            "The University of Texas Health Science Center at Houston"
          ]
        },
        {
          "name": "Gretchen Purcell Jackson",
          "openalex_id": "A5066556144",
          "orcid": "https://orcid.org/0000-0002-3242-8058",
          "institutions": [
            "Intuitive Surgical (United States)",
            "Vanderbilt University Medical Center"
          ]
        },
        {
          "name": "Yuri Quintana",
          "openalex_id": "A5022760712",
          "orcid": "https://orcid.org/0000-0001-6583-0257",
          "institutions": [
            "University of Victoria",
            "Homewood Research Institute",
            "Beth Israel Deaconess Medical Center",
            "Harvard University"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-09-26",
      "abstract": "Abstract Background Integrating artificial intelligence (AI) in healthcare settings has the potential to benefit clinical decision-making. Addressing challenges such as ensuring trustworthiness, mitigating bias, and maintaining safety is paramount. The lack of established methodologies for pre- and post-deployment evaluation of AI tools regarding crucial attributes such as transparency, performance monitoring, and adverse event reporting makes this situation challenging. Objectives This paper aims to make practical suggestions for creating methods, rules, and guidelines to ensure that the development, testing, supervision, and use of AI in clinical decision support (CDS) systems are done well and safely for patients. Materials and Methods In May 2023, the Division of Clinical Informatics at Beth Israel Deaconess Medical Center and the American Medical Informatics Association co-sponsored a working group on AI in healthcare. In August 2023, there were 4 webinars on AI topics and a 2-day workshop in September 2023 for consensus-building. The event included over 200 industry stakeholders, including clinicians, software developers, academics, ethicists, attorneys, government policy experts, scientists, and patients. The goal was to identify challenges associated with the trusted use of AI-enabled CDS in medical practice. Key issues were identified, and solutions were proposed through qualitative analysis and a 4-month iterative consensus process. Results Our work culminated in several key recommendations: (1) building safe and trustworthy systems; (2) developing validation, verification, and certification processes for AI-CDS systems; (3) providing a means of safety monitoring and reporting at the national level; and (4) ensuring that appropriate documentation and end-user training are provided. Discussion AI-enabled Clinical Decision Support (AI-CDS) systems promise to revolutionize healthcare decision-making, necessitating a comprehensive framework for their development, implementation, and regulation that emphasizes trustworthiness, transparency, and safety. This framework encompasses various aspects including model training, explainability, validation, certification, monitoring, and continuous evaluation, while also addressing challenges such as data privacy, fairness, and the need for regulatory oversight to ensure responsible integration of AI into clinical workflow. Conclusions Achieving responsible AI-CDS systems requires a collective effort from many healthcare stakeholders. This involves implementing robust safety, monitoring, and transparency measures while fostering innovation. Future steps include testing and piloting proposed trust mechanisms, such as safety reporting protocols, and establishing best practice guidelines.",
      "cited_by_count": 82,
      "type": "article",
      "source": {
        "name": "Journal of the American Medical Informatics Association",
        "type": "journal",
        "issn": [
          "1067-5027",
          "1527-974X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "green",
        "oa_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/11491642"
      },
      "topics": [
        "Artificial Intelligence in Healthcare and Education",
        "Ethics in Clinical Research",
        "Electronic Health Records Systems"
      ],
      "referenced_works_count": 42,
      "url": "https://openalex.org/W4402858717"
    },
    {
      "openalex_id": "W4391404408",
      "doi": "10.3390/educsci14020148",
      "title": "Development and Evaluation of a Custom GPT for the Assessment of Students\u2019 Designs in a Typography Course",
      "authors": [
        {
          "name": "Miada Almasre",
          "openalex_id": "A5088266974",
          "orcid": "https://orcid.org/0000-0002-4071-277X",
          "institutions": [
            "King Abdulaziz University"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-01-31",
      "abstract": "The recent advancements in the fields of AI technology, generative AI, and Large Language Models (LLMs) have increased the potential of the deployment of such tools in educational environments, especially in contexts where student assessment fairness, quality, and automation are a priority. This study introduces an AI-enhanced evaluation tool that utilizes OpenAI\u2019s GPT-4 and the recently released custom GPT feature to evaluate the typography designs of 25 students enrolled in the Visual Media diploma offered by King Abdulaziz University. A mixed methods approach is adopted to evaluate the performance of this tool against the rubric-based evaluations offered by two human evaluators, considering both grading and text feedback. The results indicate that there are statistically significant differences between the AI tool\u2019s grading and feedback when compared to that of Evaluator 2; however, none is reported with Evaluator 1. The study presents a qualitative interpretation of the comprehensive feedback by the evaluator and reflects in further research in this area.",
      "cited_by_count": 31,
      "type": "article",
      "source": {
        "name": "Education Sciences",
        "type": "journal",
        "issn": [
          "2227-7102"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://www.mdpi.com/2227-7102/14/2/148/pdf?version=1706708769"
      },
      "topics": [
        "Second Language Acquisition and Learning",
        "Educational Assessment and Pedagogy",
        "Open Education and E-Learning"
      ],
      "referenced_works_count": 18,
      "url": "https://openalex.org/W4391404408"
    },
    {
      "openalex_id": "W4384561835",
      "doi": "10.1007/s44163-023-00074-4",
      "title": "How AI developers can assure algorithmic fairness",
      "authors": [
        {
          "name": "Khensani Xivuri",
          "openalex_id": "A5030973419",
          "orcid": "https://orcid.org/0000-0002-1041-3648",
          "institutions": [
            "University of Johannesburg"
          ]
        },
        {
          "name": "Hossana Twinomurinzi",
          "openalex_id": "A5083962004",
          "orcid": "https://orcid.org/0000-0002-9811-3358",
          "institutions": [
            "University of Johannesburg"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-07-17",
      "abstract": "Abstract Artificial intelligence (AI) has rapidly become one of the technologies used for competitive advantage. However, there are also growing concerns about bias in AI models as AI developers risk introducing bias both unintentionally and intentionally. This study, using a qualitative approach, investigated how AI developers can contribute to the development of fair AI models. The key findings reveal that the risk of bias is mainly because of the lack of gender and social diversity in AI development teams, and haste from AI managers to deliver much-anticipated results. The integrity of AI developers is also critical as they may conceal bias from management and other AI stakeholders. The testing phase before model deployment risks bias because it is rarely representative of the diverse societal groups that may be affected. The study makes practical recommendations in four main areas: governance, social, technical, and training and development processes. Responsible organisations need to take deliberate actions to ensure that their AI developers adhere to fair processes when developing AI; AI developers must prioritise ethical considerations and consider the impact their models may have on society; partnerships between AI developers, AI stakeholders, and society that might be impacted by AI models should be established; and AI developers need to prioritise transparency and explainability in their models while ensuring adequate testing for bias and corrective measures before deployment. Emotional intelligence training should also be provided to the AI developers to help them engage in productive conversations with individuals outside the development team.",
      "cited_by_count": 23,
      "type": "article",
      "source": {
        "name": "Discover Artificial Intelligence",
        "type": "journal",
        "issn": [
          "2731-0809"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s44163-023-00074-4.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Artificial Intelligence in Healthcare and Education"
      ],
      "referenced_works_count": 19,
      "url": "https://openalex.org/W4384561835"
    },
    {
      "openalex_id": "W4396598447",
      "doi": "10.1371/journal.pdig.0000492",
      "title": "Achieving health equity through conversational AI: A roadmap for design and implementation of inclusive chatbots in healthcare",
      "authors": [
        {
          "name": "Tom Nadarzynski",
          "openalex_id": "A5019554383",
          "orcid": "https://orcid.org/0000-0001-7010-5308",
          "institutions": [
            "University of Westminster"
          ]
        },
        {
          "name": "Nicky Knights",
          "openalex_id": "A5036268823",
          "institutions": [
            "University of Westminster"
          ]
        },
        {
          "name": "Deborah Husbands",
          "openalex_id": "A5070548680",
          "orcid": "https://orcid.org/0000-0003-2979-5655",
          "institutions": [
            "University of Westminster"
          ]
        },
        {
          "name": "Cynthia A. Graham",
          "openalex_id": "A5056470797",
          "orcid": "https://orcid.org/0000-0002-7884-599X",
          "institutions": [
            "Indiana University Bloomington"
          ]
        },
        {
          "name": "Carrie Llewellyn",
          "openalex_id": "A5011614442",
          "orcid": "https://orcid.org/0000-0002-9107-8473",
          "institutions": [
            "University of Sussex",
            "Brighton and Sussex Medical School"
          ]
        },
        {
          "name": "Tom Buchanan",
          "openalex_id": "A5088287018",
          "orcid": "https://orcid.org/0000-0002-8994-2939",
          "institutions": [
            "University of Westminster"
          ]
        },
        {
          "name": "Ian Montgomery",
          "openalex_id": "A5010852797",
          "orcid": "https://orcid.org/0000-0002-7005-8027"
        },
        {
          "name": "Damien Ridge",
          "openalex_id": "A5032274875",
          "orcid": "https://orcid.org/0000-0001-9245-5958",
          "institutions": [
            "University of Westminster"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-05-02",
      "abstract": "Background The rapid evolution of conversational and generative artificial intelligence (AI) has led to the increased deployment of AI tools in healthcare settings. While these conversational AI tools promise efficiency and expanded access to healthcare services, there are growing concerns ethically, practically and in terms of inclusivity. This study aimed to identify activities which reduce bias in conversational AI and make their designs and implementation more equitable. Methods A qualitative research approach was employed to develop an analytical framework based on the content analysis of 17 guidelines about AI use in clinical settings. A stakeholder consultation was subsequently conducted with a total of 33 ethnically diverse community members, AI designers, industry experts and relevant health professionals to further develop a roadmap for equitable design and implementation of conversational AI in healthcare. Framework analysis was conducted on the interview data. Results A 10-stage roadmap was developed to outline activities relevant to equitable conversational AI design and implementation phases: 1) Conception and planning, 2) Diversity and collaboration, 3) Preliminary research, 4) Co-production, 5) Safety measures, 6) Preliminary testing, 7) Healthcare integration, 8) Service evaluation and auditing, 9) Maintenance, and 10) Termination. Discussion We have made specific recommendations to increase conversational AI\u2019s equity as part of healthcare services. These emphasise the importance of a collaborative approach and the involvement of patient groups in navigating the rapid evolution of conversational AI technologies. Further research must assess the impact of recommended activities on chatbots\u2019 fairness and their ability to reduce health inequalities.",
      "cited_by_count": 46,
      "type": "article",
      "source": {
        "name": "PLOS Digital Health",
        "type": "journal",
        "issn": [
          "2767-3170"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1371/journal.pdig.0000492"
      },
      "topics": [
        "Artificial Intelligence in Healthcare and Education",
        "Mobile Health and mHealth Applications",
        "Digital Mental Health Interventions"
      ],
      "referenced_works_count": 34,
      "url": "https://openalex.org/W4396598447"
    },
    {
      "openalex_id": "W4387845099",
      "doi": "10.1016/j.clsr.2023.105897",
      "title": "Fairness and justice through automation in China's smart courts",
      "authors": [
        {
          "name": "Straton Papagianneas",
          "openalex_id": "A5029918987",
          "orcid": "https://orcid.org/0000-0001-7490-0536",
          "institutions": [
            "Leiden University"
          ]
        },
        {
          "name": "Nino Junius",
          "openalex_id": "A5019210397",
          "orcid": "https://orcid.org/0000-0003-3813-2175",
          "institutions": [
            "University of Antwerp"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-21",
      "abstract": "Xi Jinping's judicial reforms have placed the concepts of 'fairness' and 'justice' at the forefront, coinciding with the integration of information technology and AI into all aspects of China's court system through smart court reform. According to official Chinese discourse, smart court reform is supposed to make the justice system 'fairer'. However, research has not yet clearly established how 'fairness' and automation are connected in the Chinese context. This article is interested in how smart court and automation fit into Chinese interpretations of 'fairness'. Therefore, we ask what notions of 'fairness' drive and justify smart court reform? The main argument is that SCR allegedly reinforces elements of procedural fairness, i.e., internal accountability, external visibility, and due process in a way that they are conducive to substantive goals of legitimation, social stability, and user convenience. Most noteworthy, there is a strong emphasis on procedural consistency. This article conducts a systematic qualitative analysis of the foundational texts and discourse about smart courts in China, such as judicial policy documents, development and reform plans, white papers, and regulations. In our analysis we find that smart courts promote procedural and substantive components of 'fairness' that strengthen legal rationality while keeping open channels of control. Our findings help explain the rapid embrace of automation and technology in China's justice administration: they fit perfectly within the ruling party's worldview and perpetuate it in turn.",
      "cited_by_count": 38,
      "type": "article",
      "source": {
        "name": "Computer law & security review",
        "type": "journal",
        "issn": [
          "2212-473X",
          "2212-4748"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://doi.org/10.1016/j.clsr.2023.105897"
      },
      "topics": [
        "Dispute Resolution and Class Actions",
        "Judicial and Constitutional Studies",
        "Law, Economics, and Judicial Systems"
      ],
      "referenced_works_count": 117,
      "url": "https://openalex.org/W4387845099"
    },
    {
      "openalex_id": "W3093876711",
      "doi": "10.1145/3415218",
      "title": "Intersectional AI",
      "authors": [
        {
          "name": "Nora McDonald",
          "openalex_id": "A5030100981",
          "orcid": "https://orcid.org/0000-0003-0216-5573",
          "institutions": [
            "University of Maryland, Baltimore County"
          ]
        },
        {
          "name": "Shimei Pan",
          "openalex_id": "A5048111120",
          "orcid": "https://orcid.org/0000-0002-5989-8543",
          "institutions": [
            "University of Maryland, Baltimore County"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-10-14",
      "abstract": "Recent literature has demonstrated the limited and, in some instances, waning role of ethical training in computing classes in the US. The capacity for artificial intelligence (AI) to be inequitable or harmful is well documented, yet it's an issue that continues to lack apparent urgency or effective mitigation. The question we raise in this paper is how to prepare future generations to recognize and grapple with the ethical concerns of a range of issues plaguing AI, particularly when they are combined with surveillance technologies in ways that have grave implications for social participation and restriction?from risk assessment and bail assignment in criminal justice, to public benefits distribution and access to housing and other critical resources that enable security and success within society. The US is a mecca of information and computer science (IS and CS) learning for Asian students whose experiences as minorities renders them familiar with, and vulnerable to, the societal bias that feeds AI bias. Our goal was to better understand how students who are being educated to design AI systems think about these issues, and in particular, their sensitivity to intersectional considerations that heighten risk for vulnerable groups. In this paper we report on findings from qualitative interviews with 20 graduate students, 11 from an AI class and 9 from a Data Mining class. We find that students are not predisposed to think deeply about the implications of AI design for the privacy and well-being of others unless explicitly encouraged to do so. When they do, their thinking is focused through the lens of personal identity and experience, but their reflections tend to center on bias, an intrinsic feature of design, rather than on fairness, an outcome that requires them to imagine the consequences of AI. While they are, in fact, equipped to think about fairness when prompted by discussion and by design exercises that explicitly invite consideration of intersectionality and structural inequalities, many need help to do this empathy 'work.' Notably, the students who more frequently reflect on intersectional problems related to bias and fairness are also more likely to consider the connection between model attributes and bias, and the interaction with context. Our findings suggest that experience with identity-based vulnerability promotes more analytically complex thinking about AI, lending further support to the argument that identity-related ethics should be integrated into IS and CS curriculums, rather than positioned as a stand-alone course.",
      "cited_by_count": 34,
      "type": "article",
      "source": {
        "name": "Proceedings of the ACM on Human-Computer Interaction",
        "type": "journal",
        "issn": [
          "2573-0142"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Qualitative Comparative Analysis Research",
        "Ethics in Business and Education"
      ],
      "referenced_works_count": 32,
      "url": "https://openalex.org/W3093876711"
    },
    {
      "openalex_id": "W4386103646",
      "doi": "10.33395/jmp.v12i1.12693",
      "title": "Ethical Use of ChatGPT in the Context of Leadership and Strategic Decisions",
      "authors": [
        {
          "name": "Abdul Basir",
          "openalex_id": "A5112530310"
        },
        {
          "name": "Erlinda Dwi Puspitasari",
          "openalex_id": "A5092681916",
          "institutions": [
            "Universitas 17 Agustus 1945 Surabaya"
          ]
        },
        {
          "name": "Cindy Chintya Aristarini",
          "openalex_id": "A5092681917",
          "institutions": [
            "Universitas 17 Agustus 1945 Surabaya"
          ]
        },
        {
          "name": "Pebri Defi Sulastri",
          "openalex_id": "A5092681918",
          "institutions": [
            "Universitas 17 Agustus 1945 Surabaya"
          ]
        },
        {
          "name": "Abu Muna Almaududi Ausat",
          "openalex_id": "A5045004751",
          "orcid": "https://orcid.org/0000-0002-4726-9491",
          "institutions": [
            "Universitas Subang"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-07-15",
      "abstract": "The development of AI has had a significant impact on various aspects of human life, including in the fields of communication and decision-making. One popular example of AI is ChatGPT, a generative language model designed to interact and generate human-like text. While ChatGPT provides great potential in facilitating communication and decision-making, its presence also poses ethical challenges that need to be considered. This research aims to explore the ethical issues that arise in the use of ChatGPT in the context of leadership and decision-making, and formulate an ethical framework that can guide the responsible and beneficial practice of using ChatGPT. The current research type is qualitative. Data collection techniques include listening and recording important information to conduct data analysis through data reduction, data display, and conclusion drawing. The study results show that the ethical use of ChatGPT in the context of leadership and strategic decision-making involves complex and important considerations related to transparency, fairness, privacy, long-term impact considerations, and risk management. While ChatGPT can provide significant benefits, it also poses ethical challenges that need to be addressed.&#x0D;",
      "cited_by_count": 36,
      "type": "article",
      "source": {
        "name": "Jurnal Minfo Polgan",
        "type": "journal",
        "issn": [
          "2089-9424",
          "2797-3298"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://jurnal.polgan.ac.id/index.php/jmp/article/download/12693/1789"
      },
      "topics": [
        "Legal and Policy Analysis in Indonesia",
        "Governance, Compliance, and Sustainability",
        "FinTech, Crowdfunding, Digital Finance"
      ],
      "referenced_works_count": 18,
      "url": "https://openalex.org/W4386103646"
    },
    {
      "openalex_id": "W4386591903",
      "doi": "10.1097/hc9.0000000000000239",
      "title": "Artificial intelligence-based clinical decision support for liver transplant evaluation and considerations about fairness: A qualitative study",
      "authors": [
        {
          "name": "Alexandra T. Strauss",
          "openalex_id": "A5003102672",
          "orcid": "https://orcid.org/0000-0001-6313-7221",
          "institutions": [
            "Johns Hopkins University",
            "Johns Hopkins Medicine"
          ]
        },
        {
          "name": "Carolyn N. Sidoti",
          "openalex_id": "A5063229964",
          "orcid": "https://orcid.org/0000-0002-0491-7137",
          "institutions": [
            "New York University"
          ]
        },
        {
          "name": "Hannah C. Sung",
          "openalex_id": "A5074851876",
          "orcid": "https://orcid.org/0000-0003-4531-2094",
          "institutions": [
            "Johns Hopkins Medicine",
            "Johns Hopkins University"
          ]
        },
        {
          "name": "Vedant Jain",
          "openalex_id": "A5046005164",
          "institutions": [
            "Johns Hopkins University",
            "Johns Hopkins Medicine"
          ]
        },
        {
          "name": "Harold P. Lehmann",
          "openalex_id": "A5010827397",
          "orcid": "https://orcid.org/0000-0002-7698-219X",
          "institutions": [
            "University of Maryland, Baltimore"
          ]
        },
        {
          "name": "Tanjala S. Purnell",
          "openalex_id": "A5085818740",
          "orcid": "https://orcid.org/0000-0002-8661-7911",
          "institutions": [
            "Johns Hopkins University"
          ]
        },
        {
          "name": "John W. Jackson",
          "openalex_id": "A5036099699",
          "orcid": "https://orcid.org/0000-0002-1528-7003",
          "institutions": [
            "Johns Hopkins University"
          ]
        },
        {
          "name": "Daniel Malinsky",
          "openalex_id": "A5041475714",
          "orcid": "https://orcid.org/0000-0001-6110-5664",
          "institutions": [
            "Columbia University"
          ]
        },
        {
          "name": "James P. Hamilton",
          "openalex_id": "A5050832231",
          "orcid": "https://orcid.org/0000-0003-3137-7567",
          "institutions": [
            "Johns Hopkins Medicine",
            "Johns Hopkins University"
          ]
        },
        {
          "name": "Jacqueline Garonzik\u2010Wang",
          "openalex_id": "A5065233891",
          "orcid": "https://orcid.org/0000-0002-2789-7503",
          "institutions": [
            "University of Wisconsin\u2013Madison"
          ]
        },
        {
          "name": "Stephen H. Gray",
          "openalex_id": "A5019359913",
          "orcid": "https://orcid.org/0000-0002-5702-7226",
          "institutions": [
            "University of Maryland, Baltimore"
          ]
        },
        {
          "name": "Macey L. Levan",
          "openalex_id": "A5070148436",
          "orcid": "https://orcid.org/0000-0002-4239-1252",
          "institutions": [
            "New York University"
          ]
        },
        {
          "name": "Jeremiah S. Hinson",
          "openalex_id": "A5004814527",
          "orcid": "https://orcid.org/0000-0002-2024-2360",
          "institutions": [
            "Johns Hopkins University",
            "Johns Hopkins Medicine"
          ]
        },
        {
          "name": "Ay\u015fe P. G\u00fcrses",
          "openalex_id": "A5069939492",
          "orcid": "https://orcid.org/0000-0001-7422-6852",
          "institutions": [
            "Johns Hopkins Medicine",
            "Johns Hopkins University"
          ]
        },
        {
          "name": "Ahmet G\u00fcrakar",
          "openalex_id": "A5014834423",
          "orcid": "https://orcid.org/0000-0002-2221-9148",
          "institutions": [
            "Johns Hopkins Medicine",
            "Johns Hopkins University"
          ]
        },
        {
          "name": "Dorry L. Segev",
          "openalex_id": "A5030533822",
          "orcid": "https://orcid.org/0000-0002-1924-4801",
          "institutions": [
            "New York University"
          ]
        },
        {
          "name": "Scott Levin",
          "openalex_id": "A5103033927",
          "orcid": "https://orcid.org/0000-0002-7143-7635",
          "institutions": [
            "Johns Hopkins Medicine",
            "Beckman Coulter Foundation",
            "Johns Hopkins University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-09-11",
      "abstract": "Background: The use of large-scale data and artificial intelligence (AI) to support complex transplantation decisions is in its infancy. Transplant candidate decision-making, which relies heavily on subjective assessment (ie, high variability), provides a ripe opportunity for AI-based clinical decision support (CDS). However, AI-CDS for transplant applications must consider important concerns regarding fairness (ie, health equity). The objective of this study was to use human-centered design methods to elicit providers\u2019 perceptions of AI-CDS for liver transplant listing decisions. Methods: In this multicenter qualitative study conducted from December 2020 to July 2021, we performed semistructured interviews with 53 multidisciplinary liver transplant providers from 2 transplant centers. We used inductive coding and constant comparison analysis of interview data. Results: Analysis yielded 6 themes important for the design of fair AI-CDS for liver transplant listing decisions: (1) transparency in the creators behind the AI-CDS and their motivations; (2) understanding how the AI-CDS uses data to support recommendations (ie, interpretability); (3) acknowledgment that AI-CDS could mitigate emotions and biases; (4) AI-CDS as a member of the transplant team, not a replacement; (5) identifying patient resource needs; and (6) including the patient\u2019s role in the AI-CDS. Conclusions: Overall, providers interviewed were cautiously optimistic about the potential for AI-CDS to improve clinical and equitable outcomes for patients. These findings can guide multidisciplinary developers in the design and implementation of AI-CDS that deliberately considers health equity.",
      "cited_by_count": 28,
      "type": "article",
      "source": {
        "name": "Hepatology Communications",
        "type": "journal",
        "issn": [
          "2471-254X"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://doi.org/10.1097/hc9.0000000000000239"
      },
      "topics": [
        "Organ Donation and Transplantation",
        "Artificial Intelligence in Healthcare and Education",
        "Palliative Care and End-of-Life Issues"
      ],
      "referenced_works_count": 30,
      "url": "https://openalex.org/W4386591903"
    },
    {
      "openalex_id": "W4220689410",
      "doi": "10.1007/s00146-022-01430-1",
      "title": "An AI ethics \u2018David and Goliath\u2019: value conflicts between large tech companies and their employees",
      "authors": [
        {
          "name": "Mark Ryan",
          "openalex_id": "A5110616325",
          "orcid": "https://orcid.org/0000-0003-4850-0111",
          "institutions": [
            "Wageningen University & Research"
          ]
        },
        {
          "name": "Eleni Christodoulou",
          "openalex_id": "A5042198916",
          "orcid": "https://orcid.org/0000-0002-3865-1904",
          "institutions": [
            "University of Cyprus"
          ]
        },
        {
          "name": "Josephina Antoniou",
          "openalex_id": "A5012075498",
          "orcid": "https://orcid.org/0000-0003-0169-1299",
          "institutions": [
            "University of Central Lancashire Cyprus"
          ]
        },
        {
          "name": "Kalypso Iordanou",
          "openalex_id": "A5043375278",
          "orcid": "https://orcid.org/0000-0001-5930-9393",
          "institutions": [
            "University of Central Lancashire Cyprus"
          ]
        }
      ],
      "publication_year": 2022,
      "publication_date": "2022-03-31",
      "abstract": null,
      "cited_by_count": 24,
      "type": "article",
      "source": {
        "name": "AI & Society",
        "type": "journal",
        "issn": [
          "0951-5666",
          "1435-5655"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://link.springer.com/content/pdf/10.1007/s00146-022-01430-1.pdf"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "Psychology of Moral and Emotional Judgment",
        "Blockchain Technology Applications and Security"
      ],
      "referenced_works_count": 28,
      "url": "https://openalex.org/W4220689410"
    },
    {
      "openalex_id": "W4322489559",
      "doi": "10.1016/j.chb.2023.107721",
      "title": "Utilizing artificial intelligence to support analyzing self-regulated learning: A preliminary mixed-methods evaluation from a human-centered perspective",
      "authors": [
        {
          "name": "Chia-Yu Wang",
          "openalex_id": "A5072278604",
          "orcid": "https://orcid.org/0000-0002-9907-3132",
          "institutions": [
            "National Taiwan University of Science and Technology"
          ]
        },
        {
          "name": "John J. H. Lin",
          "openalex_id": "A5029382210",
          "orcid": "https://orcid.org/0000-0001-7784-9609",
          "institutions": [
            "National Taiwan Normal University"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-02-27",
      "abstract": null,
      "cited_by_count": 28,
      "type": "article",
      "source": {
        "name": "Computers in Human Behavior",
        "type": "journal",
        "issn": [
          "0747-5632",
          "1873-7692"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "Innovative Teaching and Learning Methods",
        "Educational Strategies and Epistemologies",
        "Online Learning and Analytics"
      ],
      "referenced_works_count": 76,
      "url": "https://openalex.org/W4322489559"
    },
    {
      "openalex_id": "W2969625533",
      "doi": "10.1016/j.ijinfomgt.2019.08.002",
      "title": "Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",
      "authors": [
        {
          "name": "Yogesh K. Dwivedi",
          "openalex_id": "A5048622877",
          "orcid": "https://orcid.org/0000-0002-5547-9990",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Laurie Hughes",
          "openalex_id": "A5072512285",
          "orcid": "https://orcid.org/0000-0002-0956-0608",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Elvira Ismagilova",
          "openalex_id": "A5033472055",
          "orcid": "https://orcid.org/0000-0001-9634-194X",
          "institutions": [
            "University of Bradford"
          ]
        },
        {
          "name": "Gert Aarts",
          "openalex_id": "A5027512483",
          "orcid": "https://orcid.org/0000-0002-6038-3782",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Crispin Coombs",
          "openalex_id": "A5018731131",
          "orcid": "https://orcid.org/0000-0002-4203-9291",
          "institutions": [
            "Loughborough University"
          ]
        },
        {
          "name": "Tom Crick",
          "openalex_id": "A5015452463",
          "orcid": "https://orcid.org/0000-0001-5196-9389",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Yanqing Duan",
          "openalex_id": "A5032994640",
          "orcid": "https://orcid.org/0000-0003-4205-7403",
          "institutions": [
            "University of Bedfordshire"
          ]
        },
        {
          "name": "Rohita Dwivedi",
          "openalex_id": "A5070017829",
          "orcid": "https://orcid.org/0000-0003-3801-3635",
          "institutions": [
            "Prin. L. N. Welingkar Institute of Management Development and Research"
          ]
        },
        {
          "name": "John S. Edwards",
          "openalex_id": "A5007695310",
          "orcid": "https://orcid.org/0000-0003-3979-017X",
          "institutions": [
            "Aston University"
          ]
        },
        {
          "name": "Aled Eirug",
          "openalex_id": "A5000411910",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Vassilis Galanos",
          "openalex_id": "A5015685463",
          "orcid": "https://orcid.org/0000-0002-8363-4855",
          "institutions": [
            "University of Edinburgh"
          ]
        },
        {
          "name": "P. Vigneswara Ilavarasan",
          "openalex_id": "A5004125306",
          "orcid": "https://orcid.org/0000-0002-9431-3520",
          "institutions": [
            "Indian Institute of Technology Delhi"
          ]
        },
        {
          "name": "Marijn Janssen",
          "openalex_id": "A5062073470",
          "orcid": "https://orcid.org/0000-0001-6211-8790",
          "institutions": [
            "Delft University of Technology"
          ]
        },
        {
          "name": "Paul Jones",
          "openalex_id": "A5080152304",
          "orcid": "https://orcid.org/0000-0003-0417-9143",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Arpan Kumar Kar",
          "openalex_id": "A5061235109",
          "orcid": "https://orcid.org/0000-0003-4186-4887",
          "institutions": [
            "Indian Institute of Technology Delhi"
          ]
        },
        {
          "name": "Hatice Kizgin",
          "openalex_id": "A5037522059",
          "orcid": "https://orcid.org/0000-0003-0841-8973",
          "institutions": [
            "University of Bradford"
          ]
        },
        {
          "name": "Bianca Kronemann",
          "openalex_id": "A5037724665",
          "orcid": "https://orcid.org/0009-0002-5146-537X",
          "institutions": [
            "Swansea University"
          ]
        },
        {
          "name": "Banita Lal",
          "openalex_id": "A5103045218",
          "orcid": "https://orcid.org/0000-0003-1340-1746",
          "institutions": [
            "University of Bedfordshire"
          ]
        },
        {
          "name": "Biagio Lucini",
          "openalex_id": "A5003777616",
          "orcid": "https://orcid.org/0000-0001-8974-8266",
          "institutions": [
            "Swansea University",
            "Foundry (United Kingdom)"
          ]
        },
        {
          "name": "Rony Medaglia",
          "openalex_id": "A5003475331",
          "orcid": "https://orcid.org/0000-0001-7292-5895",
          "institutions": [
            "Copenhagen Business School"
          ]
        },
        {
          "name": "Kenneth Le Meunier\u2010FitzHugh",
          "openalex_id": "A5059234800",
          "institutions": [
            "University of East Anglia"
          ]
        },
        {
          "name": "Leslie Caroline Le Meunier-FitzHugh",
          "openalex_id": "A5076965699"
        },
        {
          "name": "Santosh K. Misra",
          "openalex_id": "A5018760782",
          "orcid": "https://orcid.org/0000-0002-3313-4895",
          "institutions": [
            "University of East Anglia",
            "Government of Tamil Nadu"
          ]
        },
        {
          "name": "Emmanuel Mogaji",
          "openalex_id": "A5082000265",
          "orcid": "https://orcid.org/0000-0003-0544-4842",
          "institutions": [
            "University of Greenwich"
          ]
        },
        {
          "name": "Sujeet Kumar Sharma",
          "openalex_id": "A5037836435",
          "orcid": "https://orcid.org/0000-0003-3614-9053"
        },
        {
          "name": "Jang Bahadur Singh",
          "openalex_id": "A5040405430",
          "orcid": "https://orcid.org/0000-0001-7017-1989",
          "institutions": [
            "Indian Institute of Management Tiruchirappalli"
          ]
        },
        {
          "name": "Vishnupriya Raghavan",
          "openalex_id": "A5050603102"
        },
        {
          "name": "Ramakrishnan Raman",
          "openalex_id": "A5072261829",
          "orcid": "https://orcid.org/0000-0003-3642-6989",
          "institutions": [
            "Symbiosis International University"
          ]
        },
        {
          "name": "Nripendra P. Rana",
          "openalex_id": "A5034248834",
          "orcid": "https://orcid.org/0000-0003-1105-8729",
          "institutions": [
            "University of Bradford"
          ]
        },
        {
          "name": "Spyridon Samothrakis",
          "openalex_id": "A5033216620",
          "orcid": "https://orcid.org/0000-0003-1902-9690",
          "institutions": [
            "University of Essex"
          ]
        },
        {
          "name": "Jak Spencer",
          "openalex_id": "A5016998336",
          "institutions": [
            "Training Programs in Epidemiology and Public Health Interventions Network"
          ]
        },
        {
          "name": "Kuttimani Tamilmani",
          "openalex_id": "A5008267619",
          "orcid": "https://orcid.org/0000-0002-9615-1465",
          "institutions": [
            "University of Bradford"
          ]
        },
        {
          "name": "Annie Tubadji",
          "openalex_id": "A5070089201",
          "orcid": "https://orcid.org/0000-0002-6134-3520",
          "institutions": [
            "University of the West of England"
          ]
        },
        {
          "name": "Paul Walton",
          "openalex_id": "A5109157215",
          "institutions": [
            "Capgemini (United Kingdom)",
            "Swansea University"
          ]
        },
        {
          "name": "Michael D. Williams",
          "openalex_id": "A5002569790",
          "orcid": "https://orcid.org/0000-0002-3047-0332",
          "institutions": [
            "Swansea University"
          ]
        }
      ],
      "publication_year": 2019,
      "publication_date": "2019-08-27",
      "abstract": null,
      "cited_by_count": 3558,
      "type": "article",
      "source": {
        "name": "International Journal of Information Management",
        "type": "journal",
        "issn": [
          "0268-4012",
          "1873-4707"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://www.sciencedirect.com/science/article/pii/S026840121930917X"
      },
      "topics": [
        "Big Data and Business Intelligence",
        "Economic and Technological Systems Analysis",
        "Digital Transformation in Industry"
      ],
      "referenced_works_count": 338,
      "url": "https://openalex.org/W2969625533"
    },
    {
      "openalex_id": "W4387670758",
      "doi": "10.1080/10447318.2023.2266244",
      "title": "When AI is Perceived to Be Fairer than a Human: Understanding Perceptions of Algorithmic Decisions in a Job Application Context",
      "authors": [
        {
          "name": "Hyesun Choung",
          "openalex_id": "A5002525174",
          "orcid": "https://orcid.org/0000-0001-9464-0399",
          "institutions": [
            "Michigan State University"
          ]
        },
        {
          "name": "John S. Seberger",
          "openalex_id": "A5041367674",
          "orcid": "https://orcid.org/0000-0002-3101-3686",
          "institutions": [
            "Drexel University"
          ]
        },
        {
          "name": "Prabu David",
          "openalex_id": "A5072914616",
          "orcid": "https://orcid.org/0000-0002-5096-1016",
          "institutions": [
            "Rochester Institute of Technology"
          ]
        }
      ],
      "publication_year": 2023,
      "publication_date": "2023-10-15",
      "abstract": "This study investigates people's perceptions of AI decision-making as compared to human decision-making within the job application context. It takes into account both favorable and unfavorable outcomes, employing a 2 \u00d7 2 experimental design (decision-making agent: AI algorithm vs. human; outcome: favorable vs. unfavorable). Upon evaluating a job seeker's suitability for a position, participants viewed algorithmic decisions as fairer, more competent, more trustworthy, and more useful than those made by humans. Interestingly, when a candidate was deemed unsuitable for hiring, people reacted more negatively to the verdict given by a human than to the same judgment offered by AI. Moreover, participants credited algorithmic decisions with greater sensitivity to both quantitative and qualitative qualifications, thus indicating algorithmic appreciation. Our findings shed light on the psychological basis of perceptions surrounding Algorithmic Decision-Making (ADM) and the responses to the decisions rendered by ADM systems.",
      "cited_by_count": 22,
      "type": "article",
      "source": {
        "name": "International Journal of Human-Computer Interaction",
        "type": "journal",
        "issn": [
          "1044-7318",
          "1532-7590"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "hybrid",
        "oa_url": "https://www.tandfonline.com/doi/pdf/10.1080/10447318.2023.2266244?needAccess=true"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "AI in Service Interactions",
        "Artificial Intelligence in Healthcare and Education"
      ],
      "referenced_works_count": 73,
      "url": "https://openalex.org/W4387670758"
    },
    {
      "openalex_id": "W3003574506",
      "doi": "10.1145/3351095.3375784",
      "title": "Algorithmic targeting of social policies",
      "authors": [
        {
          "name": "Alejandro Noriega-Campero",
          "openalex_id": "A5071122166",
          "institutions": [
            "Hesperia Hospital"
          ]
        },
        {
          "name": "Bernardo Garcia-Bulle",
          "openalex_id": "A5046689828",
          "institutions": [
            "Inter-American Development Bank",
            "Moscow Institute of Thermal Technology",
            "Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico",
            "IIT@MIT"
          ]
        },
        {
          "name": "Luis Fernando Cant\u00fa",
          "openalex_id": "A5024417709",
          "institutions": [
            "Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico"
          ]
        },
        {
          "name": "Michiel A. Bakker",
          "openalex_id": "A5035791917",
          "orcid": "https://orcid.org/0000-0003-4474-7109",
          "institutions": [
            "Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico",
            "Inter-American Development Bank",
            "IIT@MIT",
            "Moscow Institute of Thermal Technology"
          ]
        },
        {
          "name": "Luis Tejerina",
          "openalex_id": "A5044445260",
          "institutions": [
            "Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico",
            "Inter-American Development Bank",
            "IIT@MIT"
          ]
        },
        {
          "name": "Alex Pentland",
          "openalex_id": "A5007176508",
          "orcid": "https://orcid.org/0000-0002-8053-9983",
          "institutions": [
            "Inter-American Development Bank",
            "IIT@MIT",
            "Instituto Tecnol\u00f3gico Aut\u00f3nomo de M\u00e9xico",
            "Moscow Institute of Thermal Technology"
          ]
        }
      ],
      "publication_year": 2020,
      "publication_date": "2020-01-27",
      "abstract": "Targeted social policies are the main strategy for poverty alleviation across the developing world. These include targeted cash transfers (CTs), as well as targeted subsidies in health, education, housing, energy, childcare, and others. Due to the scale, diversity, and widespread relevance of targeted social policies like CTs, the algorithmic rules that decide who is eligible to benefit from them---and who is not---are among the most important algorithms operating in the world today. Here we report on a year-long engagement towards improving social targeting systems in a couple of developing countries. We demonstrate that a shift towards the use of AI methods in poverty-based targeting can substantially increase accuracy, extending the coverage of the poor by nearly a million people in two countries, without increasing expenditure. However, we also show that, absent explicit parity constraints, both status quo and AI-based systems induce disparities across population subgroups. Moreover, based on qualitative interviews with local social institutions, we find a lack of consensus on normative standards for prioritization and fairness criteria. Hence, we close by proposing a decision-support platform for distributed governance, which enables a diversity of institutions to customize the use of AI-based insights into their targeting decisions.",
      "cited_by_count": 29,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3351095.3375784"
      },
      "topics": [
        "Ethics and Social Impacts of AI",
        "COVID-19 epidemiological studies"
      ],
      "referenced_works_count": 44,
      "url": "https://openalex.org/W3003574506"
    },
    {
      "openalex_id": "W4399364148",
      "doi": "10.1145/3630106.3659033",
      "title": "A Critical Analysis of the Largest Source for Generative AI Training Data: Common Crawl",
      "authors": [
        {
          "name": "Stefan Baack",
          "openalex_id": "A5014487236",
          "orcid": "https://orcid.org/0000-0002-2464-7699"
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-06-03",
      "abstract": "Common Crawl is the largest freely available collection of web crawl data and one of the most important sources of pre-training data for large language models (LLMs). It is used so frequently and makes up such large proportions of the overall pre-training data in many cases that it arguably has become a foundational building block for LLM development, and subsequently generative AI products built on top of LLMs. Despite its pivotal role, Common Crawl itself is not widely understood, nor is there much reflection evident among LLM builders about the implications of using Common Crawl's data. This paper discusses what Common Crawl's popularity for LLM development means for fairness, accountability, and transparency in generative AI by highlighting the organization's values and practices, as well as how it views its own role within the AI ecosystem. Our qualitative analysis is based on in-depth interviews with Common Crawl staffers and relevant online documents.",
      "cited_by_count": 29,
      "type": "article",
      "source": null,
      "open_access": {
        "is_oa": true,
        "oa_status": "gold",
        "oa_url": "https://dl.acm.org/doi/pdf/10.1145/3630106.3659033"
      },
      "topics": [
        "Topic Modeling",
        "Software Engineering Research",
        "Natural Language Processing Techniques"
      ],
      "referenced_works_count": 29,
      "url": "https://openalex.org/W4399364148"
    },
    {
      "openalex_id": "W4399170782",
      "doi": "10.1016/j.jbusres.2024.114730",
      "title": "Human or AI robot? Who is fairer on the service organizational frontline",
      "authors": [
        {
          "name": "Xiaolong Wu",
          "openalex_id": "A5026828366",
          "orcid": "https://orcid.org/0000-0002-7713-1995",
          "institutions": [
            "Sun Yat-sen University"
          ]
        },
        {
          "name": "Shuhua Li",
          "openalex_id": "A5078360109",
          "orcid": "https://orcid.org/0009-0000-8383-1966",
          "institutions": [
            "Sun Yat-sen University"
          ]
        },
        {
          "name": "Yonglin Guo",
          "openalex_id": "A5080909014",
          "orcid": "https://orcid.org/0009-0005-2148-7449",
          "institutions": [
            "Sun Yat-sen University"
          ]
        },
        {
          "name": "Shujie Fang",
          "openalex_id": "A5035267858",
          "orcid": "https://orcid.org/0000-0002-2438-434X",
          "institutions": [
            "Zhengzhou University"
          ]
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-05-30",
      "abstract": null,
      "cited_by_count": 15,
      "type": "article",
      "source": {
        "name": "Journal of Business Research",
        "type": "journal",
        "issn": [
          "0148-2963",
          "1873-7978"
        ]
      },
      "open_access": {
        "is_oa": false,
        "oa_status": "closed",
        "oa_url": null
      },
      "topics": [
        "AI in Service Interactions",
        "Service and Product Innovation",
        "Consumer Retail Behavior Studies"
      ],
      "referenced_works_count": 104,
      "url": "https://openalex.org/W4399170782"
    },
    {
      "openalex_id": "W4401161409",
      "doi": "10.55813/gaea/jessr/v4/n3/123",
      "title": "Integraci\u00f3n de la inteligencia artificial en la ense\u00f1anza de las Ciencias Sociales en la educaci\u00f3n superior",
      "authors": [
        {
          "name": "Wilson Iv\u00e1n Piedra-Castro",
          "openalex_id": "A5054086744",
          "orcid": "https://orcid.org/0000-0002-9565-9961"
        },
        {
          "name": "Mishell Alejandra Cajamarca-Correa",
          "openalex_id": "A5106109678",
          "institutions": [
            "Universidad Tecnol\u00f3gica Empresarial de Guayaquil"
          ]
        },
        {
          "name": "Erika Silvana Burbano-Bu\u00f1ay",
          "openalex_id": "A5093931757",
          "orcid": "https://orcid.org/0009-0004-9493-2200"
        },
        {
          "name": "Elvin Fray Moreira-Alc\u00edvar",
          "openalex_id": "A5095955893",
          "orcid": "https://orcid.org/0009-0001-2822-0131"
        }
      ],
      "publication_year": 2024,
      "publication_date": "2024-07-31",
      "abstract": "The integration of artificial intelligence (AI) in the teaching of social sciences in higher education has become a crucial issue due to the rapid technological evolution and access to digital tools, which allow for more personalized and effective learning. This study aims to analyze the trends, opportunities and challenges of AI in this context. Methodologically, a comprehensive review of articles from the Scopus database of the year 2024 was conducted, selecting 436 relevant articles that were analyzed qualitatively and quantitatively. The results indicate that 58.3% of the publications are scientific articles, followed by conference proceedings and reviews, underlining the preference for validation and replicability in knowledge dissemination. The discussion reveals that, despite the potential of AI to personalize education and automate administrative tasks, there are significant barriers such as lack of adequate technological infrastructure and resistance to change among educators. Finally, it is concluded that, for effective adoption of AI in higher education, it is essential to invest in infrastructure, train teachers, and develop robust ethical and regulatory frameworks that ensure fairness and privacy of student data.",
      "cited_by_count": 27,
      "type": "article",
      "source": {
        "name": "Journal of Economic and Social Science Research",
        "type": "journal",
        "issn": [
          "2953-6790"
        ]
      },
      "open_access": {
        "is_oa": true,
        "oa_status": "diamond",
        "oa_url": "https://economicsocialresearch.com/index.php/home/article/download/123/409"
      },
      "topics": [
        "Scientific Research and Technology",
        "Knowledge Societies in the 21st Century"
      ],
      "referenced_works_count": 25,
      "url": "https://openalex.org/W4401161409"
    }
  ],
  "count": 30,
  "errors": []
}
