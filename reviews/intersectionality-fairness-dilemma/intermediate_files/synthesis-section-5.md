## Section 4: Normative Pluralism—Which Groups Matter and Why?

Technical approaches to intersectional fairness assume the question "which groups matter?" has a determinate, value-neutral answer discoverable from data or demographic attributes. Yet philosophical analysis reveals this question is fundamentally normative: different ethical frameworks yield systematically different answers about which intersectional groups warrant protection and how to prioritize them. This normative dimension compounds the ontological uncertainty examined in Section 2, showing that contestation about group specification is not merely metaphysical but reflects deeper disagreement about the purposes of fairness auditing itself.

### Distributive Justice Frameworks—Priorities and Thresholds

Classical theories of distributive justice—prioritarianism, sufficientarianism, and egalitarianism—differ not merely in how much inequality to tolerate but in which groups matter and why. These differences have direct implications for intersectional fairness auditing.

Sufficientarianism holds that securing sufficiency has special moral importance distinct from equality or maximization. As Shields (2016) argues, properly specified sufficientarian principles focus on weighted priority below thresholds rather than absolute lexical priority, avoiding standard objections about indifference above thresholds. In algorithmic contexts, this implies fairness interventions should prioritize ensuring all intersectional groups reach minimum thresholds—minimum acceptable true positive rates, minimum access to benefits, minimum protection from harms—rather than equalizing outcomes across groups. Groups below thresholds warrant urgent intervention; inequality above thresholds may be tolerable. Timmer (2021) refines this framework by decomposing sufficientarianism into three claims: a priority claim (benefits in certain ranges matter more), a continuum claim (ranges exist on one continuum), and a deficiency claim (lower ranges warrant stronger priority). This tripartite structure allows for multiple thresholds and variable priority weights, suggesting different intersectional groups may have different sufficiency thresholds depending on context—perhaps higher thresholds for groups facing systemic disadvantage. The framework answers the ontological question "which groups matter?" by focusing analytical attention on groups below relevant thresholds rather than attempting comprehensive coverage of all possible intersections.

Prioritarianism offers a contrasting answer. This view assigns greater moral weight to benefits for worse-off individuals without treating equality as intrinsically valuable (Arneson 2000). Unlike egalitarianism, prioritarianism is "impartial between individuals" but non-linear in valuation: benefiting people matters more the worse off those people are. For intersectional fairness, this implies greater moral urgency to improve outcomes for the worst-off intersectional groups—multiply marginalized groups—even if this increases inequality with better-off groups. As Parfit (2012) clarifies in his defense of the priority view, the framework properly captures the moral importance of benefiting disadvantaged individuals without requiring that we treat equality itself as valuable. His discussion of competing claims directly addresses trade-offs in algorithmic fairness: when improving outcomes for some groups worsens outcomes for others, prioritarianism dictates weighting improvements for the worst-off groups more heavily. Critically, prioritarianism yields a different group prioritization than sufficientarianism: while sufficientarians focus on groups below thresholds (wherever they fall in the distribution), prioritarians care most about the absolute worst-off groups regardless of whether they've crossed sufficiency thresholds.

Relational egalitarianism, most prominently defended by Anderson (1999), offers a fundamentally different normative framework that rejects distributive approaches altogether. Anderson critiques luck egalitarianism and distributive egalitarianism for failing to capture what matters about equality, proposing democratic equality as an alternative: the fundamental aim is creating a community where people relate as equals, free from oppression and domination, rather than equalizing distributions of goods. This framework focuses on social relationships and capabilities for democratic participation. Applied to algorithmic fairness, relational egalitarianism asks not whether algorithms achieve statistical parity across intersectional groups but whether they create hierarchies of social status or enable domination. For intersectional fairness auditing, this reframes the central question: rather than measuring error rates or outcome distributions, audits should examine whether algorithms entrench hierarchies between groups—treating multiply marginalized groups as second-class—or undermine their standing as equal participants in democratic society. Anderson's framework thus yields a categorically different answer to "which groups matter": groups facing potential algorithmic domination, not merely groups with unequal distributions.

These competing frameworks generate incompatible group prioritizations. Fazelpour, Lipton, and Danks (2021) further complicate this picture by arguing that fairness should be assessed based on dynamic trajectories rather than static snapshots: temporal evolution, robustness to perturbations, and whose interests are represented matter more than point-in-time parity. Different normative frameworks evaluate these trajectories differently: prioritarians care most about trajectories for worst-off groups, sufficientarians about whether trajectories keep all groups above thresholds over time, egalitarians about whether trajectories maintain parity, relationalists about whether trajectories preserve equal standing. This shifts fairness auditing's purpose from compliance checking to trajectory assessment—a fundamentally different enterprise.

### Applications to Algorithmic Fairness

Recent work directly bridging normative philosophy and algorithmic fairness reveals how these theoretical differences constrain technical implementations. Hertweck, Heitz, and Loi (2024) argue that current algorithmic fairness approaches erroneously link fairness criteria to ideal theories of distributive justice. Since algorithmic decision-making is inherently imperfect, "we should focus on how *deviations* from ideal distributions are themselves distributed" (p. 600). Fairness in imperfect systems requires evaluating how unfairness in errors is distributed, not just distributions of outcomes. For intersectional fairness, this implies we cannot simply ask whether outcomes are distributed equally, prioritarian, or sufficientarian across groups; we must ask how algorithmic *errors* are distributed—are false negatives concentrated on multiply marginalized groups? This reframes the relationship between normative theories and fairness auditing: different frameworks apply differently to error distributions than to outcome distributions.

Holm (2025) makes a related but distinct argument by applying Broome's theory of fairness as proportional satisfaction of claims to algorithmic contexts. He argues that popular statistical fairness criteria fail to respect the separateness of persons because they can allocate treatments—medical interventions, educational opportunities—to individuals for whom treatment would be harmful in expectation, purely to achieve group-level statistical parity. Drawing on Broome's claims-based fairness theory, Holm contends that "fairness requires allocating for the right reasons—reasons that respect each person's separate interests" (p. 4). This grounds a distinctive normative constraint: fairness audits must ensure algorithms respect each individual's claims, not merely equalize group statistics. For intersectional fairness, Holm's Broomean framework challenges dominant approaches focused solely on group parity across intersections. The separateness of persons demands individual-level decision thresholds, raising the question: can we even meaningfully audit fairness across exponentially many intersectional groups without violating individuals' separate claims? Castro (2024) refines this Broomean approach further by arguing for counterfactual rather than statistical interpretation: determining which groups matter requires counterfactual reasoning about what different groups would be owed in fair possible worlds, not just examining actual outcome distributions.

Green (2022) introduces a different axis of normative disagreement: formal versus substantive algorithmic fairness. Current "formal algorithmic fairness" restricts analysis to isolated decision-making procedures, leading to impossibility results and models that may exacerbate oppression despite appearing fair. Green proposes "substantive algorithmic fairness" drawing on theories of substantive equality from law and philosophy, taking "a more expansive scope of analysis—examining structural context, power relations, and long-term effects" (p. 4). This distinction maps onto different purposes for fairness auditing: compliance-focused audits adopt formal fairness (do statistical criteria hold?), while justice-focused audits require substantive fairness (does the system reduce oppression?). For intersectional fairness, substantive approaches examine how algorithms affect multiply marginalized groups' structural positions, not just their statistical representation. Different normative frameworks map onto this formal-substantive distinction differently: egalitarian and sufficientarian frameworks might be implementable in formal mode (measure parity or threshold achievement), while relational egalitarian frameworks necessarily require substantive mode (assess domination and social standing).

Binns (2024) identifies limits to directly importing distributive justice theories into algorithmic contexts. He argues that Rawls's Difference Principle—inequalities justified only if they benefit the worst-off—won't "make a real difference" in algorithmic fairness practice despite its theoretical appeal. The Principle's lexical priority of basic liberties and its focus on the basic structure of society rather than individual decisions limits applicability to algorithmic systems. For intersectional fairness, this suggests we cannot simply apply the Difference Principle to prioritize worst-off intersectional groups; the framework doesn't fit the problem structure. This motivates considering alternative normative foundations—prioritarianism, sufficientarianism, or domain-specific principles—for determining which groups matter and how to prioritize them in fairness audits.

### Normative Pluralism as Compounding Ontological Uncertainty

The proliferation of competing normative frameworks reveals that ontological uncertainty about which groups to audit is partly irreducible normative disagreement. Sufficientarians identify groups below thresholds as mattering most; prioritarians focus on absolutely worst-off groups; egalitarians treat all groups equally; relationalists prioritize groups facing domination; Broomean approaches examine individual claims rather than group statistics; substantive approaches look to structural position rather than statistical parity. These are not merely different metrics for the same underlying fairness concept but reflect fundamental disagreement about what fairness *is* and what purposes fairness auditing should serve.

This normative pluralism compounds the metaphysical disagreements examined in Section 2. Even if we resolved debates between attribute-based and practice-based social ontology—even if we agreed on whether intersectional categories emerge from social structures or can be derived from demographic attributes—we would still face normative disagreement about which of the resulting groups warrant auditing attention. A prioritarian using practice-based ontology would identify different groups than a sufficientarian using the same ontology, because they are looking for different things: worst-off groups versus groups below thresholds. Conversely, two prioritarians disagreeing about group ontology (one attribute-based, one practice-based) would generate different group lists because they disagree about what constitutes group membership, even though they share normative commitments.

The interaction between normative and ontological uncertainty creates a dilemma within the dilemma. Attempting to resolve ontological questions about which intersections exist requires confronting normative questions about which normative framework should guide the inquiry—yet these normative frameworks themselves are contested. Robeyns (2022) argues for normative pluralism explicitly: no single principle suffices for distributive justice; we need limitarianism (upper bounds on wealth), sufficientarianism (minimum thresholds), and egalitarianism (equal opportunities) working together. If she is right, then determining which intersectional groups matter requires combining multiple frameworks—but these frameworks may yield conflicting group prioritizations in specific cases, leaving the ontological question unresolved.

Recent work on impossibility results reveals another dimension of this normative entanglement. Sahlgren (2024) draws on philosophical literature on feasibility to argue that impossibility results reflect current structural conditions that could be changed through collective efforts, not permanent logical necessities. If fairness impossibility is diachronically rather than synchronically feasible, then fairness audits should aim not at optimizing current algorithms but at identifying structural changes needed to make fairness feasible across intersectional groups. Yet different normative frameworks prioritize different structural changes: prioritarians care about reducing absolute disadvantage of worst-off groups, egalitarians about reducing relative inequality, relationalists about eliminating domination. The purpose of auditing itself depends on which normative framework guides the analysis.

This normative dimension of the group specification problem remains largely unaddressed in both technical and philosophical fairness literature. Technical work treats metric choice as a technical decision about which mathematical criterion best captures fairness, occasionally acknowledging that different metrics embody different fairness intuitions. But the recognition that these "intuitions" reflect contested normative frameworks—prioritarian, sufficientarian, egalitarian, relational—with systematically different implications for which groups matter has not been integrated into technical approaches. Philosophical work, conversely, debates the merits of these frameworks in abstraction from algorithmic implementation constraints, rarely examining how normative choices interact with statistical feasibility and ontological uncertainty to determine the scope of fairness auditing.

The literature on normative frameworks thus reveals a fundamental challenge: determining which intersectional groups warrant auditing is not a value-neutral technical or metaphysical question but requires contestable normative commitments about the purposes of fairness and the structure of justice. These normative disagreements are not resolvable through better conceptual analysis or more sophisticated algorithms; they reflect enduring philosophical controversy. Section 5 examines how this normative pluralism interacts with the statistical and ontological challenges identified in previous sections to create a genuine dilemma for intersectional fairness auditing.
