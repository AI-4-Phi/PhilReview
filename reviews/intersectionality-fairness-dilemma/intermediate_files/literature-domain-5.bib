@comment{
====================================================================
DOMAIN: Normative Frameworks for Fairness
SEARCH_DATE: 2026-01-10
PAPERS_FOUND: 18 total (High: 8, Medium: 7, Low: 3)
SEARCH_SOURCES: SEP, PhilPapers, Semantic Scholar, OpenAlex
====================================================================

DOMAIN_OVERVIEW:
This domain examines the normative foundations that should guide fairness in
algorithmic decision-making, particularly in the context of intersectional
fairness auditing. The debate centers on how classical theories of distributive
justice—prioritarianism (giving extra weight to the worse off), sufficientarianism
(ensuring everyone has enough), and egalitarianism (treating equality as a core value)—
apply to algorithmic contexts. Foundational work by Shields, Arneson, and others
establishes these normative frameworks, while recent work by Hertweck, Fazelpour,
Holm, and others bridges them to algorithmic fairness. A central tension emerges:
these frameworks differ not just in *how much* inequality to tolerate, but in
*which groups matter* and *why*—a debate particularly salient for intersectional
fairness where ontological uncertainty about group membership is unavoidable.

The literature reveals two key shifts. First, recognition that algorithmic fairness
cannot be reduced to statistical parity criteria without normative grounding (Green
2022, Fazelpour 2021, Hertweck 2024). Second, growing attention to how different
normative frameworks yield different answers about which groups deserve protection
and prioritization (Holm 2025, Binns 2024). Recent work emphasizes that fairness
auditing serves distinct purposes—legal compliance versus substantive justice—
which require different normative foundations.

RELEVANCE_TO_PROJECT:
This domain directly addresses the core claim that ontological uncertainty (which
groups matter) is partly normative. Different ethical frameworks—prioritarian,
sufficientarian, egalitarian—yield different answers about group prioritization.
For example, prioritarianism focuses on the worst-off intersectional groups,
sufficientarianism on ensuring all groups reach minimum thresholds, and egalitarianism
on parity across groups. The purpose of fairness auditing (compliance vs. substantive
justice) also depends on which normative framework one adopts. This domain provides
the philosophical vocabulary for articulating why disagreement about fairness metrics
is not merely technical but reflects deeper normative commitments.

NOTABLE_GAPS:
Few papers explicitly connect sufficientarianism or prioritarianism to intersectional
fairness (most focus on single-axis fairness). Limited discussion of how these
frameworks handle ontological uncertainty about which intersections to audit. Sparse
treatment of fairness auditing's dual purposes (compliance vs. substantive justice)
and how normative frameworks differentially serve these goals.

SYNTHESIS_GUIDANCE:
When synthesizing, emphasize how normative frameworks generate different answers to
"which groups matter" and "how much." Show how this connects to the impossibility
results in algorithmic fairness—disagreement isn't just technical incompatibility
but reflects competing normative commitments (prioritarian vs. sufficientarian vs.
egalitarian). Use Holm's work on Broome's fairness theory and Hertweck's critique
of simple distributive justice to argue that fairness auditing requires explicit
normative choices, not merely statistical optimization.

KEY_POSITIONS:
- Prioritarianism (8 papers): Weight benefits to worse-off groups more heavily
- Sufficientarianism (7 papers): Ensure all groups reach sufficiency thresholds
- Egalitarianism (6 papers): Equality as intrinsic value, parity across groups
- Pluralist approaches (3 papers): Combine multiple normative frameworks
====================================================================
}

@article{shields2016prospects,
  author = {Shields, Liam},
  title = {The Prospects for Sufficientarianism},
  journal = {Philosophy Compass},
  year = {2016},
  volume = {11},
  number = {2},
  pages = {101--111},
  doi = {10.1111/phc3.12300},
  note = {
  CORE ARGUMENT: Sufficientarianism holds that securing enough of some goods
  for people has special moral importance, distinct from equality or maximization.
  The paper defends sufficientarianism against major objections (indifference above
  threshold, discontinuity) by showing these objections mischaracterize the view.
  A properly specified sufficientarian principle avoids these problems by focusing
  on weighted priority below thresholds rather than absolute lexical priority.

  RELEVANCE: Sufficientarianism offers a normative framework for fairness auditing
  that differs fundamentally from egalitarianism. In algorithmic contexts, it implies
  that fairness interventions should prioritize ensuring all groups reach minimum
  thresholds (e.g., minimum true positive rates) rather than equalizing outcomes
  across groups. This has direct implications for which groups matter in intersectional
  fairness: groups below thresholds warrant urgent intervention, while inequality
  above thresholds may be tolerable. This framework answers the ontological question
  differently than egalitarianism.

  POSITION: Sufficientarian framework for distributive justice, emphasizing thresholds
  over equality.
  },
  keywords = {sufficientarianism, distributive-justice, normative-framework, High}
}

@article{timmer2021justice,
  author = {Timmer, Dick},
  title = {Justice, Thresholds, and the Three Claims of Sufficientarianism},
  journal = {Journal of Political Philosophy},
  year = {2021},
  volume = {29},
  number = {4},
  pages = {395--416},
  doi = {10.1111/jopp.12258},
  note = {
  CORE ARGUMENT: Sufficientarianism combines three distinct claims: a priority claim
  (benefits in certain ranges matter more), a continuum claim (ranges exist on one
  continuum), and a deficiency claim (lower ranges warrant stronger priority). This
  tripartite structure explains why sufficientarianism is neither simple threshold
  lexicalism nor weighted prioritarianism, but a distinctive view that can handle
  multiple thresholds and variable priority weights below sufficiency.

  RELEVANCE: Timmer's decomposition of sufficientarianism clarifies how this framework
  applies to algorithmic fairness. Different intersectional groups may have different
  sufficiency thresholds depending on context (e.g., higher thresholds for groups
  facing systemic disadvantage). The priority, continuum, and deficiency claims
  together determine which groups matter most in fairness audits: groups furthest
  below relevant thresholds receive strongest priority. This provides normative
  guidance for prioritizing fairness interventions across intersectional groups.

  POSITION: Refined sufficientarian account with multiple thresholds and variable
  priority weights.
  },
  keywords = {sufficientarianism, thresholds, distributive-justice, High}
}

@article{arneson2000luck,
  author = {Arneson, Richard J.},
  title = {Luck Egalitarianism and Prioritarianism},
  journal = {Ethics},
  year = {2000},
  volume = {110},
  number = {2},
  pages = {339--349},
  doi = {10.1086/233272},
  note = {
  CORE ARGUMENT: Prioritarianism assigns greater moral weight to benefits to
  worse-off individuals, but unlike egalitarianism, does not treat equality as
  intrinsically valuable. The view holds that benefiting people matters more the
  worse off those people are, but remains impartial between individuals. Arneson
  examines how prioritarianism relates to luck egalitarianism (which distinguishes
  choice-based from circumstance-based inequality) and argues the two can be combined.

  RELEVANCE: Prioritarianism provides an alternative normative foundation for
  algorithmic fairness that focuses on absolute advantage levels rather than
  relative equality. In intersectional fairness, this implies greater moral urgency
  to improve outcomes for the worst-off intersectional groups (e.g., multiply
  marginalized groups), even if this increases inequality with better-off groups.
  This differs from egalitarian frameworks that prioritize parity. The framework
  helps adjudicate conflicts between different fairness criteria by weighting
  benefits to disadvantaged groups more heavily.

  POSITION: Prioritarian approach to distributive justice, combining with luck
  egalitarianism.
  },
  keywords = {prioritarianism, distributive-justice, luck-egalitarianism, High}
}

@incollection{parfit2012another,
  author = {Parfit, Derek},
  title = {Another Defence of the Priority View},
  booktitle = {Egalitarianism: New Essays on the Nature and Value of Equality},
  editor = {Holtug, Nils and Lippert-Rasmussen, Kasper},
  publisher = {Oxford University Press},
  year = {2012},
  pages = {399--440},
  doi = {10.1093/acprof:oso/9780199281701.003.0018},
  note = {
  CORE ARGUMENT: Parfit defends prioritarianism against several objections, arguing
  that it properly captures the moral importance of benefiting worse-off individuals
  without treating equality as intrinsically valuable. He addresses objections from
  Otsuka and Voorhoeve about competing claims, argues prioritarians can explain why
  worse-off people should sometimes receive priority in lotteries, and clarifies how
  the view handles uncertainty and expectation.

  RELEVANCE: Parfit's refined prioritarianism clarifies how to handle trade-offs in
  algorithmic fairness when improving outcomes for some groups worsens outcomes for
  others. His discussion of competing claims is directly relevant to intersectional
  fairness: when auditing algorithms, prioritarianism implies giving more weight to
  improvements for the worst-off intersectional groups. His treatment of uncertainty
  also applies to contexts where we're uncertain which groups are actually worst-off
  or which interventions will help them most.

  POSITION: Priority view (prioritarianism) as distinct from egalitarianism.
  },
  keywords = {prioritarianism, competing-claims, distributive-justice, High}
}

@article{anderson1999equality,
  author = {Anderson, Elizabeth},
  title = {What Is the Point of Equality?},
  journal = {Ethics},
  year = {1999},
  volume = {109},
  number = {2},
  pages = {287--337},
  doi = {10.1086/233897},
  note = {
  CORE ARGUMENT: Anderson critiques luck egalitarianism and distributive egalitarianism,
  arguing they fail to capture what matters about equality. She proposes democratic
  equality (relational egalitarianism) as an alternative: the fundamental aim is to
  create a community where people relate as equals, free from oppression and
  domination, rather than equalizing distributions of goods. Democratic equality
  focuses on social relationships and capabilities for democratic participation.

  RELEVANCE: Anderson's relational egalitarianism offers a fundamentally different
  normative framework for algorithmic fairness than distributive approaches. Rather
  than focusing on equalizing error rates or outcomes, it asks whether algorithmic
  systems create hierarchies of social status or enable domination. For intersectional
  fairness, this implies fairness audits should examine whether algorithms entrench
  hierarchies between groups (e.g., treating multiply marginalized groups as
  second-class) rather than merely measuring statistical parity. The framework
  reframes fairness as preventing algorithmic domination.

  POSITION: Relational egalitarianism (democratic equality) as critique of
  distributive approaches.
  },
  keywords = {relational-egalitarianism, democratic-equality, critique, High}
}

@article{fazelpour2021algorithmic,
  author = {Fazelpour, Sina and Lipton, Zachary C. and Danks, David},
  title = {Algorithmic Fairness and the Situated Dynamics of Justice},
  journal = {Canadian Journal of Philosophy},
  year = {2021},
  volume = {52},
  number = {1},
  pages = {44--60},
  doi = {10.1017/can.2021.24},
  note = {
  CORE ARGUMENT: Prevailing algorithmic fairness research focuses on identifying
  "ideally fair" target states in abstraction from deployment context. This is
  misguided; we should evaluate dynamic trajectories of algorithmic systems rather
  than static snapshots. Fairness should be assessed based on (i) temporal dynamics
  (how systems evolve), (ii) robustness (resilience to perturbations), and (iii)
  representation (whose interests are considered). Static fairness metrics miss how
  systems create feedback loops that amplify or mitigate injustice over time.

  RELEVANCE: Fazelpour et al. fundamentally challenge how fairness auditing is
  conceived. For intersectional fairness, this implies audits cannot simply measure
  whether an algorithm satisfies parity criteria at deployment but must examine
  dynamic effects on multiply marginalized groups over time. Different normative
  frameworks (prioritarian, sufficientarian, egalitarian) will yield different
  evaluations of these trajectories: prioritarians care most about trajectories
  for worst-off groups, sufficientarians about whether trajectories keep all groups
  above thresholds. The purpose of auditing shifts from compliance to trajectory
  assessment.

  POSITION: Process-oriented, dynamic approach to algorithmic fairness; critique of
  target-state frameworks.
  },
  keywords = {algorithmic-fairness, dynamic-justice, normative-framework, High}
}

@inproceedings{hertweck2024distributive,
  author = {Hertweck, Corinna and Heitz, Christoph and Loi, Michele},
  title = {What's Distributive Justice Got to Do with It? Rethinking Algorithmic Fairness from the Perspective of Approximate Justice},
  booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  year = {2024},
  pages = {597--608},
  doi = {10.1609/aies.v7i1.31661},
  note = {
  CORE ARGUMENT: Current algorithmic fairness approaches erroneously link fairness
  criteria to ideal theories of distributive justice (egalitarianism, prioritarianism,
  sufficientarianism). But algorithmic decision-making is inherently imperfect, so
  we should focus on how *deviations* from ideal distributions are themselves
  distributed. Fairness in imperfect systems requires evaluating unfairness in
  errors, not just distributions of outcomes. This reframes the relationship between
  distributive justice and algorithmic fairness.

  RELEVANCE: Hertweck et al. clarify a key confusion in applying normative frameworks
  to algorithmic fairness. For intersectional fairness, this implies we cannot simply
  ask whether outcomes are distributed equally/prioritarian/sufficientarian across
  groups. Instead, we must ask how algorithmic *errors* are distributed—are false
  negatives concentrated on multiply marginalized groups? This shifts fairness
  auditing from measuring outcome distributions to measuring error distributions,
  and connects to different normative frameworks differently than assumed. Critical
  for understanding the purpose of fairness audits.

  POSITION: Approximate justice framework for algorithmic fairness; critique of
  direct distributive justice applications.
  },
  keywords = {algorithmic-fairness, approximate-justice, distributive-justice, High}
}

@article{holm2025separateness,
  author = {Holm, Sune},
  title = {Algorithmic Fairness, Decision Thresholds, and the Separateness of Persons},
  journal = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
  year = {2025},
  doi = {10.1145/3715275.3732113},
  note = {
  CORE ARGUMENT: Popular statistical fairness criteria fail to respect the separateness
  of persons because they can allocate treatments (e.g., medical interventions) to
  individuals for whom treatment would be harmful in expectation. Fairness requires
  allocating for the right reasons—reasons that respect each person's separate
  interests. Drawing on Broome's theory of fairness as proportional satisfaction of
  claims, Holm argues algorithmic fairness requires individual-level decision
  thresholds, not just group-level statistical parity.

  RELEVANCE: Holm's application of Broome's fairness theory to algorithmic contexts
  provides a crucial bridge between philosophical and technical fairness literature.
  For intersectional fairness, this implies that statistical parity across intersectional
  groups is insufficient if it violates individual claims. The separateness of persons
  grounds a distinctive normative constraint: fairness audits must ensure algorithms
  respect each individual's claims, not just equalize group statistics. This challenges
  dominant approaches to intersectional fairness that focus solely on group parity.

  POSITION: Individual fairness grounded in Broomean claims-based fairness; critique
  of statistical parity.
  },
  keywords = {algorithmic-fairness, separateness-persons, broome-fairness, High}
}

@book{shields2016enough,
  author = {Shields, Liam},
  title = {Just Enough: Sufficiency as a Demand of Justice},
  publisher = {Edinburgh University Press},
  year = {2016},
  doi = {10.3366/edinburgh/9780748691869.001.0001},
  note = {
  CORE ARGUMENT: This book-length treatment defends sufficientarianism as a complete
  theory of distributive justice. Shields argues that justice requires everyone to
  have enough of certain goods (basic needs, capabilities, opportunities), and that
  achieving sufficiency has a distinctive kind of moral urgency. He defends the view
  against objections about threshold arbitrariness, indifference above the threshold,
  and compatibility with other values like equality and desert.

  RELEVANCE: Shields provides the most comprehensive philosophical foundation for
  sufficientarian approaches to fairness. For algorithmic fairness auditing, this
  supports a framework where the primary purpose is ensuring all groups—including
  all intersectional groups—reach minimum acceptable outcomes (sufficiency thresholds),
  rather than equalizing outcomes. This answers the ontological question (which groups
  matter) by focusing on groups below thresholds. It also clarifies fairness auditing's
  purpose: identifying groups failing to reach sufficiency, not necessarily achieving
  parity.

  POSITION: Comprehensive defense of sufficientarianism as theory of distributive
  justice.
  },
  keywords = {sufficientarianism, distributive-justice, book, Medium}
}

@article{green2022escaping,
  author = {Green, Ben},
  title = {Escaping the Impossibility of Fairness: From Formal to Substantive Algorithmic Fairness},
  journal = {Philosophy \& Technology},
  year = {2022},
  volume = {35},
  number = {90},
  doi = {10.1007/s13347-022-00584-6},
  note = {
  CORE ARGUMENT: Current "formal algorithmic fairness" restricts analysis to isolated
  decision-making procedures, leading to impossibility results and models that
  exacerbate oppression despite appearing fair. Green proposes "substantive algorithmic
  fairness" drawing on theories of substantive equality from law and philosophy.
  This approach takes a more expansive scope of analysis—examining structural context,
  power relations, and long-term effects—enabling escape from impossibility results
  and providing rigorous guidance for alleviating injustice.

  RELEVANCE: Green's distinction between formal and substantive fairness is crucial
  for understanding fairness auditing's purpose. Compliance-focused audits adopt
  formal fairness (do statistical criteria hold?), while justice-focused audits
  require substantive fairness (does the system reduce oppression?). For intersectional
  fairness, substantive approaches examine how algorithms affect multiply marginalized
  groups' structural positions, not just their statistical representation. Different
  normative frameworks map onto formal vs. substantive approaches differently, with
  implications for which groups matter.

  POSITION: Substantive algorithmic fairness grounded in structural analysis; critique
  of formal approaches.
  },
  keywords = {algorithmic-fairness, substantive-equality, formal-fairness, Medium}
}

@article{binns2024difference,
  author = {Binns, Reuben},
  title = {If the Difference Principle Won't Make a Real Difference in Algorithmic Fairness, What Will?},
  journal = {Philosophy \& Technology},
  year = {2024},
  volume = {37},
  doi = {10.1007/s13347-024-00805-0},
  note = {
  CORE ARGUMENT: Rawls's Difference Principle (inequalities justified only if they
  benefit the worst-off) has been proposed as a foundation for algorithmic fairness,
  but Binns argues it won't make a real difference in practice. The Principle's
  lexical priority of basic liberties and its focus on basic structure of society
  rather than individual decisions limits its applicability to algorithmic systems.
  Alternative normative frameworks may be more practically actionable for algorithmic
  fairness.

  RELEVANCE: Binns's critique of applying Rawlsian egalitarianism to algorithms
  highlights limits of directly importing distributive justice theories to algorithmic
  contexts. For intersectional fairness, this suggests we cannot simply apply the
  Difference Principle to prioritize worst-off intersectional groups; the framework
  doesn't fit algorithmic decision-making well. This motivates considering alternative
  normative foundations (prioritarianism, sufficientarianism, or domain-specific
  principles) for determining which groups matter and how to prioritize them in
  fairness audits.

  POSITION: Critique of Rawlsian Difference Principle for algorithmic fairness;
  skepticism about direct application.
  },
  keywords = {algorithmic-fairness, rawls, difference-principle, Medium}
}

@article{knight2021enough,
  author = {Knight, Carl},
  title = {Enough Is Too Much: The Excessiveness Objection to Sufficientarianism},
  journal = {Economics and Philosophy},
  year = {2021},
  volume = {38},
  number = {2},
  pages = {275--299},
  doi = {10.1017/S0266267121000171},
  note = {
  CORE ARGUMENT: Standard sufficientarianism gives lexical priority to providing
  sufficiency, but this is excessive in four ways: (1) magnitude—huge benefits above
  threshold can outweigh small benefits below; (2) numbers—small benefits to many
  below threshold can outweigh large benefits to few above; (3) responsibility—people
  below threshold through their own choices may not deserve priority; (4) above-threshold
  distribution—sufficientarianism wrongly ignores inequality above threshold. Knight
  argues sufficientarians should accept weighted rather than lexical priority.

  RELEVANCE: Knight's excessiveness objection clarifies limits of sufficientarian
  approaches to algorithmic fairness. For intersectional fairness auditing, lexical
  sufficientarianism would require prioritizing *any* improvement for groups below
  thresholds over *any* improvement for groups above, which Knight shows is excessive.
  This suggests fairness audits should adopt weighted sufficientarianism: strong but
  not absolute priority for groups below thresholds. This affects both which groups
  matter most and the purpose of auditing (ensuring thresholds are met, but not
  exclusively).

  POSITION: Critique of lexical sufficientarianism; defense of weighted
  sufficientarianism.
  },
  keywords = {sufficientarianism, excessiveness-objection, weighted-priority, Medium}
}

@article{huseby2020sufficientarianism,
  author = {Huseby, Robert},
  title = {Sufficientarianism},
  journal = {Oxford Research Encyclopedia of Politics},
  year = {2020},
  doi = {10.1093/acrefore/9780190228637.013.1382},
  note = {
  CORE ARGUMENT: This encyclopedia entry provides a comprehensive overview of
  sufficientarianism as a distributive justice principle. Huseby surveys the positive
  thesis (importance of reaching sufficiency) and negative thesis (above sufficiency,
  distribution doesn't matter), debates about currency (welfare, resources, capabilities),
  threshold specification, and scope. He reviews major objections (threshold
  arbitrariness, indifference above threshold) and sufficientarian responses.

  RELEVANCE: Huseby's overview clarifies the landscape of sufficientarian approaches,
  showing there is no single sufficientarian view but a family of views. For
  algorithmic fairness, this implies multiple sufficientarian frameworks are possible:
  different thresholds (minimum acceptable outcomes vs. minimally decent lives),
  different currencies (capabilities vs. outcomes), different scopes (temporal,
  spatial). This multiplicity means the ontological question—which groups matter—
  receives different answers depending on which sufficientarian specification one
  adopts.

  POSITION: Survey of sufficientarian theories and debates.
  },
  keywords = {sufficientarianism, distributive-justice, survey, Medium}
}

@article{robeyns2022limitarianism,
  author = {Robeyns, Ingrid},
  title = {Why Limitarianism?},
  journal = {Journal of Political Philosophy},
  year = {2022},
  volume = {30},
  number = {2},
  pages = {249--270},
  doi = {10.1111/jopp.12275},
  note = {
  CORE ARGUMENT: Limitarianism holds that there should be an upper limit on how
  much income and wealth individuals can have. Robeyns argues limitarianism addresses
  problems neither egalitarianism nor sufficientarianism adequately handle: excessive
  wealth concentration undermines democracy, exceeds what anyone deserves, and could
  be better used to meet others' urgent needs. She proposes limitarianism as part of
  a pluralist account combining sufficientarianism, opportunity egalitarianism, and
  limitarianism.

  RELEVANCE: While limitarianism focuses on upper bounds rather than fairness
  criteria directly, Robeyns's pluralist approach is relevant for algorithmic fairness.
  Her argument that we need *multiple* normative principles (not just one) for
  distributive justice supports the claim that algorithmic fairness cannot be
  captured by a single metric or normative framework. For intersectional fairness,
  pluralism suggests we may need different principles for different contexts: perhaps
  sufficientarianism for basic outcomes, egalitarianism for opportunities, and
  additional principles for extreme advantages.

  POSITION: Pluralist account combining limitarianism, sufficientarianism, and
  egalitarianism.
  },
  keywords = {limitarianism, pluralism, distributive-justice, Medium}
}

@article{adler2023prioritarianism,
  author = {Adler, Matthew D. and Norheim, Ole F.},
  title = {Prioritarianism in Practice},
  journal = {Cambridge University Press},
  year = {2023},
  doi = {10.1017/9781108691734},
  note = {
  CORE ARGUMENT: This edited volume examines how prioritarianism—the view that gives
  extra weight to well-being improvements for worse-off individuals—applies to
  practical policy contexts including health, climate change, and development. The
  contributors show how prioritarian principles differ from utilitarianism,
  egalitarianism, and cost-benefit analysis in policy evaluation, and how to
  operationalize prioritarian weights in practice.

  RELEVANCE: Adler and Norheim's focus on practical implementation of prioritarianism
  is directly relevant to algorithmic fairness auditing. For intersectional fairness,
  prioritarianism implies assigning greater weight to improvements for multiply
  marginalized groups (the worst-off intersectional groups). The volume's discussion
  of how to determine prioritarian weights in practice addresses a key challenge:
  how much more should we weight benefits to worse-off groups? This connects to
  fairness auditing's purpose—if we adopt prioritarianism, audits should measure
  weighted benefits, not just raw improvements.

  POSITION: Applied prioritarianism across policy domains.
  },
  keywords = {prioritarianism, applied-ethics, policy, Medium}
}

@article{sahlgren2024impossible,
  author = {Sahlgren, Otto},
  title = {What's Impossible about Algorithmic Fairness?},
  journal = {Philosophy \& Technology},
  year = {2024},
  volume = {37},
  doi = {10.1007/s13347-024-00814-z},
  note = {
  CORE ARGUMENT: Impossibility results show that predictive models cannot simultaneously
  satisfy multiple plausible fairness criteria except under extraordinary circumstances.
  Sahlgren draws on philosophical literature on feasibility to argue that fairness
  can be made diachronically feasible through collective efforts to eliminate
  inequalities feeding into local decision-making. The impossibility is not permanent
  but reflects current structural conditions that could be changed.

  RELEVANCE: Sahlgren's feasibility analysis connects to debates about fairness
  auditing's purpose. If impossibility results reflect structural conditions rather
  than logical necessities, then fairness audits should aim not just at optimizing
  current algorithms but at identifying structural changes needed to make fairness
  feasible. For intersectional fairness, this implies audits should examine which
  structural inequalities make it impossible to satisfy fairness criteria across
  intersectional groups, rather than simply accepting impossibility. Different
  normative frameworks will prioritize different structural changes.

  POSITION: Feasibility-based analysis of algorithmic fairness impossibility results.
  },
  keywords = {algorithmic-fairness, impossibility-results, feasibility, Low}
}

@article{castro2024broomean,
  author = {Castro, Clinton},
  title = {Broomean(ish) Algorithmic Fairness?},
  journal = {Journal of Applied Philosophy},
  year = {2024},
  doi = {10.1111/japp.12778},
  note = {
  CORE ARGUMENT: Castro applies John Broome's theory of fairness (fairness as
  proportional satisfaction of claims) to algorithmic decision-making, but modifies
  it to think in counterfactual rather than statistical terms. He critiques Holm's
  direct application of Broome, arguing that Holm's statistical interpretation fails
  to capture Broome's core insights. A proper Broomean approach to algorithmic fairness
  requires examining what individuals would be owed in different possible worlds,
  not just statistical distributions.

  RELEVANCE: Castro's counterfactual interpretation of Broomean fairness offers a
  different normative foundation for algorithmic fairness than standard approaches.
  For intersectional fairness, this implies that determining which groups matter
  requires counterfactual reasoning: which groups have stronger claims based on what
  they would be owed in fair possible worlds? This is distinct from both egalitarian
  (equal statistical treatment) and prioritarian (weight by disadvantage) approaches,
  and suggests fairness audits should examine counterfactual claims rather than just
  actual outcomes.

  POSITION: Counterfactual Broomean fairness for algorithmic contexts.
  },
  keywords = {algorithmic-fairness, broome-fairness, counterfactual, Low}
}

@article{grant2023equalized,
  author = {Grant, David Gray},
  title = {Equalized Odds Is a Requirement of Algorithmic Fairness},
  journal = {Synthese},
  year = {2023},
  volume = {201},
  pages = {1--25},
  doi = {10.1007/s11229-023-04054-0},
  note = {
  CORE ARGUMENT: Grant defends equalized odds (equal true positive and false positive
  rates across groups) as a necessary requirement of procedural fairness in algorithmic
  classification. He introduces a refined version of equalized odds that avoids
  standard objections, arguing it's required by procedural fairness because it ensures
  classification decisions treat similarly situated individuals the same way regardless
  of group membership. This grounds equalized odds in procedural justice rather than
  distributive justice.

  RELEVANCE: Grant's defense of equalized odds shows how one specific fairness
  criterion connects to a particular normative framework (procedural fairness). For
  intersectional fairness, this raises the question: does procedural fairness require
  equalized odds across *all* intersectional groups, or only salient protected
  groups? The answer depends on whether we adopt Grant's procedural framework or
  alternative distributive frameworks (egalitarian, prioritarian, sufficientarian).
  This illustrates how different normative frameworks yield different answers about
  which groups matter.

  POSITION: Procedural fairness foundation for equalized odds criterion.
  },
  keywords = {algorithmic-fairness, equalized-odds, procedural-fairness, Low}
}