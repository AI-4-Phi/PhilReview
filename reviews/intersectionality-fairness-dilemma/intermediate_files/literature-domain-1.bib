@comment{
====================================================================
DOMAIN: Algorithmic Fairness and Intersectionality (ML/CS Literature)
SEARCH_DATE: 2026-01-10
PAPERS_FOUND: 20 total (High: 10, Medium: 7, Low: 3)
SEARCH_SOURCES: Semantic Scholar, OpenAlex
====================================================================

DOMAIN_OVERVIEW:

The technical ML/CS literature on intersectional algorithmic fairness emerged in the late 2010s, primarily addressing the statistical challenge of ensuring equitable predictions across multiple overlapping demographic groups. The field has developed around several key technical approaches: (1) multicalibration methods that ensure calibrated predictions across rich collections of subgroups (Hébert-Johnson et al. 2018), (2) differential fairness frameworks inspired by differential privacy (Foulds et al. 2020), (3) subgroup fairness methods that prevent worst-case disparities (Kearns et al. 2018), and (4) recent work on fairness gerrymandering that highlights how strategic group selection can manipulate fairness metrics (Kong 2022, Tian et al. 2024).

A central challenge identified across this literature is the statistical difficulty of measuring fairness for small intersectional groups. Papers explicitly address sparse data problems through various technical solutions: importance weighting, hierarchical models, tensor factorization, and hypothesis testing approaches (Ferrara et al. 2025). The multicalibration literature offers the most developed technical framework for handling exponentially many overlapping groups, with efficient algorithms that avoid explicit enumeration (Gopalan et al. 2022).

Recent work has begun to identify the interaction between statistical and ontological problems. Kong (2022) provides a philosophical analysis arguing that the dominant statistical parity approach faces a "dilemma between infinite regress and fairness gerrymandering" - either continuously splitting groups into smaller subgroups (statistical problem) or arbitrarily selecting protected groups (ontological problem). This connects directly to the research proposal's core thesis. The fairness auditing literature (Cherian and Candès 2023) further explores how to conduct statistically rigorous fairness evaluations across rich collections of subgroups.

RELEVANCE_TO_PROJECT:

This domain provides the technical foundation for understanding how the fairness ML community conceptualizes and attempts to solve intersectional fairness problems. The multicalibration and subgroup fairness literature demonstrates sophisticated awareness of statistical challenges (exponentially many groups, sparse data) but largely treats group specification as given. Kong (2022) and recent work on fairness gerrymandering explicitly identify the ontological dimension, providing crucial support for the paper's argument that these two problems interact rather than being separately solvable.

NOTABLE_GAPS:

Few papers explicitly theorize the interaction between statistical and ontological uncertainty. Most multicalibration work assumes a fixed class of group membership functions without questioning their normative justification. The literature on sparse data solutions focuses on technical fixes rather than fundamental limits. There is minimal engagement with social ontology or philosophical questions about group construction, despite Kong's (2022) philosophical intervention.

SYNTHESIS_GUIDANCE:

When synthesizing, emphasize the sophistication of technical solutions (multicalibration, differential fairness) while highlighting how even these advanced methods cannot escape the group specification problem. Kong (2022) should be positioned as a key bridge between technical and philosophical literatures. The fairness gerrymandering papers demonstrate that the ontological problem is not merely philosophical but has measurable technical consequences.

KEY_POSITIONS:
- Multicalibration approaches: 5 papers - Calibrated predictions across rich subgroup collections
- Differential fairness / intersectional metrics: 3 papers - Statistical parity across intersectional groups
- Fairness gerrymandering critique: 3 papers - Highlighting manipulation through group selection
- Sparse data solutions: 4 papers - Technical approaches to small group challenges
- Survey/overview: 3 papers - Comprehensive reviews of fairness landscape
- Auditing methods: 2 papers - Statistical inference for fairness evaluation
====================================================================
}

@inproceedings{hebert-johnson2018multicalibration,
  author = {Hébert-Johnson, Úrsula and Kim, Michael P. and Reingold, Omer and Rothblum, Guy N.},
  title = {Multicalibration: Calibration for the (Computationally-Identifiable) Masses},
  booktitle = {Proceedings of the 35th International Conference on Machine Learning},
  year = {2018},
  pages = {1944--1953},
  note = {
  CORE ARGUMENT: Introduces multicalibration as a fairness notion requiring that predictions be calibrated not just overall but simultaneously across a rich collection of overlapping subgroups defined by efficiently computable functions. Provides efficient algorithms that achieve multicalibration without explicitly enumerating all subgroups, solving the combinatorial explosion problem for intersectional groups.

  RELEVANCE: Foundational paper for the multicalibration framework, which represents the most technically sophisticated approach to intersectional fairness. Demonstrates that calibration across exponentially many overlapping groups is computationally tractable, addressing the statistical side of the dilemma. However, assumes the class of group-defining functions is given, leaving the ontological question of which groups warrant consideration unaddressed.

  POSITION: Represents the "rich subgroup framework" approach to intersectional fairness - solve the statistical challenge through clever algorithms while treating group specification as an input to the fairness problem.
  },
  keywords = {multicalibration, subgroup-fairness, foundational, High}
}

@inproceedings{kong2022intersectionally,
  author = {Kong, Youjin},
  title = {Are "Intersectionally Fair" AI Algorithms Really Fair to Women of Color? A Philosophical Analysis},
  booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
  year = {2022},
  doi = {10.1145/3531146.3533114},
  note = {
  CORE ARGUMENT: Provides philosophical critique of dominant statistical parity approach to intersectional fairness in AI. Argues this approach faces a fundamental "dilemma between infinite regress and fairness gerrymandering": either continuously split groups into smaller subgroups ad infinitum, or arbitrarily select which groups to protect. Distinguishes "strong" fairness (addressing oppression) from "weak" fairness (statistical parity).

  RELEVANCE: Most explicit statement in the ML literature of the interaction between statistical and ontological problems in intersectional fairness. Directly supports the paper's core argument by identifying fairness gerrymandering as a consequence of arbitrary group selection. Bridges technical ML literature and philosophical analysis of intersectionality.

  POSITION: Philosophical critique of dominant technical approaches, arguing they fail to address intersection of oppressions and face fundamental conceptual problems in group specification.
  },
  keywords = {intersectionality, fairness-gerrymandering, philosophical-analysis, High}
}

@inproceedings{foulds2020intersectional,
  author = {Foulds, James R. and Islam, Rashidul and Keya, Kamrun Naher and Pan, Shimei},
  title = {An Intersectional Definition of Fairness},
  booktitle = {2020 IEEE 36th International Conference on Data Engineering (ICDE)},
  year = {2020},
  pages = {1918--1921},
  doi = {10.1109/icde48307.2020.00203},
  note = {
  CORE ARGUMENT: Proposes differential fairness, a multi-attribute fairness definition inspired by differential privacy that requires similar treatment for individuals who differ in protected attributes. Addresses intersectionality by requiring fairness simultaneously across all possible conjunctions of protected attributes. Provides learning algorithm with privacy, economic, and generalization guarantees.

  RELEVANCE: Represents major technical approach to intersectional fairness distinct from multicalibration. Demonstrates how differential privacy concepts can formalize intersectional requirements. However, like multicalibration, assumes protected attributes are pre-specified, not addressing the ontological question of which attributes constitute relevant axes of oppression.

  POSITION: Differential privacy-inspired approach to intersectional fairness, emphasizing formal guarantees across attribute combinations.
  },
  keywords = {differential-fairness, intersectionality, technical-approach, High}
}

@article{mehrabi2019survey,
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  title = {A Survey on Bias and Fairness in Machine Learning},
  journal = {ACM Computing Surveys},
  year = {2021},
  volume = {54},
  number = {6},
  pages = {1--35},
  doi = {10.1145/3457607},
  note = {
  CORE ARGUMENT: Comprehensive survey of bias and fairness in ML systems, covering sources of bias (data, algorithm, user interaction), fairness definitions (group fairness, individual fairness, subgroup fairness), and mitigation strategies across the ML pipeline. Identifies real-world applications where biased outcomes have occurred and discusses limitations of existing approaches.

  RELEVANCE: Provides comprehensive overview of the fairness landscape that situates intersectional approaches within broader fairness research. Useful for understanding how the field conceptualizes bias sources and fairness goals. However, survey format means limited depth on the specific statistical/ontological interaction central to the research project.

  POSITION: Survey paper establishing the state of the field, taxonomizing approaches without strongly advocating for specific solutions.
  },
  keywords = {fairness-survey, bias-mitigation, comprehensive-review, Medium}
}

@inproceedings{gohar2023intersectional,
  author = {Gohar, Usman and Cheng, Lu},
  title = {A Survey on Intersectional Fairness in Machine Learning: Notions, Mitigation, and Challenges},
  booktitle = {Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
  year = {2023},
  pages = {6619--6627},
  doi = {10.24963/ijcai.2023/742},
  note = {
  CORE ARGUMENT: Surveys state-of-the-art in intersectional fairness, presenting taxonomy of intersectional fairness notions and mitigation strategies. Identifies key challenges including computational complexity, data scarcity for intersectional groups, and metric selection. Provides guidelines for future research directions in intersectional fairness.

  RELEVANCE: Most comprehensive recent survey specifically focused on intersectional fairness. Explicitly identifies data scarcity for intersectional groups as a key challenge, directly relevant to the statistical dimension of the research proposal. Taxonomizes different technical approaches to the problem, showing variety of attempted solutions to overlapping group fairness.

  POSITION: Survey establishing the current state of intersectional fairness research, emphasizing open challenges and future directions.
  },
  keywords = {intersectional-fairness, survey, data-scarcity, High}
}

@article{tian2024multifair,
  author = {Tian, Huan and Liu, Bo and Zhu, Tianqing and Zhou, Wanlei and Yu, Philip S.},
  title = {MultiFair: Model Fairness With Multiple Sensitive Attributes},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  year = {2024},
  volume = {36},
  number = {5},
  pages = {5654--5667},
  doi = {10.1109/TNNLS.2024.3384181},
  note = {
  CORE ARGUMENT: Proposes MultiFair method for achieving fairness across multiple sensitive attributes through mixup-based data augmentation. Addresses fairness gerrymandering concern by ensuring fairness for all attribute combinations, not just per-attribute. Demonstrates that naive per-attribute approaches leave intersectional groups unfair, while their approach delivers fairness protections for multiple attributes simultaneously.

  RELEVANCE: Recent technical contribution explicitly addressing fairness gerrymandering in multi-attribute settings. Shows empirically that per-attribute fairness interventions can fail for intersectional groups, validating the need for explicit intersectional approaches. Represents state-of-the-art technical solution but assumes attributes are pre-specified.

  POSITION: Technical solution emphasizing that fairness must be evaluated at intersections to avoid gerrymandering, not just for individual attributes separately.
  },
  keywords = {multi-attribute-fairness, fairness-gerrymandering, recent-work, High}
}

@inproceedings{gopalan2022lowdegree,
  author = {Gopalan, Parikshit and Kim, Michael P. and Singhal, Mihir and Zhao, Shengjia},
  title = {Low-Degree Multicalibration},
  booktitle = {Proceedings of Thirty Fifth Conference on Learning Theory},
  year = {2022},
  pages = {3193--3234},
  note = {
  CORE ARGUMENT: Introduces low-degree multicalibration as middle ground between multiaccuracy (weak) and full multicalibration (strong but expensive). Shows that key fairness and accuracy properties of multicalibration manifest as low-degree properties, achieving exponentially better sample complexity than full multicalibration in multi-class settings. Provides theoretical analysis of the fairness-efficiency tradeoff.

  RELEVANCE: Addresses sample complexity challenges in multicalibration - directly relevant to sparse data problem for intersectional groups. Shows that achieving multicalibration for all intersectional groups requires exponentially growing data, but low-degree approximations can achieve many desiderata more efficiently. Illustrates statistical limits inherent in intersectional fairness.

  POSITION: Technical refinement of multicalibration showing that approximate solutions can achieve key fairness properties with better sample efficiency than exact solutions.
  },
  keywords = {multicalibration, sample-complexity, sparse-data, High}
}

@article{cherian2023statistical,
  author = {Cherian, John J. and Candès, Emmanuel J.},
  title = {Statistical Inference for Fairness Auditing},
  journal = {Journal of Machine Learning Research},
  year = {2024},
  volume = {25},
  pages = {1--56},
  note = {
  CORE ARGUMENT: Develops statistical framework for fairness auditing using multiple hypothesis testing with bootstrap methods. Shows how to simultaneously bound performance disparities over rich collections of subgroups with statistical guarantees. Addresses challenge of auditing fairness across exponentially many intersectional subgroups while controlling for multiple testing.

  RELEVANCE: Provides rigorous statistical methodology for fairness evaluation across intersectional groups. Demonstrates that statistically valid fairness auditing is possible for rich subgroup collections, but requires careful control of false discovery rates. Illustrates the statistical sophistication required to handle intersectional fairness evaluation, relevant to the statistical dimension of the dilemma.

  POSITION: Statistical methodology for fairness auditing, emphasizing rigorous hypothesis testing across multiple subgroups.
  },
  keywords = {fairness-auditing, statistical-inference, multiple-testing, High}
}

@article{ferrara2025sizehypothesis,
  author = {Ferrara, Antonio and Cozzi, Francesco and Perotti, Alan and Panisson, André and Bonchi, Francesco},
  title = {Size-adaptive Hypothesis Testing for Fairness},
  journal = {arXiv preprint arXiv:2506.10586},
  year = {2025},
  doi = {10.48550/arXiv.2506.10586},
  note = {
  CORE ARGUMENT: Proposes size-adaptive hypothesis testing framework that handles varying data availability across demographic groups, addressing the challenge that intersectional groups become increasingly small and sparse. Uses Central Limit Theorem for large groups and Bayesian Dirichlet-multinomial estimator for small groups. Demonstrates empirically that this approach provides interpretable, statistically rigorous fairness decisions under data scarcity.

  RELEVANCE: Most recent technical contribution specifically addressing sparse data problem for small intersectional groups. Provides practical statistical methods for handling the long tail of small intersectional subgroups where standard methods fail. Directly addresses the statistical challenge central to the research proposal's argument about the dilemma.

  POSITION: Statistical solution to sparse intersectional data through adaptive methods that adjust rigor based on group size.
  },
  keywords = {sparse-data, hypothesis-testing, intersectionality, High}
}

@inproceedings{raz2022gerrymandering,
  author = {Räz, Tim},
  title = {Gerrymandering Individual Fairness},
  journal = {Artificial Intelligence},
  year = {2023},
  volume = {323},
  doi = {10.48550/arXiv.2204.11615},
  note = {
  CORE ARGUMENT: Proves that individual fairness (similar individuals treated similarly) is susceptible to gerrymandering through manipulation of the feature space and similarity metric. Shows constructively how to create predictors that satisfy individual fairness while being systematically unfair. Argues for refined notions of fairness that are robust to such manipulation.

  RELEVANCE: Extends fairness gerrymandering concept from group fairness to individual fairness, showing the problem is fundamental rather than specific to group-based approaches. Demonstrates that fairness metrics can be gamed through strategic choices about problem representation, relevant to the ontological dimension of group specification.

  POSITION: Critique showing that even individual fairness (often proposed as alternative to group fairness) is susceptible to gerrymandering through feature/metric manipulation.
  },
  keywords = {fairness-gerrymandering, individual-fairness, critique, Medium}
}

@article{lee2025multicalibration,
  author = {Lee, Ho Ming and Antonio, Katrien and Avanzi, Benjamin and Marchi, Lorenzo and Zhou, Rui},
  title = {Machine Learning with Multitype Protected Attributes: Intersectional Fairness through Regularisation},
  journal = {arXiv preprint arXiv:2509.08163},
  year = {2025},
  doi = {10.48550/arXiv.2509.08163},
  note = {
  CORE ARGUMENT: Proposes distance covariance regularization framework for multicalibration that handles protected attributes of various types (categorical, continuous, mixed). Extends multicalibration to incorporate joint distance covariance and concatenated distance covariance measures, addressing fairness gerrymandering by ensuring fairness across intersectional subgroups defined by density ratios. Applies to both regression and classification with various attribute types.

  RELEVANCE: Very recent (2025) technical contribution addressing fairness gerrymandering through explicit intersectional modeling. Extends multicalibration to handle continuous and mixed-type attributes, broadening the technical framework beyond categorical groups. Demonstrates ongoing evolution of technical approaches to intersectional fairness challenges.

  POSITION: Technical extension of multicalibration addressing fairness gerrymandering through sophisticated statistical measures of attribute interactions.
  },
  keywords = {multicalibration, fairness-gerrymandering, continuous-attributes, Medium}
}

@inproceedings{davis2021algorithmic,
  author = {Davis, Jenny L. and Williams, Apryl and Yang, Michael W.},
  title = {Algorithmic Reparation},
  journal = {Big Data \& Society},
  year = {2021},
  volume = {8},
  number = {2},
  doi = {10.1177/20539517211044808},
  note = {
  CORE ARGUMENT: Critiques existing fair ML methods (anti-classification, classification parity, calibration) as operating from "algorithmic idealism" that cannot address systemic, intersectional stratifications. Proposes "algorithmic reparation" grounded in intersectionality theory, which names, unmasks, and undoes allocative and representational harms as they materialize in sociotechnical form.

  RELEVANCE: Provides intersectionality-grounded critique of technical fairness approaches, arguing they fail to engage with structural oppression and intersectional complexity. Represents perspective from critical data studies emphasizing that technical fixes cannot solve fundamentally social-ontological problems. Relevant to the paper's argument that statistical solutions alone cannot resolve the intersectional fairness dilemma.

  POSITION: Critical perspective arguing that technical fairness methods fail to address intersectional oppression and proposing reparation-oriented alternative.
  },
  keywords = {algorithmic-reparation, intersectionality-theory, critical-perspective, Medium}
}

@inproceedings{himmelreich2024intersectionality,
  author = {Himmelreich, Johannes and Hsu, Arbie and Lum, Kristian and Veomett, Ellen},
  title = {The Intersectionality Problem for Algorithmic Fairness},
  journal = {arXiv preprint arXiv:2411.02569},
  year = {2024},
  doi = {10.48550/arXiv.2411.02569},
  note = {
  CORE ARGUMENT: Elucidates the problem of intersectionality in algorithmic fairness, developing desiderata to clarify challenges and guide solutions. Identifies both statistical challenges (small intersectional groups) and moral-methodological challenges (which groups matter). Proposes and evaluates hypothesis testing approach, demonstrating tradeoffs between statistical power and intersectional coverage.

  RELEVANCE: Recent philosophical-technical paper explicitly framing intersectional fairness as involving both statistical and normative challenges. Provides clear articulation of the problem space and proposes concrete desiderata for evaluating solutions. Directly relevant to the paper's framing of the dilemma as involving interacting statistical and ontological dimensions.

  POSITION: Philosophical-technical analysis identifying the intersectionality problem as multi-dimensional, requiring both statistical sophistication and normative clarity about group relevance.
  },
  keywords = {intersectionality-problem, statistical-normative, philosophical-technical, High}
}

@article{caton2024fairness,
  author = {Caton, Simon and Haas, Christian},
  title = {Fairness in Machine Learning: A Survey},
  journal = {ACM Computing Surveys},
  year = {2024},
  volume = {56},
  number = {7},
  pages = {1--38},
  doi = {10.1145/3616865},
  note = {
  CORE ARGUMENT: Comprehensive survey organizing fairness approaches into pre-processing, in-processing, and post-processing methods across 11 method areas. Discusses fairness in regression, recommender systems, and unsupervised learning beyond binary classification. Concludes by identifying five fundamental dilemmas in fairness research including the impossibility of satisfying all fairness criteria simultaneously.

  RELEVANCE: Provides broad overview of fairness methods and fundamental tradeoffs. Identifies structural dilemmas in fairness research that constrain possible solutions. Useful for situating intersectional fairness within broader landscape of fairness approaches and understanding inherent limitations.

  POSITION: Survey establishing the fairness landscape, emphasizing fundamental tradeoffs and impossibility results that constrain fairness approaches.
  },
  keywords = {fairness-survey, tradeoffs, methods-taxonomy, Medium}
}

@article{ekstrand2022fairness,
  author = {Ekstrand, Michael D. and Das, Anubrata and Burke, Robin and Díaz, Fernando},
  title = {Fairness in Information Access Systems},
  journal = {Foundations and Trends in Information Retrieval},
  year = {2022},
  volume = {16},
  number = {1-2},
  pages = {1--177},
  doi = {10.1561/1500000079},
  note = {
  CORE ARGUMENT: Comprehensive treatment of fairness in information access systems (recommendation, retrieval), emphasizing multi-stakeholder nature, rank-based settings, and role of personalization. Develops taxonomy of fairness dimensions specific to information access. Discusses how fairness challenges differ from classification settings due to user response dynamics and multi-sided platforms.

  RELEVANCE: Demonstrates how fairness challenges manifest differently across application domains, with information access posing unique challenges for intersectional fairness due to feedback loops and stakeholder complexity. Illustrates that intersectional fairness problems vary by application context, relevant to understanding scope and generality of solutions.

  POSITION: Domain-specific survey showing how fairness concerns in information access differ from classification, requiring adapted approaches.
  },
  keywords = {information-access, fairness-survey, domain-specific, Low}
}

@article{hansen2024multicalibration,
  author = {Hansen, Dutch and Devic, Siddartha and Nakkiran, Preetum and Sharan, Vatsal},
  title = {When is Multicalibration Post-Processing Necessary?},
  journal = {Advances in Neural Information Processing Systems},
  year = {2024},
  volume = {37},
  note = {
  CORE ARGUMENT: Conducts comprehensive empirical study evaluating when multicalibration post-processing provides benefits beyond standard calibration. Finds that models calibrated out-of-the-box tend to be relatively multicalibrated without additional processing, but multicalibration helps inherently uncalibrated models and large language models. Provides practical guidance on when multicalibration post-processing is necessary.

  RELEVANCE: Recent empirical evaluation of multicalibration's practical utility across diverse models and datasets. Demonstrates that achieving multicalibration is not always difficult in practice, but benefits vary by model type. Relevant to understanding when intersectional fairness concerns require explicit intervention versus emerging naturally from well-calibrated models.

  POSITION: Empirical analysis showing multicalibration post-processing is sometimes but not always necessary, depending on model and data characteristics.
  },
  keywords = {multicalibration, empirical-evaluation, practical-utility, Medium}
}

@inproceedings{vethman2025fairness,
  author = {Vethman, Steven and Smit, Quirine T. S. and van Liebergen, Nina M. and Veenman, Cor J.},
  title = {Fairness Beyond the Algorithmic Frame: Actionable Recommendations for an Intersectional Approach},
  booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
  year = {2025},
  doi = {10.1145/3715275.3732210},
  note = {
  CORE ARGUMENT: Argues that technical fairness interventions operating within the "algorithmic frame" are insufficient for addressing intersectional fairness. Provides actionable recommendations for incorporating intersectional approaches that go beyond algorithm design to consider broader sociotechnical context, power relations, and structural inequalities. Emphasizes need to expand scope of fairness work beyond technical optimization.

  RELEVANCE: Recent contribution arguing for expanded framing of intersectional fairness beyond purely technical approaches. Relevant to the paper's argument that technical statistical solutions cannot fully resolve the intersectional fairness dilemma without engaging with social-ontological questions about group construction and structural inequality.

  POSITION: Critical-constructive perspective arguing technical fairness must be supplemented with broader intersectional analysis of sociotechnical context.
  },
  keywords = {intersectional-approach, sociotechnical, beyond-algorithmic, Medium}
}

@inproceedings{globus-harris2023multicalibration,
  author = {Globus-Harris, Ira and Harrison, Declan and Kearns, Michael and Roth, Aaron and Sorrell, Jessica},
  title = {Multicalibration as Boosting for Regression},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  year = {2023},
  pages = {11459--11492},
  note = {
  CORE ARGUMENT: Shows multicalibration can be achieved through standard weak agnostic learning oracle, connecting multicalibration to boosting for regression. Provides simple algorithm analyzable as both boosting and multicalibration, with convergence to Bayes optimality under weak learning assumptions. Demonstrates that multicalibration and calibration together yield considerably stronger guarantees than either alone.

  RELEVANCE: Theoretical contribution showing multicalibration's connection to fundamental learning primitives. Demonstrates that achieving multicalibration requires at minimum weak agnostic learning, establishing computational complexity bounds. Relevant to understanding theoretical foundations and limits of multicalibration approaches to intersectional fairness.

  POSITION: Theoretical analysis connecting multicalibration to boosting, establishing computational and learning-theoretic foundations.
  },
  keywords = {multicalibration, boosting, learning-theory, Low}
}

@article{noarov2023scope,
  author = {Noarov, Georgy and Roth, Aaron},
  title = {The Scope of Multicalibration: Characterizing Multicalibration via Property Elicitation},
  journal = {arXiv preprint arXiv:2302.08507},
  year = {2023},
  doi = {10.48550/arXiv.2302.08507},
  note = {
  CORE ARGUMENT: Establishes connection between multicalibration and property elicitation, proving that a property can be multicalibrated if and only if it is elicitable. Extends multicalibration beyond means to general distributional properties including quantiles and variance. Provides theoretical characterization of the scope of multicalibration as a fairness framework.

  RELEVANCE: Theoretical work establishing fundamental limits and scope of multicalibration framework. Shows which fairness properties can be achieved through multicalibration and which cannot, relevant to understanding what statistical guarantees are achievable for intersectional groups. Demonstrates theoretical foundations of multicalibration approaches.

  POSITION: Theoretical characterization establishing scope and limits of multicalibration through connection to property elicitation.
  },
  keywords = {multicalibration, property-elicitation, theoretical, Low}
}

@article{wu2024bridging,
  author = {Wu, Jiayun and Liu, Jiashuo and Cui, Peng and Wu, Zhiwei Steven},
  title = {Bridging Multicalibration and Out-of-distribution Generalization Beyond Covariate Shift},
  journal = {Advances in Neural Information Processing Systems},
  year = {2024},
  volume = {37},
  note = {
  CORE ARGUMENT: Establishes link between multicalibration and out-of-distribution generalization, showing that extended multicalibration (incorporating groupings over covariates and labels jointly) is equivalent to invariance under concept shift. Proposes MC-Pseudolabel algorithm achieving both multicalibration and OOD generalization. Demonstrates connection between fairness and robustness.

  RELEVANCE: Recent work connecting multicalibration to distribution shift robustness, showing that fairness and generalization are related desiderata. Relevant to understanding how solutions to intersectional fairness challenges might also address model robustness. Demonstrates broader significance of multicalibration framework beyond fairness.

  POSITION: Technical contribution bridging fairness (multicalibration) and robustness (OOD generalization) through extended multicalibration framework.
  },
  keywords = {multicalibration, ood-generalization, robustness, Medium}
}

