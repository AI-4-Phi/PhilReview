## Section 6: Research Gaps and the Dilemma's Novelty

The literature reviewed reveals sophisticated engagement with both the statistical and ontological dimensions of intersectional fairness, yet a critical gap remains. Existing work treats these as separate optimization problems—one technical, one philosophical—rather than recognizing their interaction as constituting a genuine dilemma where addressing one horn exacerbates the other. This section identifies four specific gaps that define the research opportunity.

### Gap 1: No Recognition of Statistical-Ontological Interaction as Dilemma

The most fundamental gap is the failure to recognize that statistical uncertainty and ontological uncertainty interact as a dilemma rather than as independent challenges. The technical ML literature has developed impressive solutions to statistical problems: multicalibration enables calibrated predictions across exponentially many subgroups without explicit enumeration (Hébert-Johnson et al. 2018), low-degree approximations address sample complexity challenges (Gopalan et al. 2022), size-adaptive hypothesis testing handles varying data availability (Ferrara et al. 2025), and statistical inference frameworks provide rigorous auditing across rich subgroup collections (Cherian and Candès 2023). These advances demonstrate that the statistical dimension—ensuring reliable fairness measurement despite sparse data—has sophisticated technical responses.

Parallel to this technical progress, the philosophy literature has explored ontological questions about group constitution without engaging statistical feasibility constraints. Debates about whether intersectional categories emerge contextually from social structures (Jorba and López de Sa 2024) or reduce to constituent categories (Bernstein 2020), whether groups are defined by attributes or practices (Haslanger 2012; Ásta 2018; Ritchie 2018), and whether intersectionality should be understood through analytical or hermeneutic frameworks (Carastathis 2016; Collins 2019) proceed largely in isolation from questions about whether these metaphysical positions can be algorithmically implemented. Even work applying social ontology to discrimination (Popescu-Sarry 2023) rarely considers how practice-based group constitution undermines computational group specification.

The few papers bridging these domains identify both dimensions but do not theorize their interaction. Himmelreich et al. (2024) explicitly frame the intersectionality problem as involving "statistical challenges (small intersectional groups) and moral-methodological challenges (which groups matter)," developing desiderata to clarify both. Yet their analysis treats these as separate constraints to be jointly satisfied, not as horns of a dilemma where satisfying one makes satisfying the other harder. Gohar and Cheng's (2023) survey identifies data scarcity alongside computational complexity and metric selection as key challenges, but presents them as a list of problems rather than interacting constraints.

Kong (2022) comes closest to recognizing the interaction, identifying a "dilemma between infinite regress and fairness gerrymandering": either continuously split groups into smaller subgroups ad infinitum (creating ever-sparser data), or arbitrarily select which groups to protect (ontological gerrymandering). However, Kong frames this primarily as a philosophical problem about the statistical parity approach's conceptual adequacy, not as an intractable interaction between statistical reliability requirements and ontological indeterminacy. The statistical consequences of infinite group subdivision and the ontological arbitrariness of group selection are presented as parallel problems arising from the same flawed approach, not as interacting constraints that create a genuine dilemma.

This gap matters because if the interaction constitutes a genuine dilemma rather than two independent challenges, then existing approaches addressing either horn in isolation are systematically inadequate. Technical solutions that assume groups are given (multicalibration, differential fairness) cannot resolve ontological uncertainty about which groups exist. Philosophical analyses of group constitution that ignore statistical feasibility cannot guide fairness auditing when sample sizes impose hard constraints on how finely groups can be subdivided. The interaction is the problem: expanding intersectional coverage for ontological adequacy creates statistical unreliability; constraining coverage for statistical reliability requires resolving contested ontological questions that philosophy reveals have no neutral resolution.

### Gap 2: Limited Engagement with Statistical Feasibility in Social Ontology

The philosophy of intersectionality has produced rich conceptual analyses of how social categories combine, yet remarkably little of this work considers algorithmic implementation constraints or statistical feasibility. Debates about emergence versus reduction (Jorba and López de Sa 2024; Bernstein 2020), analytical versus hermeneutic interpretations (Carastathis 2016; Collins 2019), and mutually constitutive versus additive models (Yuval-Davis 2006) proceed without asking whether the resulting ontological commitments can be operationalized in fairness auditing systems that require statistical inference from finite data.

Social ontology debates about attribute-based versus practice-based group constitution similarly neglect computational implications. Haslanger's (2012) political constructionism defines race and gender as social positions constituted by systematic subordination and privilege, not intrinsic attributes. Mallon's (2016) social role HPC kinds show how categories are contingent artifacts of practices stabilized by homeostatic mechanisms. Ásta's (2018) conferralism argues that social properties depend on communal conferral, with the same attributes grounding different properties in different contexts. Ritchie's (2018) structuralism treats groups as networks of social relations rather than collections defined by shared features. These sophisticated accounts converge on the view that group membership cannot be derived algorithmically from demographic attributes—yet none directly engage with how this constrains fairness auditing.

The gap is not that social ontologists should become technical ML researchers, but rather that the algorithmic infeasibility of certain ontological positions deserves explicit theoretical attention. If Ásta is correct that conferralism makes group boundaries context-dependent on communal meaning-making, this implies fairness systems cannot pre-specify groups from demographic data. If Ritchie is correct that groups are constituted by relational networks rather than shared attributes, algorithmic approaches treating groups as attribute-defined categories fundamentally misconstrue what groups are. These implications matter for evaluating whether fairness auditing is possible, yet they remain undertheorized.

Measurement theory applications to fairness provide an instructive contrast. Papers like Tal (2023), Blodgett et al. (2021), and Bean et al. (2025) explicitly analyze whether fairness benchmarks validly measure what they purport to measure, connecting measurement validity challenges to construct specification problems. Similar analysis is needed for the connection between social ontology and group specification: if practice-based accounts are correct, does this make valid algorithmic group specification impossible, or merely require different computational approaches? The philosophical debates have direct bearing on technical feasibility, but the implications remain implicit.

### Gap 3: Normative Foundations Left Implicit in Technical Fairness Work

Technical fairness literature generally treats metric choice as a technical decision to be optimized rather than a normative choice reflecting contested ethical commitments. Yet the distributive justice literature shows that different normative frameworks—prioritarianism (Arneson 2000; Parfit 2012), sufficientarianism (Shields 2016; Timmer 2021), egalitarianism (Anderson 1999), and pluralist combinations (Robeyns 2022)—yield systematically different answers about which groups warrant protection and how to prioritize them. Prioritarians focus fairness interventions on the worst-off intersectional groups, weighting improvements for multiply marginalized communities most heavily. Sufficientarians prioritize ensuring all groups reach minimum acceptable thresholds, with strongest urgency for groups falling below sufficiency levels. Egalitarians pursue parity across groups. These frameworks differ not just in how much inequality to tolerate, but in which groups matter and why.

Recent philosophical work has begun making these connections explicit. Baumann et al. (2022) show that different fairness metrics embody contested philosophical commitments about distributive justice—what counts as benefit or harm, what moral claims to benefits people have. Hertweck et al. (2024) argue that algorithmic fairness should focus on distribution of errors rather than outcomes, reframing how distributive justice principles apply. Holm (2025) applies Broome's claims-based fairness theory to argue that statistical parity violates the separateness of persons by allocating treatments for the wrong reasons. These papers demonstrate that metric choice cannot be settled by technical optimization alone but requires engagement with normative theory.

However, this insight rarely penetrates technical work on intersectional fairness. Multicalibration literature treats the class of subgroup-defining functions as a technical parameter rather than recognizing that choosing which functions to include reflects normative judgments about which groups deserve fairness protections. Work on sparse data solutions focuses on statistical methodology without asking whether requiring large sample sizes for reliability constitutes epistemic injustice (Fricker 2007; Anderson 2012) by excluding groups that cannot be easily aggregated. Fairness gerrymandering research demonstrates that strategic group selection undermines metrics (Kearns et al. 2018; Kong 2022; Tian et al. 2024), yet doesn't fully theorize that the ontological question—which groups exist—is partly normative, not purely metaphysical or empirical.

The gap is consequential because normative disagreements compound ontological uncertainty. If which groups matter is partly an ethical question, then different stakeholders operating from different normative frameworks will legitimately disagree about which intersectional groups warrant auditing. A prioritarian may focus on the multiply marginalized; a sufficientarian on groups below thresholds; an egalitarian on all groups equally. These are not technical disagreements resolvable through better metrics, but substantive ethical disagreements about the purpose of fairness auditing. Technical optimization cannot resolve which normative framework to adopt.

### Gap 4: Critical Perspectives Without Constructive Alternatives

Critical perspectives on fairness formalization have identified fundamental limitations yet offer limited concrete alternatives beyond general programmatic calls. Green's (2022) distinction between formal and substantive algorithmic fairness argues that impossibility results stem from formalist methodology restricting analysis to isolated decision procedures. By expanding scope to examine structural context and power relations, substantive approaches can escape impossibility theorems. However, "substantive fairness" remains somewhat programmatic—it describes what fairness analysis should attend to (structural conditions, long-term effects, distributional patterns) without specifying operational alternatives to current fairness auditing practices.

Wachter et al.'s (2021) impossibility thesis argues that fairness cannot be automated because legal and moral conceptions of discrimination exceed statistical formalization, requiring contextual judgment about intent, causation, and structural factors. This is an important corrective to techno-optimism, yet it leaves practitioners without clear guidance: if fairness cannot be automated, what role should computational fairness assessment play? The paper emphasizes limitations without developing alternatives.

Kasirzadeh's (2022) structural injustice critique argues that fairness metrics rooted in distributive justice ideals cannot address oppressive structures, drawing on Iris Marion Young's political philosophy. This represents a genuine paradigm challenge—if the problem is structural oppression rather than maldistribution, then fairness metrics optimizing distributions miss the point. Yet the paper's proposed "responsible algorithmic fairness" remains abstract, calling for expanding scope without specifying what institutional or technical practices would realize this expansion.

Hampton's (2021) Black feminist critique is perhaps most radical, questioning whether fairness discourse itself adequately captures algorithmic oppression or merely provides liberal cover for extractive systems. The call for abolition rather than algorithmic reform represents a fundamental rejection of fairness optimization. However, as a position statement it offers limited concrete guidance for practitioners committed to working within existing institutional contexts where algorithmic systems will be deployed regardless.

The gap is not that critics should provide fully specified technical alternatives—critique can be valuable without proposing solutions. Rather, the gap is in developing a principled understanding of formalization's limits. By framing the intersectionality dilemma as arising from the interaction of statistical and ontological constraints, the present research provides more granular analysis of why fairness formalization is limited. Not all of fairness resists operationalization for the same reasons. The dilemma helps explain which aspects (intersectional group specification under sparse data) face fundamental constraints versus which might be addressable through better methods.

Critical perspectives rightly identify that impossibility results reflect deeper problems than metric incompatibility, but they have not fully theorized what those deeper problems are. Is the issue that fairness is inherently contested (Green 2022), that discrimination law requires contextual judgment (Wachter et al. 2021), that distributive justice cannot capture structural oppression (Kasirzadeh 2022), or that fairness discourse itself is ideologically compromised (Hampton 2021)? These are importantly different diagnoses suggesting different responses. The intersectionality dilemma contributes by identifying a specific structural problem—the interaction between epistemological limits (sparse data) and ontological limits (contested group constitution)—that current approaches cannot resolve because addressing either horn worsens the other.

### Summary: The Missing Interaction

Across all four gaps, the common pattern is treatment of statistical and ontological challenges as separate problems rather than interacting constraints. Technical literature assumes groups can be specified; philosophical literature ignores statistical feasibility; normative foundations remain implicit; critical perspectives diagnose limitations without specifying their sources. What the literature does not address is the interaction itself: expanding groups for ontological adequacy necessarily reduces per-group sample sizes, undermining statistical reliability. Constraining groups for statistical reliability requires resolving contested ontological questions about which groups exist—but philosophy reveals these questions have no neutral resolution, being compounded by normative disagreements about which groups matter.

This is not merely a matter of two hard problems that must both be solved. It is a dilemma where the solutions are in tension. Better statistical methods for sparse data (Ferrara et al. 2025; Cherian and Candès 2023) enable more reliable auditing of whatever groups are specified, but cannot determine which groups should be specified. Sophisticated social ontology (Haslanger 2012; Ásta 2018; Ritchie 2018) clarifies what groups are, but reveals they cannot be algorithmically derived from attributes because constitution depends on practices, conferral, and relational structures. Normative frameworks (Shields 2016; Arneson 2000; Anderson 1999) provide principled bases for prioritizing groups, but different frameworks yield different prioritizations and no framework has neutral justification. Critical perspectives (Green 2022; Kasirzadeh 2022) identify formalization's limits, but do not explain precisely why fairness resists operationalization.

The research contribution is recognizing and articulating this interaction. Existing literature identifies the pieces—statistical challenges, ontological debates, normative pluralism, formalization limits—but misses how they fit together as a dilemma. The intersectionality problem for algorithmic fairness is not that we lack good enough statistics (we have sophisticated methods) or that we lack philosophical clarity about groups (social ontology is well-developed) or that we lack ethical frameworks (distributive justice provides options). The problem is that these domains interact to create intractable trade-offs: ensuring statistical reliability while respecting ontological adequacy and accommodating normative pluralism may be impossible because satisfying each constraint makes satisfying the others harder. This is the gap the literature leaves unaddressed.
